[{"content":"1.题目 接雨水题解 这题真他妈经典，老子搞了半小时才彻底搞懂。记录一下思路，免得下次又忘。\n核心思路 每个位置能接的雨水量 = min(左边最高的柱子, 右边最高的柱子) - 当前柱子高度\n简单来说就是：\n找当前柱子左边最高的（不包括自己） 找当前柱子右边最高的（不包括自己） 取这俩的较小值 如果这个值比当前柱子高，差值就是能接的雨水 具体实现 第一步：预处理左右最大值 先搞两个数组：\nleftMax[i]：表示第i个柱子左边最高的柱子高度（不包含自己） rightMax[i]：表示第i个柱子右边最高的柱子高度（不包含自己） 计算leftMax：\n从左往右扫 维护一个当前最大值max 对于每个位置i，leftMax[i] = max（记录之前遇到的最大值） 然后更新max = Math.max(max, height[i]) 1 2 3 4 5 int max = 0; for (int i = 0; i \u0026lt; n; i++) { leftMax[i] = max; max = Math.max(max, height[i]); } 计算rightMax：\n从右往左扫 同样维护一个当前最大值max 对于每个位置i，rightMax[i] = max 然后更新max = Math.max(max, height[i]) 1 2 3 4 5 max = 0; for (int i = n - 1; i \u0026gt;= 0; i--) { rightMax[i] = max; max = Math.max(max, height[i]); } 第二步：计算雨水 现在有了leftMax和rightMax，对于每个位置：\n取leftMax[i]和rightMax[i]的较小值 如果这个值 \u0026gt; height[i]，说明能接雨水 雨水 = 较小值 - height[i] 1 2 3 4 5 6 for (int i = 0; i \u0026lt; n; i++) { int min = Math.min(leftMax[i], rightMax[i]); if (min \u0026gt; height[i]) { ans += (min - height[i]); } } 例子分析 以[0,1,0,2,1,0,1,3,2,1,2,1]为例：\n计算leftMax：\n从左往右，记录遇到的最大值 得到：[0,0,1,1,2,2,2,2,3,3,3,3] 计算rightMax：\n从右往左，记录遇到的最大值 得到：[3,3,3,3,3,3,3,2,2,2,1,0] 计算雨水：\n比如i=2，height=0 leftMax=1, rightMax=3 min=1 1 \u0026gt; 0，所以接1单位水 复杂度 时间：O(n)，扫了3遍数组 空间：O(n)，用了两个辅助数组 优化思路 其实可以用双指针把空间降到O(1)，不过这个解法已经够直观了，下次再研究优化的。\n代码总结 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public int trap(int[] height) { int n = height.length; int ans = 0; // 左边最大值 int[] leftMax = new int[n]; int max = 0; for (int i = 0; i \u0026lt; n; i++) { leftMax[i] = max; max = Math.max(max, height[i]); } // 右边最大值 int[] rightMax = new int[n]; max = 0; for (int i = n - 1; i \u0026gt;= 0; i--) { rightMax[i] = max; max = Math.max(max, height[i]); } // 计算雨水 for (int i = 0; i \u0026lt; n; i++) { int min = Math.min(leftMax[i], rightMax[i]); if (min \u0026gt; height[i]) { ans += (min - height[i]); } } return ans; } 这题真他妈经典，记住这个思路就完事了！\n","date":"2025-07-03T00:00:00Z","image":"https://nova-bryan.github.io/p/leetcode42.%E6%8E%A5%E9%9B%A8%E6%B0%B4/image_hu7343995253115549451.png","permalink":"https://nova-bryan.github.io/p/leetcode42.%E6%8E%A5%E9%9B%A8%E6%B0%B4/","title":"LeetCode42.接雨水"},{"content":"数据库索引完全指南 目录 什么是数据库索引 索引的基本原理 索引的类型 索引的创建和使用 索引的优缺点 索引失效的场景 索引优化实践 总结 什么是数据库索引 数据库索引是一种数据结构，它提供了快速访问数据库表中数据的路径。就像书籍的目录一样，索引可以帮助数据库快速定位到具体的数据行，而不需要扫描整个表。\n形象化理解 想象你要在一本1000页的字典中查找单词\u0026quot;database\u0026quot;：\n没有索引：你需要从第1页开始逐页翻阅，直到找到为止 有索引：你直接翻到\u0026quot;D\u0026quot;开头的目录页，快速定位到具体页码 索引就是数据库的\u0026quot;目录\u0026quot;。\n性能对比示意图 1 2 3 4 5 6 7 8 9 graph TD A[\u0026#34;全表扫描\u0026lt;br/\u0026gt;O(n) 时间复杂度\u0026#34;] --\u0026gt; B[\u0026#34;逐行检查每条记录\u0026#34;] B --\u0026gt; C[\u0026#34;找到匹配记录\u0026#34;] D[\u0026#34;使用索引\u0026lt;br/\u0026gt;O(log n) 时间复杂度\u0026#34;] --\u0026gt; E[\u0026#34;通过索引快速定位\u0026#34;] E --\u0026gt; F[\u0026#34;直接访问目标记录\u0026#34;] G[\u0026#34;1000万记录对比\u0026#34;] --\u0026gt; H[\u0026#34;全表扫描: 最多1000万次比较\u0026#34;] G --\u0026gt; I[\u0026#34;B+树索引: 最多4次比较\u0026#34;] 索引的基本原理 数据存储结构 数据库中的数据通常存储在**页(Page)**中，每个页包含多条记录。\n1 2 3 4 5 表数据存储示意： 页1: [记录1, 记录2, 记录3, ...] 页2: [记录101, 记录102, 记录103, ...] 页3: [记录201, 记录202, 记录203, ...] ... B+树索引原理 大多数数据库使用B+树作为索引的数据结构：\n1 2 3 4 5 6 B+树索引结构： 根节点 / \\ 内部节点1 内部节点2 / | \\ / | \\ 叶子节点1 叶子2 叶子3 叶子4 叶子5 叶子6 B+树的特点：\n所有数据都存储在叶子节点 叶子节点之间有指针连接，便于范围查询 树的高度较低，减少磁盘I/O次数 支持顺序访问和随机访问 B+树详细结构图 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 graph TD subgraph \u0026#34;B+树索引结构\u0026#34; Root[\u0026#34;根节点\u0026lt;br/\u0026gt;[30, 60]\u0026#34;] Internal1[\u0026#34;内部节点1\u0026lt;br/\u0026gt;[10, 20]\u0026#34;] Internal2[\u0026#34;内部节点2\u0026lt;br/\u0026gt;[40, 50]\u0026#34;] Internal3[\u0026#34;内部节点3\u0026lt;br/\u0026gt;[70, 80]\u0026#34;] Leaf1[\u0026#34;叶子节点1\u0026lt;br/\u0026gt;[1,5,8,10]\u0026lt;br/\u0026gt;→ 数据页1\u0026#34;] Leaf2[\u0026#34;叶子节点2\u0026lt;br/\u0026gt;[15,18,20,25]\u0026lt;br/\u0026gt;→ 数据页2\u0026#34;] Leaf3[\u0026#34;叶子节点3\u0026lt;br/\u0026gt;[35,38,40,42]\u0026lt;br/\u0026gt;→ 数据页3\u0026#34;] Leaf4[\u0026#34;叶子节点4\u0026lt;br/\u0026gt;[45,48,50,55]\u0026lt;br/\u0026gt;→ 数据页4\u0026#34;] Leaf5[\u0026#34;叶子节点5\u0026lt;br/\u0026gt;[65,68,70,75]\u0026lt;br/\u0026gt;→ 数据页5\u0026#34;] Leaf6[\u0026#34;叶子节点6\u0026lt;br/\u0026gt;[78,80,85,90]\u0026lt;br/\u0026gt;→ 数据页6\u0026#34;] Root --\u0026gt; Internal1 Root --\u0026gt; Internal2 Root --\u0026gt; Internal3 Internal1 --\u0026gt; Leaf1 Internal1 --\u0026gt; Leaf2 Internal2 --\u0026gt; Leaf3 Internal2 --\u0026gt; Leaf4 Internal3 --\u0026gt; Leaf5 Internal3 --\u0026gt; Leaf6 Leaf1 -.-\u0026gt; Leaf2 Leaf2 -.-\u0026gt; Leaf3 Leaf3 -.-\u0026gt; Leaf4 Leaf4 -.-\u0026gt; Leaf5 Leaf5 -.-\u0026gt; Leaf6 end 索引查找过程 从根节点开始 根据比较结果选择分支 逐层向下直到叶子节点 在叶子节点中找到目标数据 查找过程流程图 1 2 3 4 5 6 7 8 9 10 11 flowchart TD A[\u0026#34;查询: SELECT * FROM users WHERE id = 42\u0026#34;] --\u0026gt; B[\u0026#34;开始从根节点查找\u0026#34;] B --\u0026gt; C[\u0026#34;根节点: [30, 60]\u0026lt;br/\u0026gt;42 \u0026gt; 30 且 42 \u0026lt; 60\u0026#34;] C --\u0026gt; D[\u0026#34;进入中间节点2: [40, 50]\u0026lt;br/\u0026gt;42 \u0026gt; 40 且 42 \u0026lt; 50\u0026#34;] D --\u0026gt; E[\u0026#34;进入叶子节点3: [35,38,40,42]\u0026lt;br/\u0026gt;找到目标值 42\u0026#34;] E --\u0026gt; F[\u0026#34;通过指针访问数据页3\u0026#34;] F --\u0026gt; G[\u0026#34;返回完整记录数据\u0026#34;] style A fill:#e1f5fe style G fill:#c8e6c9 style E fill:#fff3e0 索引的类型 索引分类总览 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 graph TD A[\u0026#34;数据库索引分类\u0026#34;] --\u0026gt; B[\u0026#34;按数据结构\u0026#34;] A --\u0026gt; C[\u0026#34;按字段数量\u0026#34;] A --\u0026gt; D[\u0026#34;按功能特性\u0026#34;] B --\u0026gt; B1[\u0026#34;B+树索引\u0026lt;br/\u0026gt;（最常用）\u0026#34;] B --\u0026gt; B2[\u0026#34;哈希索引\u0026lt;br/\u0026gt;（等值查询）\u0026#34;] B --\u0026gt; B3[\u0026#34;全文索引\u0026lt;br/\u0026gt;（文本搜索）\u0026#34;] C --\u0026gt; C1[\u0026#34;单列索引\u0026lt;br/\u0026gt;CREATE INDEX idx_name ON users(name)\u0026#34;] C --\u0026gt; C2[\u0026#34;复合索引\u0026lt;br/\u0026gt;CREATE INDEX idx_name_age ON users(name,age)\u0026#34;] D --\u0026gt; D1[\u0026#34;普通索引\u0026lt;br/\u0026gt;（可重复）\u0026#34;] D --\u0026gt; D2[\u0026#34;唯一索引\u0026lt;br/\u0026gt;（不可重复）\u0026#34;] D --\u0026gt; D3[\u0026#34;主键索引\u0026lt;br/\u0026gt;（主键约束）\u0026#34;] style B1 fill:#c8e6c9 style C2 fill:#fff3e0 style D3 fill:#ffcdd2 1. 按数据结构分类 B+树索引（最常用） 特点：平衡多路搜索树 适用：等值查询、范围查询、排序 存储引擎：InnoDB、MyISAM 哈希索引 特点：基于哈希表 适用：等值查询 限制：不支持范围查询、排序 存储引擎：Memory 2. 按字段数量分类 单列索引 1 CREATE INDEX idx_name ON users(name); 复合索引（联合索引） 1 CREATE INDEX idx_name_age ON users(name, age); 3. 按功能分类 普通索引 1 CREATE INDEX idx_email ON users(email); 唯一索引 1 CREATE UNIQUE INDEX idx_username ON users(username); 主键索引 1 ALTER TABLE users ADD PRIMARY KEY(id); 全文索引 1 CREATE FULLTEXT INDEX idx_content ON articles(content); 索引的创建和使用 创建索引 建表时创建 1 2 3 4 5 6 7 8 9 CREATE TABLE users ( id INT PRIMARY KEY, username VARCHAR(50) UNIQUE, email VARCHAR(100), age INT, created_at TIMESTAMP, INDEX idx_email (email), INDEX idx_age_created (age, created_at) ); 建表后创建 1 2 3 4 5 6 7 8 -- 普通索引 CREATE INDEX idx_email ON users(email); -- 唯一索引 CREATE UNIQUE INDEX idx_username ON users(username); -- 复合索引 CREATE INDEX idx_name_age ON users(name, age); 查看索引 1 2 3 4 5 -- 查看表的所有索引 SHOW INDEX FROM users; -- 查看索引使用情况 EXPLAIN SELECT * FROM users WHERE email = \u0026#39;john@example.com\u0026#39;; 删除索引 1 DROP INDEX idx_email ON users; 索引的优缺点 优点 1. 提高查询速度 无索引：全表扫描，时间复杂度 O(n) 有索引：B+树查找，时间复杂度 O(log n) 2. 加速排序 1 2 -- 如果name字段有索引，以下查询会很快 SELECT * FROM users ORDER BY name; 3. 提升连接效率 1 2 3 -- 如果user_id有索引，JOIN操作会更快 SELECT * FROM orders o JOIN users u ON o.user_id = u.id; 4. 加速分组 1 2 -- 如果status有索引，GROUP BY会更快 SELECT status, COUNT(*) FROM orders GROUP BY status; 缺点 1. 占用存储空间 索引需要额外的存储空间 复合索引占用空间更大 2. 降低写操作性能 INSERT：需要维护索引结构 UPDATE：可能需要更新索引 DELETE：需要从索引中删除条目 3. 维护成本 数据变更时需要同步更新索引 索引越多，维护成本越高 索引失效的场景 索引失效场景总览 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 graph LR A[\u0026#34;索引失效场景\u0026#34;] --\u0026gt; B[\u0026#34;函数操作\u0026lt;br/\u0026gt;WHERE UPPER(name) = \u0026#39;JOHN\u0026#39;\u0026#34;] A --\u0026gt; C[\u0026#34;类型转换\u0026lt;br/\u0026gt;WHERE phone = 123456\u0026#34;] A --\u0026gt; D[\u0026#34;前导模糊查询\u0026lt;br/\u0026gt;WHERE name LIKE \u0026#39;%john\u0026#39;\u0026#34;] A --\u0026gt; E[\u0026#34;OR连接条件\u0026lt;br/\u0026gt;WHERE name=\u0026#39;john\u0026#39; OR age=25\u0026#34;] A --\u0026gt; F[\u0026#34;非最左匹配\u0026lt;br/\u0026gt;复合索引(name,age,city)\u0026lt;br/\u0026gt;WHERE age=25\u0026#34;] A --\u0026gt; G[\u0026#34;不等于操作\u0026lt;br/\u0026gt;WHERE status != \u0026#39;active\u0026#39;\u0026#34;] A --\u0026gt; H[\u0026#34;NULL值判断\u0026lt;br/\u0026gt;WHERE email IS NULL\u0026#34;] style B fill:#ffcdd2 style C fill:#ffcdd2 style D fill:#ffcdd2 style E fill:#ffcdd2 style F fill:#ffcdd2 style G fill:#ffcdd2 style H fill:#ffcdd2 1. 函数操作 1 2 3 4 5 -- 索引失效 SELECT * FROM users WHERE UPPER(name) = \u0026#39;JOHN\u0026#39;; -- 正确做法 SELECT * FROM users WHERE name = \u0026#39;john\u0026#39;; 2. 类型转换 1 2 3 4 5 -- 索引失效（假设phone是VARCHAR类型） SELECT * FROM users WHERE phone = 12345678901; -- 正确做法 SELECT * FROM users WHERE phone = \u0026#39;12345678901\u0026#39;; 3. 前导模糊查询 1 2 3 4 5 -- 索引失效 SELECT * FROM users WHERE name LIKE \u0026#39;%john\u0026#39;; -- 可以使用索引 SELECT * FROM users WHERE name LIKE \u0026#39;john%\u0026#39;; 4. OR连接的条件 1 2 3 4 5 6 7 -- 如果age没有索引，整个查询无法使用索引 SELECT * FROM users WHERE name = \u0026#39;john\u0026#39; OR age = 25; -- 改写为UNION（如果两个字段都有索引） SELECT * FROM users WHERE name = \u0026#39;john\u0026#39; UNION SELECT * FROM users WHERE age = 25; 5. 复合索引的非最左匹配 1 2 3 4 5 6 7 8 9 -- 假设有复合索引 (name, age, city) -- 可以使用索引 SELECT * FROM users WHERE name = \u0026#39;john\u0026#39;; SELECT * FROM users WHERE name = \u0026#39;john\u0026#39; AND age = 25; -- 索引失效 SELECT * FROM users WHERE age = 25; SELECT * FROM users WHERE city = \u0026#39;beijing\u0026#39;; 6. 不等于操作 1 2 3 4 5 -- 可能导致索引失效 SELECT * FROM users WHERE status != \u0026#39;active\u0026#39;; -- 建议改写 SELECT * FROM users WHERE status IN (\u0026#39;inactive\u0026#39;, \u0026#39;deleted\u0026#39;); 7. NULL值判断 1 2 3 -- 索引效果有限 SELECT * FROM users WHERE email IS NULL; SELECT * FROM users WHERE email IS NOT NULL; 索引优化实践 1. 选择合适的字段创建索引 高选择性字段 1 2 3 4 5 -- 好的选择：用户邮箱（几乎唯一） CREATE INDEX idx_email ON users(email); -- 差的选择：性别字段（只有几个值） -- 不建议：CREATE INDEX idx_gender ON users(gender); 经常用于查询条件的字段 1 2 3 4 5 -- 经常用于WHERE子句 CREATE INDEX idx_status ON orders(status); -- 经常用于JOIN CREATE INDEX idx_user_id ON orders(user_id); 2. 复合索引设计原则 最左前缀原则 1 2 3 4 5 6 7 8 9 -- 索引：(name, age, city) -- 可以使用索引的查询： SELECT * FROM users WHERE name = \u0026#39;john\u0026#39;; -- ✓ SELECT * FROM users WHERE name = \u0026#39;john\u0026#39; AND age = 25; -- ✓ SELECT * FROM users WHERE name = \u0026#39;john\u0026#39; AND city = \u0026#39;bj\u0026#39;; -- ✓（但不是最优） -- 不能使用索引的查询： SELECT * FROM users WHERE age = 25; -- ✗ SELECT * FROM users WHERE city = \u0026#39;beijing\u0026#39;; -- ✗ 字段顺序优化 1 2 3 4 -- 原则：选择性高的字段放前面，经常一起查询的字段放一起 -- 假设查询：WHERE status = \u0026#39;active\u0026#39; AND created_at \u0026gt; \u0026#39;2023-01-01\u0026#39; -- 如果status选择性更高： CREATE INDEX idx_status_created ON orders(status, created_at); 3. 覆盖索引优化 1 2 3 4 5 6 -- 普通查询：需要回表 CREATE INDEX idx_user_id ON orders(user_id); SELECT order_id, total_amount FROM orders WHERE user_id = 123; -- 覆盖索引：无需回表 CREATE INDEX idx_user_id_cover ON orders(user_id, order_id, total_amount); 4. 分页查询优化 1 2 3 4 5 6 7 8 -- 深分页问题 SELECT * FROM users ORDER BY created_at LIMIT 100000, 20; -- 优化方案：使用索引字段 SELECT * FROM users WHERE created_at \u0026gt; \u0026#39;2023-01-01 10:30:00\u0026#39; ORDER BY created_at LIMIT 20; 5. 索引监控和维护 查看索引使用情况 1 2 3 4 5 -- MySQL SELECT * FROM sys.schema_unused_indexes; -- 查看索引统计 SHOW INDEX FROM users; 定期重建索引 1 2 3 4 5 -- 重建索引（MySQL） ALTER TABLE users DROP INDEX idx_email, ADD INDEX idx_email(email); -- 或者 OPTIMIZE TABLE users; 实际案例分析 案例1：慢查询优化 问题查询：\n1 2 3 4 SELECT * FROM orders WHERE status = \u0026#39;pending\u0026#39; AND created_at \u0026gt;= \u0026#39;2023-01-01\u0026#39; AND user_id IN (1,2,3,4,5); 分析过程：\n使用 EXPLAIN 分析执行计划 发现全表扫描，耗时很长 分析查询条件的选择性 优化方案：\n1 2 3 4 5 -- 创建复合索引 CREATE INDEX idx_status_created_user ON orders(status, created_at, user_id); -- 或者根据实际查询模式创建 CREATE INDEX idx_user_status_created ON orders(user_id, status, created_at); 案例2：复合索引设计 业务场景：\n用户表经常按地区、年龄、状态查询 查询模式分析： WHERE region = \u0026lsquo;beijing\u0026rsquo; WHERE region = \u0026lsquo;beijing\u0026rsquo; AND age BETWEEN 20 AND 30 WHERE region = \u0026lsquo;beijing\u0026rsquo; AND status = \u0026lsquo;active\u0026rsquo; 索引设计：\n1 2 3 4 5 6 -- 方案1：按查询频率和选择性 CREATE INDEX idx_region_age_status ON users(region, age, status); -- 方案2：如果经常只按region和status查询 CREATE INDEX idx_region_status ON users(region, status); CREATE INDEX idx_region_age ON users(region, age); 总结 核心要点 索引本质：用空间换时间的数据结构，类似书籍目录 主要原理：B+树结构，减少磁盘I/O，提高查询效率 使用场景：频繁查询、排序、连接的字段 设计原则： 选择性高的字段 遵循最左前缀原则 考虑覆盖索引 避免过多索引 最佳实践清单 为经常出现在WHERE子句的字段创建索引 为经常用于JOIN的字段创建索引 复合索引遵循最左前缀原则 避免在索引字段上使用函数 定期监控和优化索引使用情况 平衡查询性能和存储空间 考虑业务场景，不要盲目创建索引 记住这句话 索引不是万能的，但没有索引是万万不能的。合理使用索引，让你的数据库查询飞起来！\n这份指南涵盖了数据库索引的方方面面，建议结合实际项目练习，加深理解。\n","date":"2025-07-03T00:00:00Z","image":"https://nova-bryan.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/image_hu17089168107649188491.png","permalink":"https://nova-bryan.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/","title":"数据库索引完全指南"},{"content":"一、常见集合篇 1. 为什么数组索引从0开始呢？假如从1开始不行咩 数组（Array）：一种用连续的内存空间存储相同数据类型数据的线性数据结构\n（1）在根据数组索引获取元素的时候，会用索引和寻址公式来计算内存所对应的元素数据，寻址公式是:数组的首地址+索引乘以存储数据的类型大小\n（2）如果数组的索引从1开始，寻址公式中，就需要增加一次减法操作，对于CPU来说就多了一次指令，性能不高。\n复杂度\n随机(通过下标)查询的时间复杂度是O(1)\n查找元素(未知下标)的时间复杂度是O(n)\n查找元素(未知下标但排序)通过二分查找的时间复杂度是O(logn)\n插入和删除的时候，为了保证数组的内存连续性，需要挪动数组元素，平均时间复杂度为O(n)\n2. ArrayList源码分析 ArrayList底层是用动态的数组实现的\n初始容量 ArrayList初始容量为0，当第一次添加数据的时候才会初始化容量为10\n扩容逻辑 ArrayList在进行扩容的时候是原来容量的1.5倍，每次扩容都需要拷贝数组\n添加逻辑 确保数组已使用长度（size）加1之后足够存下下一个数据 计算数组的容量，如果当前数组已使用长度+1后的大于当前的数组长度，则调用grow方法扩容（原来的1.5倍） 确保新增的数据有地方存储之后，则将新元素添加到位于size的位置上。 返回添加成功布尔值。 3. ArrayList list=new ArrayList(10)中的list扩容几次 该语句只是声明和实例了一个 ArrayList，指定了容量为 10，未扩容\n4. 如何实现数组和List之间的转换 数组转List ，使用JDK中java.util.Arrays工具类的asList方法 List转数组，使用List的toArray方法。无参toArray方法返回 Object数组，传入初始化长度的数组对象，返回该对象数组 用Arrays.asList转List后，如果修改了数组内容，list受影响吗 会受影响\n当你使用 Arrays.asList 方法将数组转换为 List 时，Arrays.asList 返回的 List 实际上是 Arrays 类的一个内部类 ArrayList 的实例。这个内部类并没有创建一个新的、独立的列表来存储数组元素，而是直接对传入的数组进行了包装。也就是说，这个 List 内部维护的是对原始数组的引用，它们指向的是同一块内存地址。\nList用toArray转数组后，如果修改了List内容，数组受影响吗 使用无参的 toArray 方法：这种情况下，返回的是一个 Object 类型的数组。toArray 方法会创建一个新的数组，并将 List 中的元素复制到这个新数组中。但是，这里复制的是元素的引用（对于引用类型），而不是元素本身。所以，如果 List 中的元素是可变对象，修改 List 中对象的属性会影响到数组中的对应对象；如果只是改变 List 中元素的引用（比如替换某个元素），则不会影响数组。 当传入一个指定类型的数组时，如果该数组长度足够，List 元素会直接填充到这个数组中；如果长度不够，会创建一个新的同类型数组。同样，对于引用类型的元素，复制的是引用，修改元素属性会相互影响，修改引用则不会。 5. ArrayList和LinkedList的区别是什么？ 底层数据结构 ArrayList 是动态数组的数据结构实现 LinkedList 是双向链表的数据结构实现 操作数据效率 ArrayList按照下标查询的时间复杂度O(1)【内存是连续的，根据寻址公式】， LinkedList不支持下标查询 查找（未知索引）： ArrayList需要遍历，链表也需要遍历，时间复杂度都是O(n) 新增和删除 ArrayList尾部插入和删除，时间复杂度是O(1)；其他部分增删需要挪动数组，时间复杂度是O(n) LinkedList头尾节点增删时间复杂度是O(1)，其他都需要遍历链表，时间复杂度是O(n) 内存空间占用 ArrayList底层是数组，内存连续，节省内存 LinkedList 是双向链表需要存储数据，和两个指针，更占用内存 线程安全 ArrayList和LinkedList都不是线程安全的 如果需要保证线程安全，有两种方案： 在方法内使用，由于每个线程都有自己独立的栈空间，局部变量在不同线程之间是隔离的，因此是线程安全的。 使用线程安全的替代类：可以使用线程安全的 ArrayList 和 LinkedList 替代类，例如 Vector （类似于线程安全的 ArrayList），或者使用 Collections.synchronizedList 方法将 ArrayList 或 LinkedList 包装成线程安全的列表。 6. 二叉树 每个节点最多有两个“叉”，也就是两个子节点，分别是左子节点和右子节点。不过，二叉树并不要求每个节点都有两个子节点，有的节点只有左子节点，有的节点只有右子节点。\n二叉树每个节点的左子树和右子树也分别满足二叉树的定义。\n二叉搜索树 二叉搜索树(Binary Search Tree,BST)又名二叉查找树，有序二叉树或者排序二叉树，是二叉树中比较常用的一种类型\n二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值\n插入，查找，删除的时间复杂度O(logn)，极端情况下二叉查找树已经退化成了链表，二叉搜索的时间复杂度O(n)\n红黑树 （1）红黑树的特质\n性质1：节点要么是红色,要么是黑色\n性质2：根节点是黑色\n性质3：叶子节点都是黑色的空节点\n性质4：红黑树中红色节点的子节点都是黑色\n性质5：从任一节点到叶子节点的所有路径都包含相同数目的黑色节点\n在添加或删除节点的时候，如果不符合这些性质会发生旋转，以达到所有的性质，保证红黑树的平衡\n（2）红黑树的复杂度\n查找： 红黑树也是一棵BST（二叉搜索树）树，查找操作的时间复杂度为：O(log n) 添加： 添加先要从根节点开始找到元素添加的位置，时间复杂度O(log n) 添加完成后涉及到复杂度为O(1)的旋转调整操作 故整体复杂度为：O(log n) 删除： 首先从根节点开始找到被删除元素的位置，时间复杂度O(log n) 删除完成后涉及到复杂度为O(1)的旋转调整操作 故整体复杂度为：O(log n) 7. 散列表 根据键（Key）直接访问在内存存储位置值（Value）的数据结构，它是由数组演化而来的，利用了数组支持按照下标进行随机访问数据的特性。\n散列函数 将键(key)映射为数组下标的函数叫做散列函数。可以表示为：hashValue = hash(key)\n散列函数的基本要求\n散列函数计算得到的散列值必须是大于等于0的正整数，因为hashValue需要作为数组的下标。 如果key1==key2，那么经过hash后得到的哈希值也必相同即：hash(key1) == hash(key2） 如果key1 != key2，那么经过hash后得到的哈希值也必不相同即：hash(key1) != hash(key2) 散列冲突 或者哈希冲突，哈希碰撞，指多个key映射到同一个数组下标位置\n散列冲突-链表法（拉链） 在散列表中，数组的每个下标位置我们可以称之为桶（bucket）或者槽（slot），每个桶(槽)会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。\n简单就是，如果有多个key最终的hash值是一样的，就会存入数组的同一个下标中，下标中挂一个链表存入多个数据\n时间复杂度\n平均情况下基于链表法解决冲突时查询的时间复杂度是O(1)\n散列表可能会退化为链表,查询的时间复杂度就从 O(1) 退化为 O(n)\n将链表法中的链表改造为其他高效的动态数据结构，比如红黑树，查询的时间复杂度是 O(logn)\n将链表法中的链表改造红黑树还有一个非常重要的原因，可以防止DDos攻击\nDDos 攻击:\n分布式拒绝服务攻击(英文意思是Distributed Denial of Service，简称DDoS）\n指处于不同位置的多个攻击者同时向一个或数个目标发动攻击，或者一个攻击者控制了位于不同位置的多台机器并利用这些机器对受害者同时实施攻击。由于攻击的发出点是分布在不同地方的，这类攻击称为分布式拒绝服务攻击，其中的攻击者可以有多个\n8. 说一下HashMap的实现原理？ HashMap的数据结构： 底层使用hash表数据结构，即数组和链表或红黑树\n当我们往HashMap中put元素时，利用key的hashCode重新hash计算出当前对象的元素在数组中的下标 存储时，如果出现hash值相同的key，此时有两种情况。 a. 如果key相同，则覆盖原始值；\nb. 如果key不同（出现冲突），则将当前的key-value放入链表或红黑树中\n获取时，直接找到hash值对应的下标，在进一步判断key是否相同，从而找到对应值。 HashMap 底层采用哈希表，结合了数组、链表和红黑树。数组是主体结构，每个数组元素是一个桶。当发生哈希冲突时，会用链表或红黑树来存储冲突元素。正常情况下用链表存储，若链表长度超过 8 且数组长度大于 64，链表就会转成红黑树，因为链表过长时，查找元素的时间复杂度会变成 O (n)，而红黑树能将查找、插入和删除操作的时间复杂度控制在 O (log n)。当红黑树节点数量少于 6 时，又会转回链表。以此提升查找效率。\n9. HashMap的jdk1.7和jdk1.8有什么区别 JDK1.8之前采用的是拉链法。拉链法：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。 jdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8） 时并且数组长度达到64时，将链表转化为红黑树，以减少搜索时间。扩容 resize( ) 时，红黑树拆分成的树的结点数小于等于临界值6个，则退化成链表 10. HashMap的put方法的具体流程 判断键值对数组table是否为空或为null，否则执行resize()进行扩容（初始化）\n根据键值key计算hash值得到数组索引\n判断table[i]==null，条件成立，直接新建节点添加\n如果table[i]==null ,不成立\n4.1 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value\n4.2 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对\n4.3 遍历table[i]，链表的尾部插入数据，然后判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操 作，遍历过程中若发现key已经存在直接覆盖value\n插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold（数组长度*0.75），如果超过，进行扩容。\n11. 讲一讲HashMap的扩容机制 HashMap 的扩容机制是为了保证其性能，避免哈希冲突过多导致查询和插入效率下降。当元素数量达到扩容阈值（数组长度 * 负载因子，默认负载因子是 0.75）时，就会触发扩容操作。\n在添加元素或初始化的时候需要调用resize方法进行扩容，第一次添加数据初始化数组长度为16，以后每次每次扩容都是达到了扩容阈值（数组长度 * 0.75） 每次扩容的时候，都是扩容之前容量的2倍； 扩容之后，会新创建一个数组，需要把老数组中的数据挪动到新的数组中 无哈希冲突的节点：则直接使用 e.hash \u0026amp; (newCap - 1) 计算新数组的索引位置 红黑树节点：按照红黑树的规则将节点添加到新数组对应的位置。红黑树是自平衡二叉搜索树，添加节点时会进行旋转和变色等操作来保持平衡。 **链表节点：**需要遍历链表，可能会拆分链表。通过e.hash \u0026amp; oldCap判断元素在新数组中的位置： 若结果为 0，说明该元素在新数组中的索引位置和原数组相同。因为扩容后多考虑的那一位二进制为 0，对索引计算结果无影响。 若结果不为 0，该元素在新数组中的索引位置是原数组中的索引位置加上 oldCap。这是因为扩容后多考虑的那一位二进制为 1，使得索引结果增加了原数组的长度。 12. hashMap的寻址算法 首先获取key的hashCode值，然后z再调用hash()方法进行二次哈希，右移16位 异或运算 原来的hashCode值，主要作用就是使原来的hash值更加均匀，减少hash冲突\n最后（capacity-1）\u0026amp; hash得到索引\n13. 关于hash值的其他面试题：为何HashMap的数组长度一定是2的次幂？ 计算索引时效率更高：如果是 2 的 n 次幂可以使用位与运算代替取模 扩容时重新计算索引效率更高： hash \u0026amp; oldCap == 0 的元素留在原来位置 ，否则新位置 = 旧位置 + oldCap 14. hashmap在1.7情况下的多线程死循环问题 在 JDK 1.7 里，HashMap 扩容时把旧数组的数据迁移到新数组，链表采用的是头插法。\n假设有两个线程同时操作 HashMap 的扩容。\n线程一读取数据准备扩容：线程一读取当前 HashMap 的数据，发现有一个链表，准备对数组进行扩容。可就在这时候，线程二介入了。 线程二完成扩容：线程二也读取了 HashMap 的数据，然后直接开始扩容。因为用的是头插法，扩容后链表的顺序就颠倒了。打个比方，原来链表顺序是 A -\u0026gt; B，扩容后就变成 B -\u0026gt; A 了，之后线程二执行结束。 线程一继续扩容引发死循环：线程一接着干活，先把 A 移到新链表，再把 B 插到新链表的头部。但由于线程二已经把链表顺序颠倒了，B 的 next 指针指向了 A。这样一来，新链表就变成 B -\u0026gt; A -\u0026gt; B，形成了一个循环。之后要是有线程去访问这个链表，就会一直在这个循环里出不来，也就是出现了死循环问题。 JDK 8 对扩容算法做了调整，链表数据迁移时用的是尾插法，就是新元素会被插到链表的尾部。这样扩容后链表元素的顺序和扩容前是一样的，就不会出现因为链表顺序颠倒而导致的死循环问题了。\n总的来说，JDK 1.7 的 HashMap 在多线程扩容时，头插法可能会让链表顺序错乱，进而引发死循环；而 JDK 8 采用尾插法，避免了这个问题，提升了多线程环境下的稳定性。\n关于 HashMap、HashTable、ConcurrentHashMap、TreeMap 和 HashSet 1. 基本概念\nHashMap：基于哈希表实现的 Map 接口，允许 null 键和 null 值，非线程安全，适用于单线程环境下快速查找和存储键值对。 HashTable：古老的 Map 实现类，与 HashMap 类似，但不允许 null 键和 null 值，并且是线程安全的（方法都被 synchronized 修饰），不过性能相对 HashMap 较差，现在已不常用。 ConcurrentHashMap：线程安全的 Map 实现类，采用分段锁（锁分段技术）提高并发性能，允许多个线程同时操作不同的段，适用于高并发环境下的键值对存储和访问。 TreeMap：实现了 SortedMap 接口，基于红黑树实现，会对键进行排序（默认升序，也可自定义比较器），不允许 null 键，值可以为 null，非线程安全，适合需要对键进行有序操作的场景。 HashSet：实现了 Set 接口，基于 HashMap 实现（元素存储在 HashMap 的键中，值为一个默认的 Object 对象），不允许重复元素，允许 null 元素，非线程安全，用于存储不重复的元素集合。 2. 线程安全性\nHashMap 和 HashSet：非线程安全，在多线程环境下可能会出现数据不一致等问题。 HashTable：线程安全，通过 synchronized 保证同一时间只有一个线程能访问其方法。 ConcurrentHashMap：线程安全，采用分段锁技术，提高并发访问性能，允许多个线程同时访问不同的段。 TreeMap：非线程安全，在多线程环境下若有多个线程同时修改，可能会导致数据混乱。 3. 性能特点\n查找、插入和删除操作 HashMap 和 HashSet：在理想情况下，基于哈希表的操作时间复杂度为 O(1)，但在哈希冲突严重时性能会下降。 HashTable：由于线程安全的实现方式（synchronized），在单线程环境下性能比 HashMap 差，操作时间复杂度与 HashMap 类似，但在多线程并发时会有锁竞争。 ConcurrentHashMap：并发性能较好，在高并发环境下，由于分段锁机制，不同段的操作可以并行进行，总体性能优于 HashTable。 TreeMap：基于红黑树，查找、插入和删除操作的时间复杂度为 O(logn)，因为需要维护树的平衡和排序。 4. 键和值的允许情况\nHashMap：键和值都可以为 null，但键的 null 只能有一个。 HashTable：键和值都不允许为 null，否则会抛出 NullPointerException。 ConcurrentHashMap：键和值都不允许为 null，否则会在多线程环境下导致不确定行为。 TreeMap：键不允许为 null（因为需要进行比较和排序），值可以为 null。 HashSet：允许一个 null 元素，不允许重复元素。 5. 排序功能\nHashMap、HashTable 和 HashSet：不具备排序功能，元素的存储顺序与插入顺序无关（HashMap 在 JDK 8 后引入了链表转红黑树机制，在一定程度上会影响元素顺序，但不是真正的排序）。 TreeMap：实现了 SortedMap 接口，会根据键的自然顺序或自定义比较器对键进行排序。 6. 应用场景\nHashMap 和 HashSet：适用于单线程环境下，对元素顺序无要求，只需要快速查找和存储不重复元素的场景，如缓存、数据统计等。 HashTable：由于性能问题，现在很少使用，仅在一些遗留代码或对线程安全有严格要求且性能要求不高的场景中可能会用到。 ConcurrentHashMap：适用于高并发环境下，需要线程安全的 Map 操作，如多线程的计数器、缓存等。 TreeMap：适用于需要对键进行排序，并且按照顺序遍历或查找元素的场景，如按照时间顺序存储和查询日志记录等。 15. HashSet与HashMap的区别 (1)HashSet实现了Set接口, 仅存储对象; HashMap实现了 Map接口, 存储的是键值对.\n(2)HashSet底层其实是用HashMap实现存储的, HashSet封装了一系列HashMap的方法. 依靠HashMap来存储元素值,(利用hashMap的key键进行存储), 而value值默认为Object对象. 所以HashSet也不允许出现重复值, 判断标准和HashMap判断标准相同, 两个元素的hashCode相等并且通过equals()方法返回true.\n16. HashTable与HashMap的区别 嗯，他们的主要区别是有几个吧\n第一，数据结构不一样，hashtable是数组+链表，hashmap在1.8之后改为了数组+链表+红黑树\n第二，hashtable存储数据的时候都不能为null，而hashmap是可以的\n第三，hash算法不同，hashtable是用本地修饰的hashcode值，而hashmap进行了二次hash\n第四，扩容方式不同，hashtable是当前容量翻倍+1，hashmap是当前容量翻倍\n第五，hashtable是线程安全的，操作数据的时候加了锁synchronized，hashmap不是线程安全的，效率更高一些\n在实际开中不建议使用HashTable，在多线程环境下可以使用ConcurrentHashMap类\n17. TreeMap与HashMap的区别 HashMap 和 TreeMap 都继承自 AbstractMap。但 TreeMap 还实现了 NavigableMap 和 SortedMap 接口，这是它与 HashMap 的主要区别。\nTreeMap 实现 NavigableMap 接口后：\n能定向搜索，像 ceilingEntry() 找大于等于键的最近元素，floorEntry() 找小于等于键的最近元素等。 可进行子集操作，如 submap()、headMap()、tailMap() 来获取子集视图，不复制全集合。 有逆序视图，descendingMap() 能反向迭代集合。 方便边界操作，firstEntry() 取首元素，lastEntry() 取尾元素，pollFirstEntry() 和 pollLastEntry() 取并移除首、尾元素。 这些基于红黑树实现，搜索时间复杂度 O(logn)。 实现 SortedMap 接口后，TreeMap 能按键排序，默认升序，也能自定义比较器。\n而 HashMap 基于哈希表，侧重快速键值对操作，无上述顺序相关功能，理想时操作时间复杂度 O(1)。\n18. ConcurrentHashMap 与 Hashtable 的区别 线程安全实现方式 Hashtable： 实现方式：使用 synchronized 方法来保证线程安全。 特点：所有操作（如 put、get）都是同步的，这意味着同一时间只有一个线程可以访问整个哈希表。 缺点：效率较低，尤其是在高并发场景下，因为所有线程都会竞争同一把锁，导致其他线程阻塞，性能下降。 ConcurrentHashMap： JDK 1.7： 实现方式：使用分段锁（Segment）来实现线程安全。 特点：将哈希表分成多个段（Segment），每个段是一个独立的锁。不同段的数据可以被不同线程并发访问，大大提高了并发性能。 优点：减少了锁竞争，提高了并发访问率。 JDK 1.8： 实现方式：取消了 Segment 的概念，改为使用 Node 数组 + 链表 + 红黑树的数据结构。 特点：使用 synchronized 和 CAS（Compare-And-Swap）操作来保证线程安全。锁粒度更细，synchronized 只锁定当前链表或红黑树的首节点。 优点：进一步减少了锁竞争，提高了并发性能。链表长度超过一定阈值时，链表会转换为红黑树，优化了查找性能。 底层数据结构 Hashtable： 数据结构：数组 + 链表。 特点：数组是哈希表的主体，链表用于解决哈希冲突。 缺点：在高并发场景下，所有操作都需要竞争同一把锁，导致性能瓶颈。 ConcurrentHashMap： JDK 1.7： 数据结构：Segment 数组 + HashEntry 数组 + 链表。 特点：每个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素。通过分段锁机制，不同段的数据可以被不同线程并发访问。 JDK 1.8： 数据结构：Node 数组 + 链表 + 红黑树。 特点：当链表长度超过一定阈值（默认为 8）时，链表会转换为红黑树，以优化查找性能。使用 synchronized 和 CAS 操作来保证线程安全，锁粒度更细。 并发度 Hashtable： 并发度：最大并发度为 1，因为所有操作都同步在同一个锁上。 特点：在高并发场景下，性能较差，因为所有线程都会竞争同一把锁。 ConcurrentHashMap： JDK 1.7： 并发度：最大并发度为 Segment 数组的大小，默认是 16。 特点：通过分段锁机制，不同段的数据可以被不同线程并发访问，提高了并发性能。 JDK 1.8： 并发度：最大并发度为 Node 数组的大小，通常比 JDK 1.7 更高。 特点：锁粒度更细，减少了锁竞争，进一步提高了并发性能。 19. JDK 1.7 和 JDK 1.8 的 ConcurrentHashMap 实现差异 线程安全实现方式 JDK 1.7： 实现方式：使用分段锁（Segment）来实现线程安全。 特点：每个 Segment 是一个独立的锁，不同 Segment 的数据可以被不同线程并发访问，减少了锁竞争。 JDK 1.8： 实现方式：取消了 Segment 的概念，改为使用 Node 数组 + 链表 + 红黑树。 特点：使用 synchronized 和 CAS 操作来保证线程安全，锁粒度更细，synchronized 只锁定当前链表或红黑树的首节点，进一步减少了锁竞争。 底层数据结构 JDK 1.7： 数据结构：Segment 数组 + HashEntry 数组 + 链表。 特点：每个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素。通过分段锁机制，不同段的数据可以被不同线程并发访问。 JDK 1.8： 数据结构：Node 数组 + 链表 + 红黑树。 特点：当链表长度超过一定阈值（默认为 8）时，链表会转换为红黑树，以优化查找性能。使用 synchronized 和 CAS 操作来保证线程安全，锁粒度更细。 性能优化 JDK 1.7： 优化：通过分段锁机制，减少了锁竞争，提高了并发性能。 JDK 1.8： 优化：锁粒度更细，进一步减少了锁竞争。链表转换为红黑树，优化了查找性能，特别是在高冲突情况下。 20. 为什么 ConcurrentHashMap 的 key 和 value 不能为 null 在 Java 集合框架中，ConcurrentHashMap是线程安全的哈希表实现，其设计上不允许key和value为null。\n1. 避免二义性\nnull作为一种特殊值，代表没有对象或引用。在ConcurrentHashMap中，若允许null作为key，将无法区分该key是实际存在于ConcurrentHashMap中且值为null，还是根本不存在此key。同理，对于value，也难以判断返回的null是真实存储的值，还是因未找到对应key而产生的结果。例如get方法返回null时，存在值不在集合中以及值本身为null这两种可能，这就是所谓的二义性。\n2. 多线程环境的复杂性\n在多线程环境下，当一个线程操作ConcurrentHashMap时，其他线程可能同时对其进行修改。这种情况下，无法依赖containsKey(key)方法来准确判断键值对是否存在。因为在调用containsKey方法之后，到依据该结果进行后续操作之前的这段时间内，ConcurrentHashMap可能已被其他线程修改，从而导致判断失误，使得二义性问题无法得到有效解决。\n3. 与 HashMap 对比\nHashMap则有所不同，它允许null作为key和value。其中null作为key只能有一个，null作为value可以有多个。在单线程环境中，由于不存在其他线程同时修改HashMap的情况，所以可以通过containsKey(key)方法准确判断键值对是否存在，进而做出相应处理，不会出现二义性问题。\n21. comparable 和 Comparator 的区别 接口来源和定义 comparable：接口出自java.lang包，它有一个compareTo(Object obj)方法用于排序。实现了Comparable接口的类，意味着该类的对象具有自然排序的能力。例如，String类、Integer类等都实现了Comparable接口，它们的对象可以直接进行比较和排序。 Comparator：接口出自java.util包，它有一个compare(Object obj1, Object obj2)方法用于排序。Comparator接口用于定义一种外部比较规则，当一个类没有实现Comparable接口，或者需要使用与自然排序不同的排序规则时，可以使用Comparator接口。 使用场景 comparable：一般用于对一个集合中的元素进行统一的自然排序。比如，要对一个ArrayList\u0026lt;Integer\u0026gt;进行升序排序，由于Integer类实现了Comparable接口，直接调用Collections.sort()方法即可按照自然顺序（升序）对列表中的元素进行排序。 Comparator：当需要对某一个集合实现自定义排序方式，或者需要对一个集合实现多种排序方式时使用。例如，有一个Song类，需要对其对象根据歌名和歌手名分别采用不同的排序方式，此时可以通过实现Comparator接口来定义不同的比较规则。可以创建两个不同的Comparator实现类，一个用于按歌名排序，一个用于按歌手名排序，然后在调用Collections.sort()方法时传入相应的Comparator实例来实现不同的排序需求。 二、多线程篇 1. 线程和进程的区别？ 进程：程序由指令和数据组成，但这些指令要运行，数据要读写，就必须将指令加载至 CPU，数据加载至内存。在指令运行过程中还需要用到磁盘、网络等设备。进程就是用来加载指令、管理内存、管理 IO 的。当一个程序被运行，从磁盘加载这个程序的代码至内存，这时就开启了一个进程。\n线程：一个进程之内可以分为一到多个线程。一个线程就是一个指令流，将指令流中的一条条指令以一定的顺序交给 CPU 执行\n二者对比\n（1）进程是正在运行程序的实例，进程中包含了线程，每个线程执行不同的任务\n（2）不同的进程使用不同的内存空间，在当前进程下的所有线程可以共享内存空间\n（3）线程更轻量，线程上下文切换成本一般上要比进程上下文切换低(上下文切换指的是从一个线程切换到另一个线程)\n2. 并行和并发有什么区别？ 现在都是多核CPU，在多核CPU下\n并发是同一时间应对多件事情的能力，多个线程轮流使用一个或多个CPU，每个线程在不同的时间片内获得 CPU 资源来执行任务。\n并行是同一时间动手做多件事情的能力，例如，一个 4 核 CPU 可以同时执行 4 个线程，每个线程在一个独立的 CPU 核心上运行，这些线程的执行是完全并行的，不会相互等待 CPU 资源。\n3. 创建线程的四种方式 在java中一共有四种常见的创建方式，分别是：继承Thread类、实现runnable接口、实现Callable接口、线程池创建线程。通常情况下，我们项目中都会采用线程池的方式创建线程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class MyExecutors implements Runnable{ @Override public void run() { System.out.println(\u0026#34;MyRunnable...run...\u0026#34;); } public static void main(String[] args) { // 创建线程池对象 ExecutorService threadPool = Executors.newFixedThreadPool(3); threadPool.submit(new MyExecutors()) ; // 关闭线程池 threadPool.shutdown(); } } 4. runnable 和 callable 有什么区别 Runnable 接口run方法没有返回值；Callable接口call方法有返回值，是个泛型，和Future、FutureTask配合可以用来获取异步执行的结果 Callalbe接口支持返回执行结果，需要调用FutureTask.get()得到，此方法会阻塞主进程的继续往下执行，如果不调用不会阻塞。 Callable接口的call()方法允许抛出异常；而Runnable接口的run()方法的异常只能在内部消化，不能继续上抛 5. 线程的 run()和 start()有什么区别？ start(): 用来启动线程，通过该线程调用run方法执行run方法中所定义的逻辑代码。start方法只能被调用一次。\nrun(): 封装了要被线程执行的代码，可以被调用多次。\n6. 线程包括哪些状态，状态之间是如何变化的 在JDK中的Thread类中的枚举State里面定义了6种线程的状态分别是：新建、可运行、终结、阻塞、等待和有时限等待六种。\n关于线程的状态切换情况比较多。我分别介绍一下\n当一个线程对象被创建，但还未调用 start 方法时处于新建状态，此时，线程仅仅是在 Java 堆中分配了内存，操作系统还没有为其分配任何资源，线程尚未启动。调用了 start 方法，就会由新建进入可运行状态。如果线程内代码已经执行完毕，由可运行进入终结状态。当然这些是一个线程正常执行情况。\n当线程在获取对象的锁时，如果该锁已经被其他线程持有，线程会进入阻塞状态。线程会被放入该对象的 Monitor 阻塞队列中等待。只有当持锁线程释放锁时，会按照一定规则唤醒阻塞队列中的阻塞线程，唤醒后的线程进入可运行状态\n如果线程获取锁成功后，但由于条件不满足，调用了 wait() 方法，线程会释放当前持有的锁，并进入等待状态。当其它持锁线程调用 notify() 或 notifyAll() 方法，会恢复为可运行状态，等待获取锁并继续执行。\n还有一种情况是调用 sleep(long) 方法也会从可运行状态进入有时限等待状态，不需要主动唤醒，超时时间到自然恢复为可运行状态。\n7. 新建 T1、T2、T3 三个线程，如何保证它们按顺序执行？ 嗯~~，我思考一下 （适当的思考或想一下属于正常情况，脱口而出反而太假[背诵痕迹]）\n可以这么做，在多线程中有多种方法让线程按特定顺序执行，可以用线程类的join()方法在一个线程中启动另一个线程，另外一个线程完成该线程继续执行。\n比如说：\n使用join方法，T3调用T2，T2调用T1，这样就能确保T1就会先完成而T3最后完成\n8. notify()和 notifyAll()有什么区别？ notifyAll：唤醒所有wait的线程\nnotify：只随机唤醒一个 wait 线程\n9. 在 java 中 wait 和 sleep 方法的不同？ 共同点\nwait() ，wait(long) 和 sleep(long) 的效果都是让当前线程暂时放弃 CPU 的使用权，进入阻塞状态\n这三个方法都可以被其他线程通过调用 interrupt() 方法打断唤醒，此时会抛出 InterruptedException 异常，需要在代码中进行捕获和处理。\n不同点\n方法归属不同 sleep(long) 是 Thread 的静态方法 而 wait()，wait(long) 都是 Object类的成员方法，每个对象都有 醒来时机不同 执行 sleep(long) 和 wait(long) 的线程都会在等待相应毫秒后醒来 wait(long) 和 wait() 还可以被 notify 唤醒，wait() 如果不唤醒就一直等下去 它们都可以被打断唤醒 锁特性不同（重点） wait 方法的调用必须先获取 wait 对象的锁，也就是说 wait 方法必须在 synchronized 代码块或方法中使用。而 sleep 方法则没有这个限制，可以在任何地方调用。 wait 方法执行后会释放对象锁，允许其它线程获得该对象锁（我放弃 cpu，但你们还可以用） 而 sleep 如果在 synchronized 代码块中执行，并不会释放对象锁（我放弃 cpu，你们也用不了） 10. 如何停止一个正在运行的线程？ 有三种方式可以停止线程\n​\t使用退出标志，使线程正常退出，也就是当run方法完成后线程终止\n​\t使用stop方法强行终止（不推荐，方法已作废）\n​\t使用interrupt方法中断线程\n11. 讲一下synchronized关键字的底层原理？ synchronized 翻译成中文是同步的的意思，主要解决的是多个线程之间访问资源的同步性，可以保 证被它修饰的⽅法或者代码块在任意时刻只能有⼀个线程执行。\nsynchronized 属于悲观锁。底层使用的JVM级别中的Monitor 来决定当前线程是否获得了锁，如果某一个线程获得了锁，在没有释放锁之前，其他线程是不能或得到锁的。\nsynchronized 因为需要依赖于JVM级别的Monitor ，相对性能也比较低。\nMonitor 对象存在于每个 Java 对象的对象头中，所以每个 Java 对象都可以作为锁 。对象头是 Java 对象在内存中的一部分，用于存储对象的一些元数据信息，如哈希码、分代年龄等，同时也包含了指向 Monitor 的指针。当一个线程尝试获取某个对象的锁时，实际上就是在尝试获取该对象对应的 Monitor。\nmonitor内部维护了三个变量\nWaitSet：保存处于Waiting状态的线程，当一个线程在持有锁的情况下调用了对象的 wait() 方法，它会释放当前持有的锁，并进入 WaitSet 中等待。只有当其他线程调用了该对象的 notify() 或 notifyAll() 方法时，WaitSet 中的线程才有可能被唤醒，重新参与锁的竞争。 EntryList：保存处于Blocked状态的线程，当一个线程尝试获取已经被其他线程持有的锁时，它会被放入 EntryList 中进行阻塞等待。这些线程会在持有锁的线程释放锁后，被唤醒并参与锁的竞争。 Owner：用于记录当前持有锁的线程。当一个线程成功获取到 Monitor 时，Monitor 中的 Owner 会被设置为该线程，表示该线程成为了锁的持有者。 只有一个线程获取到的标志就是在monitor中设置成功了Owner，一个monitor中只能有一个Owner\n在上锁的过程中，如果有其他线程也来抢锁，则进入EntryList 进行阻塞，当获得锁的线程执行完了，释放了锁，就会唤醒EntryList 中等待的线程竞争锁，竞争的时候是非公平的。\n12. 讲一下synchronized关键字的使用方式？ 在 Java 里，synchronized 关键字主要有三种使用方式，目的是实现线程间的同步，保证同一时刻只有一个线程能访问被保护的代码或资源。\n修饰实例方法：给当前对象实例加锁。当一个线程调用该实例方法时，在进入同步代码之前，必须先获取这个对象实例的锁。只有获得锁后，线程才能执行方法里的代码；如果锁被其他线程占用，当前线程就会被阻塞，直到锁被释放。 修饰静态方法：给当前类加锁，这个锁会作用于类的所有对象实例。由于静态成员归整个类所有，被类的所有实例共享，所以进入同步代码前要获取当前 class 的锁。要注意，静态 synchronized 方法和非静态 synchronized 方法之间的调用不会互斥。比如线程 A 调用一个实例对象的非静态 synchronized 方法，同时线程 B 调用这个实例对象所属类的静态 synchronized 方法，这种情况是允许的，因为它们占用的锁不同，前者是当前实例对象锁，后者是当前类的锁。 **修饰代码块：**对括号里指定的对象或类加锁。 synchronized(object)：表示在进入同步代码块之前，需要获得给定对象的锁。只有拿到这个对象的锁，线程才能执行代码块中的内容。 synchronized(类.class)：意味着进入同步代码前要获得给定 Class 的锁。这种方式和修饰静态方法类似，都是对类进行加锁。 12. Monitor实现的锁属于重量级锁，你了解过锁升级吗？ Java中的synchronized有偏向锁、轻量级锁、重量级锁三种形式，分别对应了锁只被一个线程持有、不同线程交替持有锁、多线程竞争锁三种情况。\n偏向锁 偏向锁适用于在很长一段时间内都只有一个线程使用锁的场景。当一个线程第一次获取锁时，会通过 CAS 操作把自己的线程 ID 记录在对象头的 mark word 里。之后这个线程再次获取这把锁时，只需检查 mark word 中的线程 ID 是不是自己的，是的话就能直接获取锁，避免了频繁 CAS 操作的开销。\n轻量级锁 轻量级锁适用于不同线程交替持有锁，也就是线程加锁时间错开、没有锁竞争的情况。线程尝试获取轻量级锁时，会先在自己的栈帧中创建一个锁记录，然后用 CAS 操作把对象头的 mark word 复制到锁记录里，并让对象头指向锁记录。如果操作成功，就获取到了轻量级锁；如果失败，就自旋等待。轻量级锁主要通过修改对象头的锁标志实现，避免了用户态和内核态的切换，性能比重量级锁好很多。这就像两个人交替用一个房间，一个人来的时候在自己本子上记房间信息，把门口牌子指向自己本子，另一个人来发现牌子指向别人本子就等一会儿。\n重量级锁 重量级锁适用于多线程竞争锁的场景。它底层用 Monitor 实现，当线程竞争锁失败时会被阻塞，进入等待队列。这涉及到用户态和内核态的切换、进程的上下文切换，成本高，性能低。就像很多人同时抢一个房间，门口有管理员管理，竞争不到的人要去等待区，等房间空了管理员再叫人进来，这个过程很麻烦，效率低。\n锁升级机制 锁的状态会根据竞争情况升级，一旦出现竞争，会按照偏向锁 -\u0026gt; 轻量级锁 -\u0026gt; 重量级锁的顺序升级，而且锁升级是单向的，升为重量级锁后就不会再降级。\n13. 你谈谈 JMM（Java 内存模型） Java内存模型是Java虚拟机规范中定义的一种非常重要的内存模型。它的主要作用是描述Java程序中线程共享变量的访问规则，以及这些变量在JVM中是如何被存储和读取的，这些规则保证了多线程环境下数据的一致性和程序的正确性。\n这个模型有几个核心的特点。首先，所有的共享变量，包括实例变量（属于对象的变量）和类变量（用 static 修饰的变量），都被存储在主内存中，也就是计算机的RAM。主内存就像是一个公共仓库，所有线程都能访问它。需要注意的是，局部变量并不包含在内，因为它们是线程私有的，所以不存在竞争问题。\n其次，每个线程都有自己的工作内存，线程会把主内存中的共享变量复制一份到自己的工作内存中，形成工作副本。这意味着，线程对变量的所有操作，无论是读还是写，都必须在自己的工作内存中完成，而不能直接读写主内存中的变量。\n最后，不同线程之间不能直接访问对方工作内存中的变量。如果线程间需要传递变量的值，那么这个过程必须通过主内存来完成。threadA 先把修改后的值写回主内存，threadB 再从主内存读取这个值，这样就完成了变量的传递。\n14. CAS 你知道吗？ CAS，是一种无锁算法，用于实现多线程同步的原子操作\nCAS 是一种**乐观锁**策略，它假设在大多数情况下不会发生冲突，因此在操作共享资源时不会加锁，而是在更新数据时检查数据是否被其他线程修改过。\n原理\nCAS 操作包含三个操作数：内存位置（V）、预期原值（A）和新值（B）。执行时，它会先比较内存位置 V 的值是否与预期原值 A 相等，如果相等，就将内存位置 V 的值更新为新值 B；如果不相等，则不进行更新。整个操作是原子性的，由 CPU 硬件保证。\n优缺点\n优点：避免了锁的使用，减少了线程上下文切换的开销，在并发冲突较少时性能较高。\n缺点：存在 ABA 问题，即一个值从 A 变为 B 再变回 A，CAS 会认为值未改变；并且在并发冲突激烈时，线程会频繁自旋，消耗大量 CPU 资源。对于 ABA 问题，Java 提供了 AtomicStampedReference 类来解决。\n15. 什么是AQS？ 什么是 AQS？ AQS（AbstractQueuedSynchronizer）是 Java 提供的一个框架，用于构建锁和其他同步组件。它的核心思想是通过一个整数变量（state）来表示同步状态，并通过一个FIFO队列来管理线程的等待和唤醒。它是一个构建同步器的基础，提供了许多阻塞锁和同步工具的实现，如 ReentrantLock、Semaphore 和 CountDownLatch 等。\nAQS 的工作机制是什么？ AQS 通过维护一个 state 属性来表示资源的状态。它提供了一个基于 FIFO 的等待队列来管理获取锁的线程。当一个线程尝试获取锁时，如果锁不可用，该线程会被加入到等待队列中。AQS 还支持条件变量和相应的等待/唤醒机制。\nAQS 如何保证线程安全地修改 state？ AQS 使用 CAS（Compare-AndSwap）操作来安全地修改 state 属性，确保这一操作的原子性，避免多线程同时修改导致的问题。\nAQS 是公平锁还是非公平锁？ AQS 本身并不直接实现公平性或非公平性，但基于 AQS 实现的锁可以是公平或非公平的。例如，ReentrantLock 默认是非公平锁，但可以配置为公平锁。公平锁确保等待时间最长的线程优先获取锁。\nAQS 常见的实现类有哪些？ 常见的基于 AQS 实现的类包括：\nReentrantLock：一种可重入的互斥锁。 Semaphore：用于控制同时访问特定资源的线程数量。 CountDownLatch：允许一个或多个线程等待其他线程完成操作。 面试说：AQS是Java并发包中的一个基础框架，用于构建锁和其他同步器。它通过一个state变量来表示同步状态，并通过一个FIFO队列来管理线程的等待和唤醒。AQS有两种模式：独占模式和共享模式。独占模式下，同一时间只有一个线程可以获取锁；共享模式下，多个线程可以共享资源。AQS的核心在于它提供了一套标准化的方法来实现线程同步，使得开发者可以更方便地实现自己的同步器。\n16. ReentrantLock的实现原理 首先，ReentrantLock是一种可重入的排它锁，主要用来解决多线程对共享资源竞争的问题。\n它的核心特性有几个：\n它支持可重入，也就是获得锁的线程在释放锁之前再次去竞争同一把锁的时候，不需要加锁就可以直接访问。\n它支持公平和非公平特性\n它提供了阻塞竞争锁和非阻塞竞争锁的两种方法，分别是lock()和tryLock()。\n然后，ReentrantLock的底层实现有几个非常关键的技术。\n锁的竞争，ReentrantLock是通过互斥变量，使用CAS机制来实现的。\n没有竞争到锁的线程，使用了AbstractQueuedSynchronizer这样一个队列同步器来存储，底层是通过双向链表来实现的。当锁被释放之后，会从AQS队列里面的头部唤醒下一个等待锁的线程。\n公平和非公平的特性，主要是体现在竞争锁的时候，是否需要判断AQS队列存在等待中的线程。\n最后，关于锁的重入特性，在AQS里面有一个成员变量来保存当前获得锁的线程，当同一个线程下次再来竞争锁的时候，就不会去走锁竞争的逻辑，而是直接增加重入次数。\n17. synchronized和Lock有什么区别 ? 第一，语法层面\nsynchronized 是关键字，源码在 jvm 中，用 c++ 语言实现，退出同步代码块锁会自动释放 Lock 是接口，源码由 jdk 提供，用 java 语言实现，需要手动调用 unlock 方法释放锁 第二，功能层面\n二者均属于悲观锁、都具备基本的互斥、同步、锁重入功能 Lock 提供了许多 synchronized 不具备的功能，例如获取等待状态、公平锁、可打断、可超时、多条件变量，同时Lock 可以实现不同的场景，如 ReentrantLock， ReentrantReadWriteLock 第三，性能层面\n在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖 在竞争激烈时，Lock 的实现通常会提供更好的性能，比如可中断获取锁，可超时获取锁，公平锁的选择，多条件变量的实现。 Lock 相比 synchronized 所具备的这些独特功能： 1. 获取等待状态 synchronized 的局限：使用 synchronized 时，我们没办法知道当前有没有线程在等待获取这把锁，也不清楚等待的线程数量。就好比你去一个公共卫生间，用 synchronized 的话，你只能知道里面有没有人，但不知道外面排了多少人等着进去。 Lock 的优势：Lock 可以让我们获取到等待锁的线程的相关状态。以 ReentrantLock 为例，借助 getQueueLength() 方法就能知道有多少线程正在等待获取这把锁。这就好像卫生间门口有个显示屏，能显示排队的人数，让我们对整体情况有更清晰的了解。 2. 公平锁 synchronized 的情况：synchronized 实现的是非公平锁。这就好比大家在抢公交车的座位，不管谁先来，只要有空座，谁抢到就是谁的。可能先来的人反而没抢到座，后来的人却捷足先登了。 Lock 的公平锁：Lock 可以实现公平锁。公平锁就像是大家排队坐公交车，先到的人先上车有座坐，后到的人依次排队等待。ReentrantLock 可以在创建时通过构造函数指定为公平锁，即 new ReentrantLock(true)，这样线程获取锁的顺序就和它们请求锁的顺序一致了。 3. 可打断 synchronized 的问题：当一个线程使用 synchronized 获取锁时，如果这个锁被其他线程持有，当前线程就会一直等待，而且在等待过程中不能被其他线程打断。这就好比你在排队买东西，前面的人一直不买完，你就只能干等着，没办法中途离开去做别的事。 Lock 的可打断特性：Lock 提供了可打断的功能。使用 lockInterruptibly() 方法获取锁时，如果线程在等待锁的过程中被其他线程打断，它会抛出 InterruptedException 异常，然后线程可以去做其他事情。就像排队买东西时，你可以选择在等得不耐烦的时候，听到别人叫你去做别的事，你就可以离开队伍去处理其他事情。 4. 可超时 synchronized 的不足：synchronized 没有超时机制，线程一旦开始等待锁，就会一直等下去，可能会造成长时间的阻塞。这就好比你去餐厅吃饭，前面的人一直占着桌子不走，你只能一直等，没有别的选择。 Lock 的可超时功能：Lock 可以设置获取锁的超时时间。使用 tryLock(long timeout, TimeUnit unit) 方法时，如果在指定的时间内没有获取到锁，线程就会放弃等待，返回 false。这就像你去餐厅吃饭，等了一段时间桌子还没腾出来，你就可以选择去别的餐厅，不用一直干等着。 5. 多条件变量 synchronized 的单一性：synchronized 配合 wait()、notify() 和 notifyAll() 方法只能实现单一的条件等待和唤醒。就好比一个房间里只有一个门铃，不管是谁在等消息，门铃一响所有人都得醒来看是不是自己的消息。 Lock 的多条件变量：Lock 可以通过 newCondition() 方法创建多个条件变量。每个条件变量都可以单独进行等待和唤醒操作。线程可以根据不同的条件在不同的队列中等待，唤醒时也可以精确地唤醒特定条件下等待的线程，减少了不必要的唤醒和上下文切换，提高了线程间协作的效率。 18. 死锁产生的条件是什么？ 嗯，是这样的，一个线程需要同时获取多把锁，这时就容易发生死锁，举个例子来说：\nt1 线程获得A对象锁，接下来想获取B对象的锁\nt2 线程获得B对象锁，接下来想获取A对象的锁\n这个时候t1线程和t2线程都在互相等待对方的锁，就产生了死锁\n19. 如何进行死锁诊断？ 可以使用jdk自带的工具：jps和 jstack\n先通过jps来查看当前java程序运行的进程id\n然后通过jstack来查看这个进程id，就能展示出来死锁的问题，并且，可以定位代码的具体行号范围，我们再去找到对应的代码进行排查就行了。\n或者用一些可视化工具：jconsole、VisualVM，bin目录下 直接启动就行\n20. ConcurrentHashMap ConcurrentHashMap 是一种线程安全的高效Map集合，jdk1.7和1.8也做了很多调整。\nJDK1.7的底层采用是分段的数组+链表 实现 JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。 在jdk1.7中 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一 种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，Segment 是一种可重入的锁 ReentrantLock，每个Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。\n在jdk1.8中的ConcurrentHashMap 做了较大的优化，性能提升了不少。首先是它的数据结构与jdk1.8的hashMap数据结构完全一致。其次是放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现，synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发 , 效率得到提升\n在 JDK 1.8 中，ConcurrentHashMap将锁机制从Segment（继承自ReentrantLock）改为synchronized后效率得到提升，主要原因如下： 1. 锁粒度的减小\nJDK 1.7 的 Segment 锁：在 JDK 1.7 中，ConcurrentHashMap使用Segment数组来分段管理数据，每个Segment是一个可重入锁，并且守护着一个HashEntry数组。这意味着如果有多个线程访问不同Segment的数据，这些线程可以并发执行；但如果访问同一个Segment的数据，就会被阻塞。由于锁的粒度是Segment级别，而一个Segment可能包含多个键值对，在高并发场景下，不同线程竞争同一个Segment锁的概率较高，从而限制了并发性能。 JDK 1.8 的 synchronized 锁：JDK 1.8 中，ConcurrentHashMap放弃了Segment，直接使用Node数组来存储数据。当需要修改数据时，synchronized只锁定当前链表或红黑二叉树的首节点。如果多个线程访问的节点位于不同的链表或红黑二叉树，或者即使在同一个链表 / 树中但首节点不同，这些线程就可以并发执行。锁粒度从Segment（包含多个键值对）细化到了链表或树的首节点，大大降低了线程之间的锁竞争，提高了并发访问的效率。 2. CAS（Compare and Swap）操作的辅助\nCAS 操作原理：CAS 是一种无锁的原子操作，它包含三个操作数：内存位置、预期原值和新值。当且仅当内存位置的值与预期原值相同时，CAS 才会将内存位置的值更新为新值。在 JDK 1.8 的ConcurrentHashMap中，对于一些操作（如插入新节点），首先会尝试使用 CAS 操作来完成。只有在 CAS 操作失败（例如发生了哈希冲突，导致 CAS 更新操作失败）时，才会使用synchronized锁来保证操作的原子性。 提升效率方式：由于大部分情况下，插入操作不会发生哈希冲突，因此 CAS 操作能够快速完成，避免了使用锁带来的开销。这使得在高并发环境下，ConcurrentHashMap可以利用 CAS 的高效性来处理大部分的操作，仅在必要时使用synchronized锁，从而整体上提升了效率。 3. 红黑树的引入优化数据结构\n链表与红黑树的转换：JDK 1.8 的ConcurrentHashMap中，当链表长度超过一定阈值（8）时，链表会转换为红黑树。红黑树相比于链表，在查找、插入和删除操作上具有更好的时间复杂度（链表的查找时间复杂度为 O (n)，红黑树为 O (log n)）。 对锁效率的影响：当使用synchronized锁定首节点时，由于红黑树的结构特性，在处理大量数据时，即使存在锁竞争，基于红黑树的操作效率也比基于链表的操作效率更高。这意味着在相同的并发环境下，JDK 1.8 的ConcurrentHashMap能够更快地完成各种操作，从而提升了整体效率。 4. JVM 对 synchronized 的优化\n锁升级机制：JVM 在 JDK 1.6 及之后对synchronized进行了一系列优化，引入了偏向锁、轻量级锁和重量级锁的锁升级机制。当一个线程访问同步块时，首先会尝试获取偏向锁，如果没有其他线程竞争，该线程可以直接进入同步块，不需要进行 CAS 操作和重量级锁的获取，从而降低了锁的开销。只有在出现锁竞争时，才会逐步升级到轻量级锁和重量级锁。 在 ConcurrentHashMap 中的作用：在 JDK 1.8 的ConcurrentHashMap中，synchronized锁的使用正好可以利用 JVM 的这些优化机制。在大部分情况下，由于锁粒度小，竞争不激烈，synchronized能够以较低的开销工作，进一步提升了ConcurrentHashMap的性能。 在 Java 中，ConcurrentHashMap在不同版本中使用了不同的数据结构来实现并发安全的哈希映射，Segment数组和Node数组是其中两个重要的组成部分，以下是对它们的详细介绍： JDK 1.7 中的Segment数组\n结构与作用：ConcurrentHashMap在 JDK 1.7 中使用Segment数组来实现分段锁机制。每个Segment内部包含一个HashEntry数组，类似于HashMap的结构，它将整个哈希表分成多个段，每个段独立进行锁控制。这样，在多线程并发访问时，不同的线程可以同时访问不同的Segment，从而提高并发性能。 锁机制：Segment继承自ReentrantLock，当对Segment中的HashEntry数组进行修改操作（如插入、删除、更新等）时，需要先获取对应的Segment的锁。这意味着同一时刻只有一个线程可以访问同一个Segment中的数据，而不同Segment之间的操作可以并发进行。 JDK 1.8 中的Node数组\n结构与作用：JDK 1.8 中的ConcurrentHashMap摒弃了Segment数组的设计，采用了Node数组来存储数据。Node是哈希表中的基本节点类型，每个Node包含键值对以及指向下一个节点的引用（用于解决哈希冲突，形成链表或红黑树结构）。数组的每个位置要么是一个Node节点，要么是null，通过哈希值来确定键值对在数组中的存储位置。 锁机制与并发控制：在 JDK 1.8 中，ConcurrentHashMap通过Node + CAS + Synchronized来保证并发安全。当对Node数组进行操作时，首先会尝试使用CAS（比较并交换）操作来更新数组中的节点，这是一种无锁的并发操作方式，能在大多数情况下提高并发性能。对于一些复杂的操作，如在链表或红黑树中插入、删除节点时，会使用synchronized关键字来锁定当前链表或红黑树的首节点。这种方式相比 JDK 1.7 的Segment锁更加精细，只锁定当前操作的节点所在的链表或红黑树，而不是整个Segment，从而减少了锁的粒度，提高了并发访问的效率。 21. 导致并发程序出现问题的根本原因是什么 Java并发编程有三大核心特性，分别是原子性、可见性和有序性。\n首先，原子性指的是一个线程在CPU中的操作是不可暂停也不可中断的，要么执行完成，要么不执行。比如，一些简单的操作如赋值可能是原子的，但复合操作如自增就不是原子的。为了保证原子性，我们可以使用synchronized关键字或JUC里面的Lock来进行加锁。\n其次，可见性是指让一个线程对共享变量的修改对另一个线程可见。由于线程可能在自己的工作内存中缓存共享变量的副本，因此一个线程对共享变量的修改可能不会立即反映在其他线程的工作内存中。为了解决这个问题，我们可以使用synchronized关键字、volatile关键字或Lock来确保可见性。\n最后，有序性是指处理器为了提高程序运行效率，可能会对输入代码进行优化，导致程序中各个语句的执行先后顺序与代码中的顺序不一致。虽然处理器会保证程序最终执行结果与代码顺序执行的结果一致，但在某些情况下我们可能需要确保特定的执行顺序。为了解决这个问题，我们可以使用volatile关键字来禁止指令重排。\n22. 说一下线程池的核心参数（线程池的执行原理知道嘛） 在线程池中一共有7个核心参数：\ncorePoolSize 核心线程数目 - 池中会保留的最多线程数 maximumPoolSize 最大线程数目 - 核心线程+救急线程的最大数目 keepAliveTime 生存时间 - 救急线程的生存时间，生存时间内没有新任务，此线程资源会释放 unit 时间单位 - 救急线程的生存时间单位，如秒、毫秒等 workQueue - 当没有空闲核心线程时，新来任务会加入到此队列排队，队列满会创建救急线程执行任务 threadFactory 线程工厂 - 可以定制线程对象的创建，例如设置线程名字、是否是守护线程等 handler 拒绝策略 - 如果所有线程都在忙着（核心线程+临时线程），则走拒绝策略，拒绝策略有4种 1.AbortPolicy：直接抛出异常，默认策略；\n2.CallerRunsPolicy：用调用者所在的线程来执行任务；\n3.DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；\n4.DiscardPolicy：直接丢弃任务；\n23. 线程池中有哪些常见的阻塞队列 Jdk中提供了很多阻塞队列，开发中常见的有两个：ArrayBlockingQueue和LinkedBlockingQueue\nArrayBlockingQueue和LinkedBlockingQueue是Java中两种常见的阻塞队列，它们在实现和使用上有一些关键的区别。\n首先，ArrayBlockingQueue是一个有界队列，它在创建时必须指定容量，并且这个容量不能改变。而LinkedBlockingQueue默认是无界的，但也可以在创建时指定最大容量，使其变为有界队列。\n其次，它们在内部数据结构上也有所不同。ArrayBlockingQueue是基于数组实现的，而LinkedBlockingQueue则是基于链表实现的。这意味着ArrayBlockingQueue在访问元素时可能会更快，因为它可以直接通过索引访问数组中的元素。而LinkedBlockingQueue则在添加和删除元素时可能更快，因为它不需要移动其他元素来填充空间。\n另外，它们在加锁机制上也有所不同。ArrayBlockingQueue使用一把锁来控制对队列的访问，这意味着读写操作都是互斥的。而LinkedBlockingQueue则使用两把锁，一把用于控制读操作，另一把用于控制写操作，这样可以提高并发性能。\n24. 如何确定核心线程数 在设置核心线程数之前，需要先熟悉一些执行线程池执行任务的类型\nIO密集型任务 一般来说：文件读写、DB读写、网络请求等\n推荐：核心线程数大小设置为2N+1 （N为计算机的CPU核数）\nCPU密集型任务 一般来说：计算型代码、Bitmap转换、Gson转换等\n推荐：核心线程数大小设置为N+1 （N为计算机的CPU核数）\n① 高并发、任务执行时间短 \u0026ndash;\u0026gt;（ CPU核数+1 ），减少线程上下文的切换，因为任务执行时间短，线程很快就能完成任务并释放资源，较少的线程数可以避免频繁的上下文切换带来的性能损耗。\n② 并发不高、任务执行时间长\nIO密集型的任务 \u0026ndash;\u0026gt; (CPU核数 * 2 + 1) 由于任务执行时间长且涉及大量 IO 操作，较多的线程可以在某个线程等待 IO 时继续执行其他任务，提高 CPU 的利用率。 计算密集型任务 \u0026ndash;\u0026gt; （ CPU核数+1 ）因为任务主要是计算工作，过多的线程会增加上下文切换的开销，所以保持与 CPU 核数相近的线程数较为合适。 ③ 并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，首先要考虑业务中的某些数据是否可以做缓存，通过缓存可以减少不必要的计算和 IO 操作，提高系统的响应速度。其次，如果缓存无法满足需求，可以考虑增加服务器来分担压力。\n25. 线程池的种类有哪些 在jdk中默认提供了4种方式创建线程池\n第一个是：newCachedThreadPool创建一个可缓存线程池\n线程池中的线程数量是灵活可变的。当有新任务提交时，如果线程池中有空闲线程，就会复用这些空闲线程来执行任务；如果没有空闲线程，就会创建新的线程来处理任务。 对于空闲线程有一定的回收机制。如果某个线程在 60 秒内都处于空闲状态，就会被回收销毁，这样可以避免资源的浪费。 第二个是：newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 适用于需要控制并发线程数量的场景，例如数据库连接池，为了避免过多的线程同时访问数据库导致资源耗尽，可以使用定长线程池来限制并发线程数。\n第三个是：newScheduledThreadPool 创建一个定时任务线程池，支持定时及周期性任务执行。 适用于需要定时执行任务或周期性执行任务的场景，例如定时数据备份、定时统计系统性能指标等。\n第四个是：newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。\n26. 为什么不建议用Executors创建线程池 主要原因是如果使用Executors创建线程池的话，它允许的请求队列默认长度是Integer.MAX_VALUE，这样的话，有可能导致堆积大量的请求，从而导致OOM（内存溢出）。\n所以，我们一般推荐使用ThreadPoolExecutor来创建线程池，这样可以明确规定线程池的参数，避免资源的耗尽。\n27. 你们项目哪里用到了多线程 参考场景一：\nes数据批量导入\n在我们项目上线之前，我们需要把数据量的数据一次性的同步到es索引库中，但是当时的数据好像是1000万左右，一次性读取数据肯定不行（oom异常），如果分批执行的话，耗时也太久了。所以，当时我就想到可以使用线程池的方式导入，利用CountDownLatch+Future来控制，就能大大提升导入的时间。\n参考场景二：\n在我做那个xx电商网站的时候，里面有一个数据汇总的功能，在用户下单之后需要查询订单信息，也需要获得订单中的商品详细信息（可能是多个），还需要查看物流发货信息。因为它们三个对应的分别三个微服务，如果一个一个的操作的话，互相等待的时间比较长。所以，我当时就想到可以使用线程池，让多个线程同时处理，最终再汇总结果就可以了，当然里面需要用到Future来获取每个线程执行之后的结果才行\n参考场景三：\n《黑马头条》项目中使用的\n我当时做了一个文章搜索的功能，用户输入关键字要搜索文章，同时需要保存用户的搜索记录（搜索历史），这块我设计的时候，为了不影响用户的正常搜索，我们采用的异步的方式进行保存的，为了提升性能，我们加入了线程池，也就说在调用异步方法的时候，直接从线程池中获取线程使用\n28. 如何控制某个方法允许并发访问线程的数量？ 在jdk中提供了一个Semaphore[seməfɔːr]类（信号量）\n它提供了两个方法，semaphore.acquire() 请求信号量，可以限制线程的个数，是一个正数，如果信号量是-1,就代表已经用完了信号量，其他线程需要阻塞了\n第二个方法是semaphore.release()，代表是释放一个信号量，此时信号量的个数+1\n29. 谈谈你对ThreadLocal的理解 ThreadLocal 主要功能有两个，第一个是可以实现资源对象的线程隔离，让每个线程各用各的资源对象，避免争用引发的线程安全问题，第二个是实现了线程内的资源共享\n30. 知道ThreadLocal的底层原理实现吗？ 在ThreadLocal内部维护了一个一个 ThreadLocalMap 类型的成员变量，用来存储资源对象\n当我们调用 set 方法，就是以 ThreadLocal 自己作为 key，资源对象作为 value，放入当前线程的 ThreadLocalMap 集合中\n当调用 get 方法，就是以 ThreadLocal 自己作为 key，到当前线程中查找关联的资源值\n当调用 remove 方法，就是以 ThreadLocal 自己作为 key，移除当前线程关联的资源值\n31. 关于ThreadLocal会导致内存溢出这个事情，了解吗？ ThreadLocalMap 中的 Entry 类的key 是一个弱引用，而 value 是一个强引用。弱引用的特点是，当垃圾回收器进行垃圾回收时，如果一个对象只被弱引用所引用，那么无论当前内存是否充足，该对象都会被回收。所以，当外部对 ThreadLocal 对象的强引用被释放后，ThreadLocalMap 中的 key 会被垃圾回收器回收，即 key 变为 null。\n然而，value 是强引用，只要当前线程还存在，ThreadLocalMap 就不会被回收，value 也不会被回收。这样就会导致 ThreadLocalMap 中存在一些 key 为 null，但 value 不为 null 的 Entry，这些 Entry 无法被访问到，却占用着内存，随着时间的推移，可能会导致内存泄漏。\n解决办法 为了避免 ThreadLocal 导致的内存泄漏问题，我们应该在使用完 ThreadLocal 后，及时调用 remove 方法。\n另外，在使用 ThreadLocal 时，尽量避免将其作为静态变量使用，因为静态变量的生命周期和类的生命周期一样长，可能会导致 ThreadLocal 对象一直存在，增加内存泄漏的风险。同时，在使用线程池时，由于线程会被复用，更要注意及时调用 remove 方法，防止 ThreadLocal 中的数据在不同任务之间产生混淆，也避免内存泄漏问题的发生。\n32. 说说线程的生命周期和状态? Java 线程具有 6 种不同的生命周期状态，分别为：\nNEW（初始状态）：线程已创建，但尚未调用start()方法启动。 RUNNABLE（运行状态）：调用start()方法后进入该状态，此时线程等待获取 CPU 资源以执行。 BLOCKED（阻塞状态）：线程在获取对象锁时被阻塞，需等待锁的释放。 WAITING（等待状态）：线程需要等待其他线程执行特定动作（如通知或中断），会一直等待直到收到相应信号。 TIME_WAITING（超时等待状态）：与 WAITING 类似，但可在指定时间后自行返回，无需一直等待。 TERMINATED（终止状态）：线程执行完毕，生命周期结束。 线程在运行过程中，会依据代码的执行情况在这些状态之间进行切换，并非固定处于某一状态 。\n33. 线程池如何知道一个线程的任务已经执行完成 线程池判断一个线程的任务是否执行完成，可从线程池内部机制和线程池外部获取状态两个方面来理解：\n线程池内部机制\n当向线程池提交任务后，线程池会调度工作线程执行任务的run方法。工作线程通过同步调用任务的run方法，等待run方法返回，一旦run方法正常结束，即表明任务完成，此时工作线程会统计任务的完成数量。\n线程池外部获取状态\n使用isTerminated()方法：线程池提供了isTerminated()方法用于判断其运行状态。通过循环判断该方法的返回结果，可了解线程池状态。当线程池状态为Terminated时，意味着所有任务都已执行完毕。不过，使用此方法的前提是程序中主动调用了线程池的shutdown()方法。在实际业务中，主动关闭线程池的情况并不常见，所以该方法在实用性和灵活性上有所欠缺。 利用submit()方法的Future返回值：线程池的submit()方法会返回一个Future对象。通过调用Future.get()方法可获取任务的执行结果。在任务未执行完成前，Future.get()方法会一直阻塞，直至任务执行结束正常返回，这也就表明传入线程池的任务已执行完成。 借助CountDownLatch计数器：CountDownLatch可以通过初始化指定一个计数器进行倒计时，其有await()方法用于阻塞线程，以及countDown()方法用于倒计时。基于此原理，可定义一个计数器为 1 的CountDownLatch对象，在线程池代码块后面调用await()方法阻塞主线程。当传入线程池的任务执行完成后，调用countDown()方法表示任务结束。此时计数器归零，被阻塞在await()方法的线程将被唤醒。 总的来说，无论是在线程池内部还是外部，要知晓线程是否执行结束，关键在于获取线程执行结束后的状态。由于线程本身没有返回值，所以常通过阻塞 - 唤醒的方式来达成，Future.get和CountDownLatch都是基于这一原理。\n34. 线程池有哪几种状态 每种状态分别表示什么 在 Java 线程池中，线程池共有以下 5 种状态，每种状态都有其特定的含义和行为：\nRUNNING（运行状态）：线程池处于正常运行状态，可以接受新任务，并处理已提交的任务。这是线程池创建后的初始状态。在这种状态下，线程池会根据任务队列和线程数量的情况，动态地创建和管理工作线程来执行任务。 SHUTDOWN（关闭状态）：当调用线程池的 shutdown() 方法后，线程池进入此状态。此时，线程池不再接受新任务，但会继续处理已提交到任务队列中尚未执行的任务。只有当任务队列中的所有任务都处理完成后，线程池才会进入下一个状态。在处理任务的过程中，线程池不会中断正在执行任务的线程，而是等待任务自然结束。 STOP（停止状态）：当调用线程池的 shutdownNow() 方法后，线程池进入此状态。与 SHUTDOWN 状态不同，STOP 状态下线程池不仅不再接受新任务，还会尝试立即停止所有正在执行的任务，并且会中断等待任务队列中任务的线程。也就是说，处于 STOP 状态的线程池会立即终止所有的工作线程，而不会等待任务完成。 TIDYING（整理状态）：当线程池中的所有任务都已执行完毕，并且工作线程数量为 0 时，线程池会自动进入 TIDYING 状态。在进入该状态时，线程池会调用 terminated() 方法，这个方法可以由用户自定义实现，用于在线程池关闭前进行一些清理和资源释放的操作。 TERMINATED（终止状态）：当 terminated() 方法执行完毕后，线程池就会进入 TERMINATED 状态。此时，线程池已经完全关闭，不再有任何活动，所有的资源也都已释放。 悲观锁与乐观锁：概念、实现及应用场景 一、悲观锁\n（一）定义与原理\n悲观锁总是假设最坏的情况，即共享资源每次被访问时，极有可能发生冲突。所以，它在每次操作共享资源前，都会先获取锁，确保同一时刻只有一个线程能访问该资源，其他线程只能阻塞等待，直到持有锁的线程释放锁资源。这种策略如同在一个公共资源前设置了一道关卡，每次只允许一个人通过，其他人必须排队等待。\n（二）Java 中的实现方式\nsynchronized 关键字：这是 Java 内置的一种同步机制，当一个线程进入被synchronized修饰的代码块或方法时，它会自动获取对象锁（若是静态方法，则获取类锁）。例如： 1 2 3 4 5 6 7 public class SynchronizedExample { private int sharedResource; public synchronized void performTask() { // 需要同步的操作 sharedResource++; } } 在上述代码中，performTask方法被synchronized修饰，当一个线程执行该方法时，其他线程若也想执行此方法，就会被阻塞，直到当前线程执行完毕并释放锁。\nReentrantLock 类：这是 Java 并发包java.util.concurrent.locks中提供的一个可重入的互斥锁。使用时，需要先创建ReentrantLock对象，然后在需要同步的代码块前后分别调用lock()和unlock()方法。通常，为了确保锁一定能被释放，会将unlock()方法放在finally块中。示例如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; public class ReentrantLockExample { private int sharedResource; private Lock lock = new ReentrantLock(); public void performTask() { lock.lock(); try { // 需要同步的操作 sharedResource++; } finally { lock.unlock(); } } } ReentrantLock相较于synchronized，提供了更灵活的锁控制，如可中断的锁获取、公平锁与非公平锁的选择等。\n（三）优缺点及适用场景\n优点：悲观锁能够严格保证数据的一致性和线程安全性，因为它通过加锁机制避免了多个线程同时修改共享资源的情况。 缺点 性能开销大：在高并发场景下，由于大量线程竞争锁资源，会导致频繁的线程阻塞和上下文切换。线程阻塞意味着线程需要等待锁，这期间线程处于空闲状态，白白占用系统资源；而上下文切换则是指操作系统在不同线程之间切换执行环境，这一过程需要保存和恢复线程的状态信息，也会消耗一定的时间和资源。 死锁风险：如果多个线程获取锁的顺序不当，就可能出现死锁现象。例如，线程 A 持有锁 1，等待获取锁 2，而线程 B 持有锁 2，等待获取锁 1，此时两个线程都无法继续执行，形成死锁，严重影响系统的正常运行。 适用场景：适用于写操作频繁、数据一致性要求极高且并发冲突可能性较大的场景。比如，在银行转账系统中，对账户余额的修改操作就需要使用悲观锁，以确保在同一时刻只有一个转账操作能对账户余额进行修改，避免出现数据不一致的情况。 二、乐观锁\n（一）定义与原理\n乐观锁秉持乐观的态度，总是假设共享资源在每次被访问时不会出现问题，线程可以自由地执行操作，无需加锁等待。它仅在提交修改时，才会去验证对应的共享资源是否被其他线程修改过。若未被修改，则提交成功；若已被修改，则重试操作，直至成功提交。这种策略就像是在一个相对和谐的环境中，大家都先假设自己的操作不会与他人冲突，各自先进行工作，最后再检查是否有冲突发生。\n（二）Java 中的实现方式\n原子变量类（基于 CAS 算法）\n在 Java 的java.util.concurrent.atomic包中，提供了一系列原子变量类，如AtomicInteger、AtomicLong、LongAdder等，它们都是通过 CAS（Compare And Swap，比较与交换）算法实现了乐观锁机制。\nCAS 算法原理：CAS 操作涉及三个操作数，分别是要更新的变量值（Var）、预期值（Expected）和拟写入的新值（New）。当且仅当 Var 的值等于 Expected 时，CAS 才会通过原子方式用 New 值来更新 Var 的值。若两者不相等，说明在当前线程操作期间，已经有其他线程修改了 Var 的值，当前线程则放弃更新。例如，假设有一个AtomicInteger对象atomicInt，其初始值为 5，线程 A 希望将其值更新为 10，此时线程 A 会先获取atomicInt的当前值（即 5）作为预期值，然后尝试将其更新为 10。若在更新前没有其他线程修改atomicInt的值，那么更新操作会成功；若有其他线程已经修改了atomicInt的值，更新操作则失败，线程 A 可以选择再次尝试更新。 LongAdder 类的特殊优化：在高并发场景下，LongAdder类相比AtomicInteger和AtomicLong具有更好的性能。LongAdder内部采用了分段累加的方式，将对一个变量的操作分散到多个不同的单元格（Cell）中，每个线程在对变量进行操作时，会先访问不同的单元格，减少了线程间的竞争。不过，这种方式会消耗更多的内存空间，因为它需要为每个单元格分配内存，本质上是用空间换取时间。例如： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import java.util.concurrent.atomic.LongAdder; public class LongAdderExample { private static LongAdder sum = new LongAdder(); public static void main(String[] args) { Thread[] threads = new Thread[10]; for (int i = 0; i \u0026lt; 10; i++) { threads[i] = new Thread(() -\u0026gt; { for (int j = 0; j \u0026lt; 1000; j++) { sum.increment(); } }); threads[i].start(); } for (Thread thread : threads) { try { thread.join(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(\u0026#34;Sum: \u0026#34; + sum.sum()); } } 在上述代码中，通过多个线程同时对LongAdder对象sum进行累加操作，展示了LongAdder在高并发环境下的高效性。\n版本号机制 在数据库操作中，常使用版本号机制来实现乐观锁。一般在数据表中添加一个数据版本号version字段，用于表示数据被修改的次数。当数据被修改时，version值会自动加 1。线程在读取数据的同时，也会读取version值，在提交更新时，只有当读取到的version值与当前数据库中的version值相等时，才会执行更新操作；否则，会重试更新操作，直到更新成功。例如，假设有一个用户信息表user_info，其中包含id、name、balance和version字段，当前有一条记录id = 1，name = \u0026quot;张三\u0026quot;，balance = 1000，version = 1。\n线程 A 读取该记录，此时version = 1，并对balance进行修改，将其值减少 100，即balance = 900。 在线程 A 操作过程中，线程 B 也读取了该记录，version同样为 1，并对balance进行修改，将其值减少 200，即balance = 800。 线程 A 完成修改后，提交更新操作，此时会比对读取的version值（1）和数据库中当前记录的version值（假设此时数据库中该记录的version值仍为 1，因为线程 B 还未提交更新），两者相等，更新操作成功，数据库中该记录的version值更新为 2，balance值更新为 900。 线程 B 完成操作后，提交更新操作，此时比对读取的version值（1）和数据库中当前记录的version值（2），两者不相等，更新操作失败，线程 B 需要重新读取数据并进行修改和提交，直到更新成功。 （三）优缺点及适用场景\n优点 高并发性能优越：由于乐观锁在大多数情况下不需要加锁，线程可以自由执行，避免了线程阻塞和上下文切换带来的性能开销，因此在高并发且读操作远多于写操作的场景中，性能表现出色。 无死锁问题：乐观锁不需要显式地获取和释放锁，不存在因获取锁顺序不当而导致的死锁问题，提高了系统的稳定性。 缺点 频繁重试开销：在写操作频繁的场景下，由于数据被其他线程修改的概率较高，可能会导致大量的更新操作失败并需要重试，这会消耗大量的 CPU 资源，严重影响系统性能，甚至可能导致 CPU 使用率飙升。 适用范围有限：乐观锁主要适用于对单个共享变量的操作，对于涉及多个共享变量的复杂操作，使用乐观锁可能无法保证数据的一致性。 适用场景：适用于读多写少的场景，例如在一些缓存系统中，数据的读取操作远远多于写入操作，使用乐观锁可以在保证数据一致性的前提下，极大地提高系统的并发性能。 三、MySQL篇 1. MySQL中，如何定位慢查询？ 在 MySQL 中，我们可以通过开启慢查询日志来定位执行缓慢的查询。具体操作是在 MySQL 的配置文件中设置 slow_query_log=1 来开启慢查询日志，并通过 long_query_time=2 参数设置慢查询的阈值，例如超过 2 秒。日志默认存放在 MySQL 数据目录下，文件名为 slow.log。通过分析这个日志文件，我们可以识别出哪些查询操作的性能不佳，进而进行优化。\u0026quot;\n除了慢查询日志，我们还可以使用 SQL Profile 工具来获取 SQL 语句的详细执行信息。在会话中开启 profiling 功能（SET profiling = 1;），执行 SQL 语句后，通过 SHOW PROFILES; 命令可以查看该语句的执行细节，包括消耗的时间、扫描的行数等，这有助于我们分析和优化慢查询。\n2. 那这个SQL语句执行很慢，如何分析呢？ 如果一条SQL执行很慢，我们通常会使用MySQL的EXPLAIN命令来分析这条SQL的执行情况。通过key和key_len可以检查是否命中了索引，如果已经添加了索引，也可以判断索引是否有效。通过type字段可以查看SQL是否有优化空间，比如是否存在全索引扫描或全表扫描。通过extra建议可以判断是否出现回表情况，如果出现，可以尝试添加索引或修改返回字段来优化。\n3. 了解过索引吗 嗯，索引在项目中非常常见，它是一种帮助MySQL高效获取数据的数据结构，主要用来提高数据检索效率，降低数据库的I/O成本。同时，索引列可以对数据进行排序，降低数据排序的成本，也能减少CPU的消耗。\n4. 索引的底层数据结构了解过吗？ MySQL的默认存储引擎InnoDB使用的是B+树作为索引的存储结构。选择B+树的原因包括：节点可以有更多子节点，路径更短；磁盘读写代价更低，非叶子节点只存储键值和指针，叶子节点存储数据；B+树适合范围查询和扫描，因为叶子节点形成了一个双向链表。\n5. B树和B+树的区别是什么呢？ B树的非叶子节点和叶子节点都存放数据，而B+树的所有数据只出现在叶子节点，这使得B+树在查询时效率更稳定。 B+树在进行范围查询时效率更高，因为所有数据都在叶子节点，并且叶子节点之间形成了双向链表。 6. 什么是聚簇索引什么是非聚簇索引？ 在数据库中，索引分为聚簇索引和非聚簇索引两种类型。聚簇索引，B+树的叶子节点保存了整行数据，通常只有一个聚簇索引，一般是由主键构成。非聚簇索引则存储的是数据的引用，B+树的叶子节点保存的是主键值，可以有多个非聚簇索引，通常我们自定义的索引都是非聚簇索引。\n7. 知道什么是回表查询吗？ 回表查询是指通过二级索引找到对应的主键值，然后再通过主键值查询聚簇索引中对应的整行数据的过程。\n8. 知道什么叫覆盖索引吗？ 覆盖索引是指在SELECT查询中，返回的列全部能在索引中找到，避免了回表查询，提高了性能。使用覆盖索引可以减少对主键索引的查询次数，提高查询效率。\n9. MySQL超大分页怎么处理？ 超大分页通常发生在数据量大的情况下，使用LIMIT分页查询且需要排序时效率较低。可以通过覆盖索引和子查询来解决。首先查询数据的ID字段进行分页，然后根据ID列表用子查询来过滤只查询这些ID的数据，因为查询ID时使用的是覆盖索引，所以效率可以提升。\n10. 索引创建原则有哪些？ 创建索引的原则包括：\n表中的数据量超过10万以上时考虑创建索引。 选择查询频繁的字段作为索引，如查询条件、排序字段或分组字段。 尽量使用复合索引，覆盖SQL的返回值。 如果字段区分度不高，可以将其放在组合索引的后面。 对于内容较长的字段，考虑使用前缀索引。 控制索引数量，因为索引虽然可以提高查询速度，但也会影响插入、更新的速度。 11. 什么情况下索引会失效？ 索引失效可能发生在几种情况下。首先，如果查询条件没有遵循最左前缀法则，即没有从复合索引的最左边列开始，索引可能不会生效。其次，如果对字符串类型的索引列使用了以 % 开头的 LIKE 查询，索引也会失效。此外，如果在索引列上进行了运算或类型转换，比如数学运算或函数操作，索引同样会失效。对于复合索引，如果在索引的中间列使用了范围查询，那么该列右边的所有列索引都将失效。\n12. SQL的优化经验有哪些？ 建表时选择合适的字段类型。 使用索引，遵循创建索引的原则。 编写高效的SQL语句，比如避免使用SELECT *，尽量使用UNION ALL代替UNION，以及在表关联时使用INNER JOIN。 查询优化：使用 EXPLAIN 分析查询执行计划，确保查询有效使用索引。 避免返回过多数据：使用覆盖索引，减少全表扫描。 在数据量大时考虑分库分表。 13. 创建表的时候，你们是如何优化的呢？ 选择合适的数据类型：根据数据的特性选择最合适的数据类型，例如，对于小整数使用 TINYINT，大整数使用 INT 或 BIGINT，字符串根据长度选择 CHAR、、VARCHAR或TEXT`。 定义字符集：选择适当的字符集，如 utf8，以支持多语言文本。 定义长度：对于可变长字段，定义合理的长度，避免不必要的空间浪费。 创建索引：为查询、排序或连接操作频繁的列创建索引，包括主键和外键。 规范化设计：应用数据库规范化原则，减少数据冗余，提高数据一致性。 分区：对于大数据量的表，考虑分区来提高查询和管理效率。 外键：使用外键来维护表之间的关系，确保引用完整性。 默认值：为具有默认值的列定义默认值。 避免冗余：设计表结构时避免重复存储相同数据。 性能测试：在开发环境中对表结构进行性能测试，确保查询和更新操作的效率。 14. 在使用索引的时候，是如何优化呢？ 在使用索引时，我们遵循索引创建原则，确保索引字段是查询频繁的，使用复合索引覆盖SQL返回值，尽量避免导致回表查询的查询条件，以减少额外的 I/O 开销。\n15. 你平时对SQL语句做了哪些优化呢？ 首先，我会避免使用 SELECT *，而是明确指定所需的字段，这有助于减少数据传输并提高查询效率。其次，我会确保在查询条件列上建立索引，并在查询中尽量使用这些索引。此外，我会优化 JOIN 操作，尽量使用 INNER JOIN，因为它在内连接时会过滤不符合条件的记录，减少需要处理的数据量。如果必须使用 LEFT JOIN 或 RIGHT JOIN，确保小表作为驱动表，即左连接的小表在左边，右连接的小表在右边。\n我还会使用 LIMIT 进行分页查询，并尽量减少 OFFSET 的使用，以提高查询性能。同时，我会创建覆盖索引以减少回表查询的需要。此外，我会重写复杂的子查询为连接查询，减少查询的复杂度和执行时间。\n16. 事务的特性是什么？可以详细说一下吗？ 事务的特性是ACID，即原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。例如，A向B转账500元，这个操作要么都成功，要么都失败，体现了原子性。转账过程中数据要保持一致，A扣除了500元，B必须增加500元。隔离性体现在A向B转账时，不受其他事务干扰。持久性体现在事务提交后，数据要被持久化存储。\n17. 并发事务带来哪些问题？ 脏读（Dirty Read）： 脏读发生在一个事务读取了另一个未提交事务修改的数据。如果该修改被回滚，那么读取的数据就是无效的。 不可重复读（Non-Repeatable Read）： 这发生在一个事务中多次读取同一数据，由于其他事务的修改，导致读取的数据在事务内出现不一致。 幻读（Phantom Read）： 幻读是指在一个事务中，两次读取同一范围的数据，第二次读取的结果包含了另一个并发事务提交的新数据。 丢失更新（Lost Update）： 当两个或多个事务同时更新同一行数据时，一个事务的更新可能被另一个事务的更新覆盖，导致数据丢失。 死锁（Deadlock）： 当两个或多个事务相互等待对方释放资源时，可能导致死锁，这会阻塞事务的进一步执行。 长时间运行的事务： 长时间运行的事务可能会锁定大量资源，这会阻塞其他事务，影响数据库性能。 系统资源竞争： 并发事务可能导致数据库的资源（如锁、日志空间、内存等）竞争，影响系统稳定性。 18. 怎么解决这些问题呢？MySQL的默认隔离级别是？ MySQL 的 InnoDB 存储引擎默认隔离级别是 可重复读（REPEATABLE READ）\n脏读：可将事务隔离级别设置为 “读已提交（READ COMMITTED）” 及以上级别来防止，这样事务只能读取到已提交的数据，避免读取到未提交的脏数据。 不可重复读：通常需要将事务隔离级别设置为 “可重复读（REPEATABLE READ）” 或更高的 “串行化（SERIALIZABLE）” 级别。在 “可重复读” 隔离级别下，事务在第一次读取数据时会对数据加锁，在事务提交前，其他事务无法修改该数据，从而保证在同一事务内多次读取同一数据的结果是一致的。 幻读：通常将事务隔离级别设置为 “串行化（SERIALIZABLE）” 可避免，此级别会对事务操作的范围数据加锁，阻止其他事务在该范围内插入或删除数据，但会降低并发性能。 丢失更新：可使用排他锁或乐观锁机制，确保在更新数据时只有一个事务能成功执行更新操作，防止更新被覆盖。 死锁：合理设计事务逻辑，避免事务之间循环等待资源；也可设置死锁检测机制，当检测到死锁时自动回滚其中一个事务来打破死锁。 长时间运行的事务：优化事务逻辑，减少不必要的操作和资源占用；对于确实需要长时间运行的事务，可适当调整资源配置和数据库参数。 系统资源竞争：合理配置数据库资源，根据并发量等情况调整缓存大小、连接数等参数；优化事务执行顺序，减少资源竞争。 19. 事务是怎么实现的，主要通过哪些机制来确保其 ACID 特性？ 事务的实现主要依赖于几个关键机制：锁机制、日志系统（包括 redo log 和 undo log），以及 MVCC（多版本并发控制）。这些机制共同协作以确保事务的 ACID 特性：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。\n锁机制： 锁机制用于控制数据的并发访问，确保在事务进行中数据不会被其他事务修改，从而满足隔离性。根据锁的粒度不同，可以是行级锁、表级锁等。 redo log（重做日志）： redo log 记录了事务对数据所做的修改。在系统崩溃后，可以通过重放这些日志来恢复数据，从而满足持久性要求。 undo log（回滚日志）： undo log 记录了事务执行前的数据状态，用于在事务回滚时恢复到事务开始前的状态，满足原子性和隔离性。 MVCC（多版本并发控制）： MVCC 是一种并发控制机制，它通过为每个事务提供一个数据的一致性视图来满足隔离性。这样，即使数据被其他事务修改，当前事务也看不到这些修改，从而避免了脏读和不可重复读的问题。 20. undo log和redo log的区别是什么？ undo log（撤销日志）和redo log（重做日志）\nundo log 主要用于事务回滚时恢复数据，它记录了事务更改之前的数据状态，确保我们可以撤销事务对数据的修改，保持数据的一致性。这有助于维护事务的原子性，即事务要么完全执行，要么完全不执行。\n相反，redo log 用于在系统故障后恢复数据，它记录了事务提交时的数据更改，确保这些更改在系统重启后可以被重新应用，从而保障事务的持久性。这有助于确保即使在系统崩溃的情况下，已提交的事务更改也不会丢失。\n21. 那事务的隔离级别有哪些，它们有什么区别？ 事务的隔离级别通常有四种，由低到高分别是：读未提交（Read Uncommitted）、读已提交（Read Committed）、可重复读（Repeatable Read）、串行化（Serializable）。\n读未提交：允许事务读取其他事务未提交的数据，可能会导致脏读。 读已提交：只能读取已经提交的数据，避免了脏读，但可能会出现不可重复读。 可重复读：保证了在同一事务中多次读取同样的数据结果是一致的，避免了不可重复读，但可能会出现幻读。 串行化：最高的隔离级别，通过强制事务串行执行来避免脏读、不可重复读和幻读，但性能开销也最大。 22. 事务中的隔离性是如何保证的呢？（你解释一下MVCC） 事务的隔离性是指当多个事务并发执行时，数据库如何管理这些事务对数据的访问，以防止数据不一致性的问题。MySQL 使用多版本并发控制（MVCC）来提供事务隔离。\n事务的隔离性通过锁和多版本并发控制（MVCC）来保证。MVCC通过维护数据的多个版本来避免读写冲突。底层实现包括隐藏字段、undo log和read view。隐藏字段包括trx_id和roll_pointer。trx_id，它是一个事务ID，用于标识对数据行进行更改的事务。undo log记录了不同版本的数据，通过roll_pointer形成版本链。read view定义了不同隔离级别下的快照读，决定了事务访问哪个版本的数据。\n23. MySQL主从同步原理是什么？ MySQL的主从同步是一种数据库复制技术，它允许将一个数据库服务器（主库）的数据变更复制到另一个或多个服务器（从库）上。\nMySQL主从复制的核心是二进制日志（Binlog）。步骤如下：\n主库在事务提交时记录数据变更到Binlog。 从库连接到主库并读取 Binlog，将 Binlog 中的事件写入到自己的中继日志（Relay Log）。 从库根据中继日志中的事件，重放（Replay）这些事件到自己的数据中，从而实现数据的同步。 24. 你们项目用过MySQL的分库分表吗？ 垂直分库：垂直分库是按照业务将不同的表拆分到不同的数据库中\n我们采用微服务架构，每个微服务对应一个数据库，是根据业务进行拆分的，这个其实就是垂直拆分。\n水平分库：水平分库是将数据按照一定的规则（如用户 ID 取模、哈希等）分布到不同的数据库中。比如，根据用户 ID 对 10 取模，将用户数据分布到 10 个不同的数据库中，每个数据库都保存着完整的数据表结构\n垂直分表：垂直分表是将一张表按照列的相关性拆分成多张表。例如，将一个包含大量字段的用户表，拆分为用户基本信息表和用户扩展信息表。垂直分表适合表中存在不常用并且占用了大量空间的表拆分出去。\n水平分表：水平分表是将一张表的数据按照行进行拆分。例如按照用户 ID 的范围或者哈希值将数据拆分到不同的表中。水平分表就适合用户表行数很多的情况下，一般单表行数超过5000万就得分表，如果单表的数据比较复杂那可能2000万甚至1000万就得分了。\n四、Redis 一、Redis 基础数据结构(五种) （一）String（字符串）\n结构特点：Redis 中最基础的数据类型，可存储字符串、整数或浮点数，最大能存储 512MB 的数据。在内存中以简单动态字符串（SDS）形式存储，相比传统 C 字符串，SDS 具有获取长度时间复杂度为 O (1)、杜绝缓冲区溢出等优势。 应用场景 数据缓存：常用来缓存各类常规数据，像用户的 session 信息、用于身份验证的 token、序列化后的对象等。通过将这些数据缓存于 Redis，可显著减少数据库查询次数，提升系统响应速度。例如在 Web 应用中，频繁访问的用户信息可先从 Redis 的 String 类型缓存中获取，若不存在再查询数据库并写入缓存。 计数场景：借助 INCR、INCRBY 等命令，可方便地对数值进行原子递增操作，用于统计用户单位时间内的请求数、页面单位时间的访问数等。比如在一个简单限流系统中，可设定用户每分钟最多请求 100 次，通过对用户请求计数（存储在 String 类型键中）与阈值比较，超过则限流。 分布式锁：利用 SETNX（SET if Not eXists）命令可实现简易分布式锁。当一个线程执行 SETNX key value 时，若键不存在，会设置成功并获取锁；若键已存在，获取锁失败。释放锁时可通过删除该键实现。但这种简单实现未处理锁超时等复杂情况，实际应用中需完善。 共享配置信息：存储应用程序的配置参数，如数据库连接字符串、系统开关配置等。应用启动时从 Redis 读取配置，配置变更时可实时更新 Redis 中的值，应用通过监听机制获取变更，实现配置动态更新。 与 Hash 存储对象对比 存储方式：String 存储的是序列化后的整个对象，比如将一个包含多个字段的 Java 对象序列化为 JSON 字符串后存储。Hash 则是将对象的每个字段作为一个键值对单独存储，例如存储一个用户对象，Hash 可将用户的姓名、年龄、邮箱等字段分别以 “field:value” 形式存储。 内存占用：一般情况下，缓存相同数量的对象数据，String 消耗内存约为 Hash 的一半。因为 Hash 结构本身会有额外开销用于存储字段名等信息。但如果对象字段较少，这种内存差异可能不明显。 查询与修改灵活性：String 适合对象整体读取和更新场景。若要获取或修改对象部分字段，需先反序列化整个对象，操作后再序列化存储，性能开销大。Hash 可直接对单个字段进行查询、修改、添加操作，无需处理整个对象，在购物车这类商品频繁变动场景中优势明显。例如购物车中商品数量、添加新商品等操作，使用 Hash 可高效完成。 建议：大多数场景下，若对对象操作以整体为主，或系统对内存资源敏感，优先使用 String 存储对象数据。但对对象部分字段频繁操作的场景，Hash 更合适。 （二）List（列表）\n结构特点：按插入顺序排序的字符串链表，可在链表头部（LPUSH）或尾部（RPUSH）插入元素，也可从头部（LPOP）或尾部（RPOP）删除元素。支持获取指定范围元素（LRANGE），时间复杂度为 O (S + N)，S 为起始位置偏移量，N 为返回元素数量。 应用场景 消息队列：可作为简单消息队列使用。生产者通过 RPUSH 向列表尾部发送消息，消费者使用 LPOP 从列表头部读取消息，实现消息的有序处理。但 Redis 原生 List 作为消息队列缺乏一些高级特性，如消息持久化、ACK 机制等，适用于对消息可靠性要求不高的简单场景。 最新消息展示：用于存储最新发布的消息、文章等内容。例如在社交媒体应用中，用户发布的动态可按时间顺序通过 RPUSH 存入 List，展示时使用 LRANGE 获取最新的若干条动态。 操作日志记录：记录系统操作日志，每次操作相关信息（如操作时间、操作人、操作内容）作为一个元素，通过 RPUSH 追加到 List 中。后续可根据需要查询特定时间段或特定类型的操作记录。 相关命令 LPUSH key value [value\u0026hellip;]：将一个或多个值插入到列表头部。 RPUSH key value [value\u0026hellip;]：将一个或多个值插入到列表尾部。 LPOP key：移除并返回列表的头元素。 RPOP key：移除并返回列表的尾元素。 LRANGE key start stop：返回列表中指定区间内的元素，start 和 stop 为元素索引，0 表示第一个元素， - 1 表示最后一个元素。 （三）Set（集合）\n结构特点：无序的字符串集合，集合中元素具有唯一性，重复添加相同元素不会产生新副本。内部实现基于哈希表，添加、删除、查找元素的时间复杂度平均为 O (1)。 应用场景 去重场景：在数据处理中，可利用 Set 的唯一性对数据进行去重。例如统计网站访问用户的唯一 IP 地址，每次将访问 IP 通过 SADD 命令添加到 Set 中，最终 Set 的元素数量即为唯一 IP 数量。 标签管理：用于管理对象标签。如在一个商品管理系统中，每个商品可关联多个标签（如电子产品、打折商品等），将商品 ID 作为 key，标签作为 Set 的元素存储。通过 SISMEMBER 命令可判断商品是否具有某个标签，通过 SMEMBERS 可获取商品所有标签。 交集、并集、差集运算：在社交应用中，可通过集合运算实现共同关注、共同爱好等功能。例如，用户 A 的关注列表和用户 B 的关注列表作为两个 Set，通过 SINTER 命令求交集，可得到 A 和 B 共同关注的人。 相关命令 SADD key member [member\u0026hellip;]：向集合中添加一个或多个成员。 SREM key member [member\u0026hellip;]：移除集合中的一个或多个成员。 SISMEMBER key member：判断成员是否在集合中，存在返回 1，不存在返回 0。 SMEMBERS key：返回集合中的所有成员。 SINTER key [key\u0026hellip;]：返回多个集合的交集。 SUNION key [key\u0026hellip;]：返回多个集合的并集。 SDIFF key [key\u0026hellip;]：返回多个集合的差集（第一个集合减去其他集合的元素）。 （四）Hash（散列）\n结构特点：由键值对组成的集合，适合存储对象。每个键值对的键和值都是字符串类型。内部采用哈希表存储，在查找、插入、删除单个字段时，时间复杂度平均为 O (1)。 应用场景 存储对象：如用户信息、商品信息等对象的存储。以用户 ID 为 key，用户的各个属性（姓名、年龄、地址等）为 field，对应的值为 value。与 String 存储对象相比，Hash 可灵活操作单个字段，无需序列化和反序列化整个对象。 购物车系统：购物车场景中，以用户 ID 为 key，商品 ID 为 field，商品数量为 value。方便对购物车中商品进行添加、修改数量、删除等操作。例如，用户添加商品时，若商品已存在，使用 HINCRBY 命令增加商品数量；删除商品时，使用 HDEL 命令。 配置管理：存储应用程序的配置信息，与 String 存储配置相比，Hash 可对单个配置项进行修改，无需重新设置整个配置字符串。如数据库连接配置，可将主机、端口、用户名、密码等字段分别存储在 Hash 中。 相关命令 HSET key field value：为哈希表中的字段赋值。 HGET key field：获取哈希表中指定字段的值。 HDEL key field [field\u0026hellip;]：删除哈希表中的一个或多个字段。 HINCRBY key field increment：为哈希表中的字段值增加指定的整数。 HGETALL key：获取哈希表中的所有字段和值。 （五）Zset（有序集合）\n结构特点：每个成员都关联一个分数的字符串集合，通过分数对成员进行从小到大排序，成员唯一但分数可重复。内部通过跳跃表和哈希表两种数据结构实现，在插入、删除、查找元素以及范围查询方面性能较好，时间复杂度为 O (log N)，N 为集合元素数量。 应用场景 排行榜系统：常用于各种排行榜场景，如直播间送礼物排行榜、游戏玩家积分排行榜、商品销量排行榜等。将用户 ID 或商品 ID 作为成员，对应的分数（如礼物价值、玩家积分、商品销量）作为排序依据。通过 ZRANGE（从小到大）或 ZREVRANGE（从大到小）命令获取排行榜数据。 带权重的任务队列：在任务调度系统中，每个任务可关联一个权重（分数），根据权重决定任务执行顺序。通过 ZADD 命令添加任务及权重，通过 ZPOPMIN 或 ZPOPMAX 命令获取并移除权重最小或最大的任务。 时间序列数据：如股票价格随时间变化数据，时间作为分数，股票价格作为成员。可方便地查询某个时间段内的股票价格数据，通过 ZRANGEBYSCORE 命令实现。 相关命令 ZADD key score member [score member\u0026hellip;]：向有序集合中添加一个或多个成员，或更新已存在成员的分数。 ZRANGE key start stop [WITHSCORES]：返回有序集合中指定范围内的成员，按分数从小到大排序，WITHSCORES 选项可同时返回成员的分数。 ZREVRANGE key start stop [WITHSCORES]：返回有序集合中指定范围内的成员，按分数从大到小排序，WITHSCORES 选项可同时返回成员的分数。 ZREVRANK key member：返回有序集合中指定成员的排名（从大到小排序）。 ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]：返回有序集合中分数在指定区间内的成员，可通过 LIMIT 选项指定返回结果的偏移量和数量。 二、Redis 特殊数据结构(八种) （一）HyperLogLogs（基数统计）\n结构特点：用于近似统计集合中唯一元素的数量，通过概率算法实现，在内存使用上极为高效。只需少量内存（12KB）即可统计大量数据，误差率约为 0.81%。内部通过稀疏矩阵和稠密矩阵存储数据。 应用场景 网页 UV 统计：统计网页的独立访客数。每次用户访问网页时，将用户 ID 通过 PFADD 命令添加到对应的 HyperLogLog 中，最后使用 PFCOUNT 命令获取 UV 数量。相比传统存储每个用户 ID 再统计唯一值的方式，HyperLogLog 大大节省内存。 广告曝光统计：在广告投放系统中，统计广告的独立曝光次数。将每次广告曝光的设备 ID 或用户 ID 记录到 HyperLogLog 中，可高效获取独立曝光数，为广告效果评估提供数据支持。 相关命令 PFADD key element [element\u0026hellip;]：向 HyperLogLog 中添加一个或多个元素。 PFCOUNT key [key\u0026hellip;]：返回一个或多个 HyperLogLog 的近似基数。 PFMERGE destkey sourcekey [sourcekey\u0026hellip;]：将多个 HyperLogLog 合并为一个。 （二）Bitmap（位存储）\n结构特点：基于字符串类型实现，通过位操作来存储和处理数据。每个字符串可存储 2^32 - 1 个位，即 512MB 大小的位数据。通过 SETBIT 命令设置某位的值（0 或 1），GETBIT 命令获取某位的值。 应用场景 用户活跃状态统计：以日期（精确到天）作为 key，用户 ID 为 offset。当用户在当天活跃过时，使用 SETBIT 命令将对应位置设置为 1。例如，统计 2023 年 10 月 1 日活跃用户，SETBIT 20231001 user_id 1。通过 BITCOUNT 命令可统计当天活跃用户数量，通过 BITOP 命令可进行位运算，如统计连续多日活跃用户。 权限管理：用 Bitmap 表示用户权限，每个权限对应一位。例如，用户具有读取权限，对应位设为 1；无写入权限，对应位设为 0。通过位运算可快速判断用户是否具有某组权限，如判断用户是否同时具有读取和执行权限。 相关命令 SETBIT key offset value：设置或清除指定 key 偏移量上的位值（0 或 1）。 GETBIT key offset：获取指定 key 偏移量上的位值。 BITCOUNT key [start end]：统计指定 key 中位值为 1 的数量，start 和 end 可选，用于指定字节范围。 BITOP operation destkey key [key\u0026hellip;]：对一个或多个 key 进行位运算（AND、OR、XOR、NOT），结果存储在 destkey 中。 （三）Geospatial（地理位置）\n结构特点：用于存储地理位置信息，并支持基于地理位置的查询。本质上是通过 Zset 实现，将地理位置的经纬度信息编码后作为分数存储，地理位置标识（如城市名、店铺名）作为成员。支持查询附近位置、计算距离等操作。 应用场景 附近位置查询：在地图应用、外卖配送、共享单车等场景中，用于查找用户附近的商家、配送员、共享单车等。例如，外卖应用中，用户可通过该功能查找附近可配送的餐厅，餐厅位置信息事先存储在 Redis 的 Geospatial 结构中，通过 GEORADIUS 命令查询。 距离计算：计算两个地理位置之间的距离。如在物流配送中，计算仓库与配送地址的距离，为配送路线规划提供数据支持。通过 GEODIST 命令实现距离计算。 相关命令 GEOADD key longitude latitude member [longitude latitude member\u0026hellip;]：将一个或多个地理位置信息添加到指定 key 中。 GEODIST key member1 member2 [m|km|ft|mi]：计算两个地理位置之间的距离，单位可指定为米（m）、千米（km）、英尺（ft）、英里（mi）。 GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count]：以指定经纬度为中心，返回指定半径内的地理位置，可选择返回地理位置的坐标、距离、哈希值，COUNT 选项可限制返回结果数量。 GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count]：与 GEORADIUS 类似，只是以已存在的地理位置成员为中心进行查询。 1. 什么是缓存穿透？怎么解决？ 嗯，我想一下。缓存穿透是指查询一个一定不存在的数据，由于存储层查不到数据因此不写入缓存，这将导致这个不存在的数据每次请求都要到 DB 去查询，可能导致 DB 挂掉。这种情况大概率是遭到了攻击。解决方案的话，我们通常都会用布隆过滤器来解决它。\n解决方法1：缓存空对象\n当查询数据库中不存在的数据时，我们不是直接返回空，而是将一个空对象（比如一个空的JSON对象或者一个标记值）存入缓存，并设置一个较短的TTL（存活时间）。这样，当下次再查询相同的数据时，可以直接从缓存中获取到这个空对象，而无需再次查询数据库，从而避免了对数据库的无效访问。\n**缺点：**虽然实现简单，但它会带来一些额外的内存消耗，因为即使是空对象，也需要占用一定的缓存空间。此外，由于设置了TTL，在缓存过期之前，即使数据库中已经添加了相应的数据，查询时仍然会返回空对象，这可能会导致短期内的数据不一致。\n解决方法2：布隆过滤器\n布隆过滤器是一种概率型数据结构，它可以用来判断一个元素是否在一个集合中。我们当时使用的是Redisson实现的布隆过滤器。它的底层原理是，先初始化一个比较大的数组，里面存放的是二进制0或1。一开始都是0，当一个key来了之后，经过3次hash计算，模数组长度找到数据的下标，然后把数组中原来的0改为1。这样，三个数组的位置就能标明一个key的存在。当需要判断一个元素是否存在时，通过相同的哈希函数计算出该元素在位数组上的位置，如果这些位置上的值都为1，则认为该元素可能存在；如果任何一个位置上的值为0，则该元素一定不存在。在缓存穿透的场景中，我们可以将数据库中存在的数据对应的key存入布隆过滤器，当查询一个key时，先通过布隆过滤器判断该key是否存在，如果不存在，直接返回，避免查询数据库。\n优点：布隆过滤器的内存占用相对较少，因为它只需要一个位数组来存储信息，相比直接缓存大量的key值，节省了很多空间。而且它没有多余的key，不会像缓存空对象那样占用额外的缓存资源。\n缺点：布隆过滤器的实现相对复杂，需要理解和使用多个哈希函数以及位数组等数据结构。而且它存在误判的可能，即当布隆过滤器判断一个key存在时，实际上该key可能并不存在，这就增加了穿透的风险。另外，布隆过滤器无法删除数据，一旦一个key被添加到布隆过滤器中，就无法单独将其移除，这在某些场景下可能会带来一些问题。\n2. 什么是缓存击穿？怎么解决？ 缓存击穿问题，也被称为热点 Key 问题。它是指在高并发场景下，一个被频繁访问且缓存重建业务较复杂的 Key 突然失效了，导致大量的请求直接穿透到数据库，给数据库带来巨大的冲击，从而引发系统性能下降甚至崩溃的情况。\n解决方法1：基于互斥锁的解决方案\n就是当线程查询缓存未命中时，尝试去获取互斥锁，然后在重建缓存数据，在这段时间里，其他线程也会去尝试获取互斥锁，如果失败就休眠一段时间，并继续，不断重试，等到数据重建成功，其他线程就可以命中数据了。这样就不会导致缓存击穿。\n这里我们获取互斥锁可以使用redis中string类型中的setnx方法 ，因为setnx方法是在key不存在的情况下才可以创建成功的，所以我们重建缓存时，使用setnx来将锁的数据加入到redis中，并且通过判断这个锁的key是否存在，如果存在就是获取锁成功，失败就是获取失败，这样刚好可以实现互斥锁的效果。释放锁就更简单了，直接删除我们存入的锁的 Key 来释放锁。\n优点：\n​\t**内存占用小：**由于不需要额外存储过期时间等信息，内存占用相对较少。\n​\t**一致性高：**所有线程最终都能获取到最新的缓存数据，数据一致性得到了保证。\n​\t**实现简单：**通过 Redis 的 SETNX 方法和简单的逻辑控制，就可以实现互斥锁，实现起来相对容易。\n缺点：\n​\t**性能较低：**多个线程在获取锁失败后会不断重试，导致线程阻塞，降低了系统的并发性能。\n​\t**容易出现死锁：**如果在获取锁后，线程出现异常或长时间未释放锁，可能会导致其他线程一直等待，从而出现死锁的情况。\n解决方法2：基于逻辑过期解决缓存击穿问题\n原理：给 Redis 缓存字段中添加一个过期时间字段，而不是直接设置缓存的过期时间。当线程查询缓存的时候，先判断是否已经过期。如果过期，就获取互斥锁，并开启一个子线程进行缓存重建任务，直到子线程完成任务后，释放锁。在这段时间内，其他线程获取互斥锁失败后，并不是继续等待重试，而是直接返回旧数据。\n实现方式：所谓的逻辑过期，类似于逻辑删除，并不是真正意义上的过期，而是新增一个字段，用来标记 Key 的过期时间。这样能够避免 Key 过期而被自动删除，从而使数据永不过期，从根本上解决因为热点 Key 过期导致的缓存击穿。一般在搞活动时，比如抢优惠券、秒杀等场景，请求量比较大就可以使用逻辑过期，等活动一过就手动删除逻辑过期的数据。逻辑过期一定要先进行数据预热，将热点数据加载到缓存中。逻辑过期时间根据具体业务而定，逻辑过期过长，会造成缓存数据的堆积，浪费内存；过短会造成频繁缓存重建，降低性能。所以设置逻辑过期时间时需要实际测试和评估不同参数下的性能和资源消耗情况，可以通过观察系统的表现，在业务需求和性能要求之间找到一个平衡点。\n优点：\n​\t性能高：通过开启子线程重建缓存，使原来的同步阻塞变成异步，提高了系统的响应速度，能够更好地应对高并发场景。\n缺点：\n​\t内存占用较大：需要额外存储过期时间字段，增加了内存的占用。\n​\t容易出现脏读：在缓存重建期间，其他线程可能会获取到旧数据，从而导致脏读的情况。\n3. 什么是缓存雪崩？怎么解决？ 缓存雪崩是指在缓存系统中，大量缓存 Key 同时失效，或者缓存服务（如 Redis）整体宕机，导致原本应该从缓存获取的数据全部穿透到数据库，从而给数据库带来巨大的压力，甚至可能导致数据库崩溃。这种情况通常会引发整个系统的性能问题，甚至导致服务不可用。\n具体来说，缓存雪崩可以分为两种情况：\n大量 Key 同时失效：如果缓存中的 Key 都设置了相同的过期时间，那么在某一时刻，这些 Key 会同时失效。此时，大量请求会同时查询数据库，导致数据库负载瞬间增加。 缓存服务宕机：如果整个缓存服务（如 Redis 集群）宕机，所有原本依赖缓存的请求都会直接查询数据库，同样会给数据库带来巨大压力。 解决方案1： 给不同的 Key 设置随机的 TTL\n为了避免大量 Key 同时失效，可以在设置缓存时，为每个 Key 的 TTL（过期时间）添加一个随机值。例如，原本的过期时间是 10 分钟，可以在此基础上随机增加 1-5 分钟。这样，每个 Key 的过期时间就会分散开来，很难同时失效。\n解决方案2： 利用 Redis 集群提高服务的可用性\n通过部署 Redis 集群，将缓存数据分散到多个 Redis 实例中。即使某个 Redis 实例宕机，其他实例仍然可以正常工作，从而提高缓存服务的整体可用性。\n解决方案3： 添加降级限流策略\n在缓存层和数据库层之间添加降级限流策略，当请求量过高时，通过快速失败机制直接返回错误或默认值，避免请求穿透到数据库。\n解决方案4： 添加多级缓存\n在应用层添加多级缓存，除了本地缓存（如 Ehcache）和分布式缓存（如 Redis）外，还可以在数据库层添加缓存（如数据库的查询缓存）。这样，即使分布式缓存失效，还可以通过本地缓存或数据库缓存来缓解压力。\n实现方式：\n在应用层使用本地缓存（如 Ehcache）作为第一级缓存。 在分布式缓存（如 Redis）作为第二级缓存。 在数据库层使用查询缓存作为第三级缓存。 4. redis作为缓存，mysql的数据如何与redis进行同步呢？（双写一致性） 我们当时采用了读写锁来保证强一致性。具体来说，我们使用了 Redisson 实现的读写锁。\n在读取数据时，我们添加共享锁，这样可以保证读读不互斥，但读写互斥。这意味着多个线程可以同时读取数据，但如果有线程正在写入数据，其他线程就不能读取，从而避免了脏读。而在更新数据时，我们添加排他锁，这样无论是读操作还是写操作，都会被互斥，确保在写数据的同时，不会有其他线程读取数据，进一步避免了脏数据。\n这里面需要注意的是，读方法和写方法上需要使用同一把锁才行。这样可以确保在任何时刻，数据的一致性都能得到保证。\n5. 那这个排他锁是如何保证读写、读读互斥的呢？ 其实排他锁底层使用的是 SETNX，它保证了同时只能有一个线程操作锁住的方法。当一个线程获取了排他锁后，其他线程无论是尝试读取还是写入，都会被阻塞，直到锁被释放。\n5. 你听说过延时双删吗？为什么不用它呢？ 延迟双删，如果是写操作，我们先把缓存中的数据删除，然后更新数据库，最后再延时删除缓存中的数据。其中，这个延时多久不太好确定。在延时的过程中，可能会出现脏数据，并不能保证强一致性，所以没有采用它。\n6. Redis 数据的持久化是怎么做的？ 候选人：在 Redis 中提供了两种主要的数据持久化方式：RDB（Redis Database）和 AOF（Append Only File）。\n7. 这两种持久化方式有什么区别呢？ 候选人：RDB 是一个快照文件，它会定期将 Redis 内存中的数据写入到磁盘上的一个 RDB 文件中。当 Redis 实例宕机后，可以从 RDB 文件中恢复数据。RDB 文件是二进制格式的，体积相对较小，恢复速度较快，但可能会丢失最后一次快照之后的数据。\nAOF 是追加文件，它会将 Redis 执行的每个写命令追加到 AOF 文件中。当 Redis 实例宕机后，可以从 AOF 文件中重新执行这些命令来恢复数据。AOF 文件是文本格式的，体积相对较大，恢复速度较慢，但数据丢失的风险更小。\n8. 这两种方式，哪种恢复的比较快呢？ 候选人：RDB 恢复速度更快，因为它是一个二进制文件，体积较小，加载和恢复数据的速度通常比 AOF 快。然而，RDB 的缺点是可能会丢失最后一次快照之后的数据。AOF 恢复速度较慢，因为它需要重新执行文件中的所有命令来恢复数据，但它的数据完整性更高，丢失数据的风险更小。\n在实际项目中，我们通常会结合使用 RDB 和 AOF 来实现数据的持久化。例如，我们会在项目中设置 RDB 每隔一定时间（如每小时）生成一次快照，同时开启 AOF 并设置为每秒批量写入一次命令。这样可以在保证数据恢复速度的同时，最大限度地减少数据丢失的风险。\n9. 你们项目中具体是如何设置的呢？ 候选人：在我们的项目中，我们采用了以下配置：\nRDB 配置：\n我们设置了 RDB 每小时生成一次快照，这样可以在 Redis 实例宕机时，从最近的快照文件中恢复大部分数据。\n配置示例：\n1 save 3600 1 AOF 配置：\n我们开启了 AOF，并设置了每秒批量写入一次命令，这样可以在 Redis 实例宕机时，从 AOF 文件中恢复最近的写操作。\n配置示例：\n1 2 appendonly yes appendfsync everysec 通过这种配置，我们既保证了数据恢复的速度，又最大限度地减少了数据丢失的风险。在实际运行中，这种组合方式表现出了良好的性能和可靠性。\n10. Redis的数据过期策略有哪些？ 候选人：嗯~，在redis中提供了两种数据过期删除策略。第一种是惰性删除。在设置该key过期时间后，我们不去管它。当需要该key时，我们检查其是否过期。如果过期，我们就删掉它；反之，返回该key。第二种是定期删除。就是说，每隔一段时间，我们就对一些key进行检查，并删除里面过期的key。定期清理的两种模式是：1) SLOW模式，是定时任务，执行频率默认为10hz，每次不超过25ms，可以通过修改配置文件redis.conf的hz选项来调整这个次数；2) FAST模式，执行频率不固定，每次事件循环会尝试执行，但两次间隔不低于2ms，每次耗时不超过1ms。Redis的过期删除策略是：惰性删除 + 定期删除两种策略配合使用。\n11. Redis的数据淘汰策略有哪些？ 候选人：嗯，这个在redis中提供了很多种，默认是noeviction，不删除任何数据，内部不足时直接报错。这个可以在redis的配置文件中进行设置。里面有两个非常重要的概念：一个是LRU，另外一个是LFU。LRU的意思就是最少最近使用。它会用当前时间减去最后一次访问时间。这个值越大，则淘汰优先级越高。LFU的意思是最少频率使用。它会统计每个key的访问频率。值越小，淘汰优先级越高。我们在项目中设置的是allkeys-lru，它会挑选最近最少使用的数据进行淘汰，把一些经常访问的key留在redis中。\n12. 数据库有1000万数据，Redis只能缓存20w数据。如何保证Redis中的数据都是热点数据？ 候选人：嗯，我想一下()。可以使用allkeys-lru（挑选最近最少使用的数据淘汰）淘汰策略。那留下来的都是经常访问的热点数据。\n13. Redis的内存用完了会发生什么？ 候选人：嗯~，这个要看redis的数据淘汰策略是什么。如果是默认的配置，redis内存用完以后则直接报错。我们当时设置的是allkeys-lru策略，把最近最常访问的数据留在缓存中。\n14. Redis分布式锁如何实现 在Redis中提供了一个命令SETNX（SET if not exists）。由于Redis是单线程的，使用这个命令之后，只能有一个客户端对某一个key设置值。在没有过期或删除key的时候，其他客户端是不能设置这个key的。\n15. 那你如何控制Redis实现分布式锁的有效时长呢？ SETNX指令不好控制有效时长。我们采用的是Redisson框架实现的。在Redisson中需要手动加锁，并且可以控制锁的失效时间和等待时间。当锁住的一个业务还没有执行完成时，Redisson会引入一个看门狗机制，每隔一段时间检查当前业务是否还持有锁。如果持有，就增加加锁的持有时间。当业务执行完成之后，需要使用释放锁。在高并发下，一个业务执行很快时，客户1持有锁，客户2来了以后并不会马上被拒绝，而是自旋不断尝试获取锁。如果客户1释放之后，客户2就可以马上持有锁，性能也得到了提升。\n16. Redisson实现的分布式锁是可重入的吗？它是怎么实现的？ 是的，Redisson 实现的分布式锁是可重入的。可重入锁允许同一个线程多次获取同一把锁而不会被阻塞，这可以有效避免死锁问题，同时让代码逻辑更清晰。\nRedisson 如何实现可重入锁\nRedisson 是基于 Redis 的哈希结构来存储锁信息的。打个比方，我们有个叫 “myLock” 的锁，这就是锁的唯一标识，相当于哈希结构里的 Key。而每个尝试获取锁的线程都有自己唯一的标识，像线程 ID 或者 UUID，这就是哈希结构里的 Field。线程获取锁的次数，也就是重入次数，就是哈希结构里的 Value。\n加锁过程\n当一个线程想去获取锁的时候，Redisson 首先会检查这个锁对应的 Key 存不存在。要是不存在，那就说明当前没有线程持有这把锁，Redisson 就会创建这个锁，把 Field 设成当前线程的标识，Value 设为 1，同时给锁设置一个过期时间。要是锁已经存在，Redisson 就会去检查 Field 是不是和当前线程的标识一样。如果一样，那就意味着当前线程已经持有这把锁了，Redisson 就把 Value 加 1，并且刷新锁的过期时间。要是不一样，那就表示锁被其他线程占着，当前线程就得等着锁被释放。\n释放锁过程\n释放锁的时候，Redisson 会先看看锁的 Field 和当前线程标识是不是一致。如果一致，就把 Value 减 1。要是减完之后 Value 变成 0 了，那就说明当前线程已经完全释放了这把锁，Redisson 就把锁对应的 Key 删除。要是 Value 还大于 0，说明当前线程还有重入的情况，还持有锁，Redisson 就刷新一下锁的过期时间。\n防止死锁\nRedisson 在防止死锁方面也有很实用的机制。一方面，加锁的时候会给锁设置过期时间，就算某个线程出问题了，一直不释放锁，到时间了锁也会自动被删除。另一方面，它的可重入机制也能避免因为线程嵌套调用导致的死锁。\n可重入锁\nRedisson 的可重入锁优势也很明显。从线程安全角度看，只有持有锁的线程才能释放锁，这就保证了不会出现线程安全问题。在性能上，它通过 Lua 脚本确保加锁和释放锁的操作是原子性的，避免了竞态条件，效率很高。\n17. Redisson实现的分布式锁能解决主从一致性的问题吗？ 不能完全解决。在Redis的主从复制模式下，主节点和从节点之间存在数据同步的延迟。当主节点宕机时，从节点可能会被提升为新的主节点，但此时锁数据可能尚未完全同步，导致锁失效。\n例如，当线程1在主节点上加锁成功后，主节点数据还未完全同步到从节点。如果此时主节点宕机，从节点被提升为新的主节点，线程2可能会在新的主节点上加锁成功，导致两个线程同时持有一把锁。\n18. 如果业务非要保证数据的强一致性，这个该怎么解决呢？ 使用Redisson的multiLock Redisson提供了multiLock方案来解决主从一致性问题。其核心思想是：\n在多个独立的Redis节点上分别创建锁。 只有当在所有指定的Redis节点上都成功获取锁时，才算获取锁成功。 这种方式的优点是可以避免主从同步不一致时锁失效的问题。但缺点是运维成本高，实现复杂，且至少需要三台Redis服务器。\n使用其他分布式锁实现 如果业务对数据一致性要求极高，建议使用其他分布式锁实现，如基于ZooKeeper的分布式锁。ZooKeeper的分布式锁可以保证强一致性，适用于对一致性要求严格的应用场景。\n19. Redis集群有哪些方案，知道吗？ 在Redis中提供的集群方案总共有三种：主从复制、哨兵模式、Redis分片集群。\n20. 那你来介绍一下主从同步。 单节点Redis的并发能力有上限，可以通过搭建主从集群实现读写分离，一般是一主多从，主节点负责写数据，从节点负责读数据。主节点写入数据后，需要把数据同步到从节点中。\n21. 能说一下主从同步数据的流程吗？ 嗯~~，好！主从同步分为了两个阶段，一个是全量同步，一个是增量同步。\n全量同步是指从节点第一次与主节点建立连接的时候使用全量同步，流程是这样的：\n第一：从节点请求主节点同步数据，其中从节点会携带自己的replication id和offset偏移量。\n第二：主节点判断是否是第一次请求，主要判断的依据就是，主节点与从节点是否是同一个replication id，如果不是，就说明是第一次同步，那主节点就会把自己的replication id和offset发送给从节点，让从节点与主节点的信息保持一致。\n第三：在同时主节点会执行BGSAVE，生成RDB文件后，发送给从节点去执行，从节点先把自己的数据清空，然后执行主节点发送过来的RDB文件，这样就保持了一致。\n当然，如果在RDB生成执行期间，依然有请求到了主节点，而主节点会以命令的方式记录到缓冲区，缓冲区是一个日志文件，最后把这个日志文件发送给从节点，这样就能保证主节点与从节点完全一致了，后期再同步数据的时候，都是依赖于这个日志文件，这个就是全量同步。\n增量同步指的是，当从节点服务重启之后，数据就不一致了，所以这个时候，从节点会请求主节点同步数据，主节点还是判断不是第一次请求，不是第一次就获取从节点的offset值，然后主节点从命令日志中获取offset值之后的数据，发送给从节点进行数据同步。\n22. 怎么保证Redis的高并发高可用？ 为了保证Redis的高并发和高可用性，通常会采用以下几种策略：\n主从复制与哨兵模式\n主从复制：通过主从复制，可以将数据从主节点同步到多个从节点。主节点负责写操作，从节点负责读操作，这样可以分散读取压力，提高系统的并发能力。 哨兵模式：哨兵（Sentinel）是Redis的高可用性解决方案，可以监控主从复制的运行状态。如果主节点发生故障，哨兵会自动将一个从节点提升为新的主节点，并通知客户端更新连接信息。哨兵模式通过以下机制实现高可用性： 监控：哨兵会持续监控主节点和从节点的状态。 自动故障转移：当主节点故障时，哨兵会自动选择一个从节点作为新的主节点。 通知客户端：哨兵会通过发布/订阅机制通知客户端新的主节点信息。 Redis集群\n分片：Redis集群通过将数据分片到多个节点上，可以有效分散负载，提高并发处理能力。 自动故障转移：集群模式下，当主节点故障时，集群会自动进行故障转移，确保服务的可用性。 23. 你们使用Redis是单点还是集群，哪种集群？ 24. Redis集群脑裂该怎么解决呢？ 25. Redis的分片集群有什么作用？ 26. Redis分片集群中数据是怎么存储和读取的？ 27. Redis是单线程的，但是为什么还那么快？ 完全基于内存的，C语言编写。 采用单线程，避免不必要的上下文切换和竞争条件。 使用多路I/O复用模型，非阻塞IO。 28. 能解释一下I/O多路复用模型？ I/O 多路复用模型呢，简单来说，就是让一个线程能同时盯着好多网络连接（Socket）。就像餐厅里一个厉害的服务员，能同时照顾好多桌客人。以前传统的方式是来一个客人就安排一个服务员专门盯着，太浪费人力了。而 I/O 多路复用就是让一个服务员（线程）看着所有桌子（Socket），哪个桌子上的客人需要点菜（可读）或者要结账（可写）了，这个服务员就过去服务。\nRedis 就是用了 I/O 多路复用结合事件处理器来处理好多 Socket 请求，像有专门处理连接的、处理命令回复的、处理命令请求的。不过在 Redis 6.0 之后，为了让处理速度更快，在命令回复和命令请求处理的某些环节用了多线程，但核心的命令执行还是单线程，保证命令执行的准确性和稳定性。\n五、设计模式篇 1. 单点登录这块怎么实现的？ 单点登录（SSO）：用户只需登录一次，即可访问所有信任的应用系统。\n基于 Cookie 和 Session 的实现\n用户登录：用户访问应用系统，输入用户名和密码进行登录，登录请求被发送到认证中心。 认证与 Session 创建：认证中心验证用户身份信息，若成功则在服务器端创建一个 Session，将用户信息存储在 Session 中，并生成一个唯一的 Session ID。 Cookie 设置：认证中心将 Session ID 通过 Cookie 发送给客户端浏览器，浏览器会在后续请求中自动携带该 Cookie。 访问其他应用系统：当用户访问其他应用系统时，浏览器会携带包含 Session ID 的 Cookie，应用系统收到请求后，从 Cookie 中获取 Session ID，并根据 Session ID 到服务器端查找对应的 Session，以此来验证用户身份，若 Session 存在且有效，则允许用户访问。 基于 Token 的实现\n用户登录：用户在登录页面输入账号和密码，系统验证身份后生成一个JWT令牌，然后将这个令牌返回给浏览器，浏览器会将其保存到Cookie中。 访问其他服务：当用户访问其他系统或服务时，浏览器会自动携带这个JWT令牌。网关会拦截请求，检查令牌是否有效。 令牌验证： 如果令牌有效，网关会将请求路由到目标服务，用户可以正常访问。 如果令牌无效（比如过期或被篡改），网关会返回401状态码，前端接收到后会跳转到登录页面，提示用户重新登录。 服务间通信：在微服务架构中，各服务之间也可能需要进行身份验证。这时，服务之间会通过传递JWT令牌来确认彼此的身份，确保通信的安全性。 2. 上传数据的安全性你们怎么控制？ 在我们项目中，对于浏览器访问后台时上传数据的安全性问题，主要是通过加密技术来控制的，常用的是对称加密和非对称加密这两种方式。\n先来说说对称加密吧。它的原理是加密和解密都使用同一个密钥。数据发送方会把要传输的明文和这个加密密钥一起，通过特定的加密算法进行处理，将其转化为复杂的密文，然后再发送出去。接收方收到密文后，要想解读出原文，就需要使用和加密时相同的密钥，以及这个加密算法的逆算法来对密文进行解密，这样才能恢复成原来可读的明文。对称加密的优点很明显，它的算法是公开的，计算量比较小，加密的速度快，效率也高，能够快速处理大量数据。不过它也有缺点，就是安全性相对非对称加密来说要低一些。所以我们一般会用它来保存像用户手机号、身份证这类虽然敏感，但后续需要解密使用的信息。常见的对称加密算法有 AES、DES、3DES 等等。\n再就是非对称加密。这种加密方式有两个密钥，一个是公开密钥，另一个是私有密钥。我们会同时生成这两把密钥，私钥由服务器端隐秘保存好，公钥则可以下发给信任的客户端。在加密和解密方面，私钥加密的内容，只有持有公钥的一方才能解密；反过来，公钥加密的内容，就只有持有私钥的一方可以解密。而且，还可以用私钥进行签名，通过公钥来验证数据有没有被篡改过。非对称加密的优势在于它的安全性更好，但是它也有不足的地方，那就是加密和解密花费的时间比较长，速度慢，所以只适合对少量数据进行加密。我们一般会把它用在签名和认证这些场景里，比如说私钥由服务器保存用来加密数据，公钥交给客户端，让客户端用来对令牌或者签名进行解密或者校验。像 RSA、DSA 这些都是常见的非对称加密算法。\n在实际应用中，我们会根据具体的情况来选择合适的加密方式。如果传输的数据量很大，为了保证效率，我们会建议使用对称加密，不过这种情况下，我们不会用它来保存特别敏感的信息。而如果传输的数据量比较小，同时对安全性要求又很高，那我们就会采用非对称加密，以确保数据的安全。通过这样的方式，我们能够有效地保障上传数据在网络传输过程中的安全性。\n3. 你负责项目的时候遇到了哪些比较棘手的问题？ 在我们的在线判题系统（OJ）项目中，不同编程语言的判题逻辑存在显著差异。例如，Java语言的内存和时间限制通常需要适当增加，而C++语言可能需要更严格的限制。此外，代码沙箱的调用也需要支持多种方式，如本地沙箱、远程沙箱和第三方沙箱。如果将所有这些逻辑都写在一个Service类中，通过大量的if...else语句来区分，代码的可读性和可维护性会变得很差，圈复杂度也会很高。因此，我选择了策略模式、工厂模式和代理模式来解决这些问题。\n(1) 首先，我们用策略模式封装不同语言的判题算法\n定义判题策略接口\n这个接口就像是一个规范，规定了所有具体判题策略类都必须实现的方法。在这个接口里，有一个 doJudge 方法，它接收一个 JudgeContext 类型的参数，这个参数可以携带判题所需的各种信息。\n1 2 3 public interface JudgeStrategy { void doJudge(JudgeContext context); } 实现具体的策略类\n以 Java 和 C++ 语言为例。对于 Java 语言，我创建了 JavaLanguageJudgeStrategy 类，它实现了 JudgeStrategy 接口，在 doJudge 方法里编写了 Java 语言特有的判题逻辑。同样地，对于 C++ 语言，我创建了 CppLanguageJudgeStrategy 类，也在其 doJudge 方法中实现了 C++ 语言的判题逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class JavaLanguageJudgeStrategy implements JudgeStrategy { @Override public void doJudge(JudgeContext context) { // Java语言的判题逻辑 } } public class CppLanguageJudgeStrategy implements JudgeStrategy { @Override public void doJudge(JudgeContext context) { // C++语言的判题逻辑 } } 定义上下文类\n为了方便传递判题所需的信息，我定义了一个上下文类 JudgeContext。在这个类中，包含了提交的代码、输入用例以及预期输出等信息，这些信息会在判题过程中被使用。\n1 2 3 4 5 6 public class JudgeContext { private String submissionCode; private String input; private String expectedOutput; // 其他需要的信息 } 定义策略管理类\n最后，为了管理这些不同的判题策略，我定义了一个策略管理类 JudgeManager。在这个类中，使用一个 Map 来存储不同语言对应的判题策略，键是语言的名称，值是对应的策略类实例。在构造函数中，我初始化了这个 Map，将 Java 和 C++ 等语言对应的策略类实例添加进去。同时，提供了一个 executeStrategy 方法，根据传入的语言名称从 Map 中获取对应的策略实例，如果存在就调用其 doJudge 方法进行判题，如果不存在则抛出异常。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class JudgeManager { private Map\u0026lt;String, JudgeStrategy\u0026gt; strategyMap; public JudgeManager() { strategyMap = new HashMap\u0026lt;\u0026gt;(); strategyMap.put(\u0026#34;Java\u0026#34;, new JavaLanguageJudgeStrategy()); strategyMap.put(\u0026#34;Cpp\u0026#34;, new CppLanguageJudgeStrategy()); // 添加其他语言的策略 } public void executeStrategy(String language, JudgeContext context) { JudgeStrategy strategy = strategyMap.get(language); if (strategy != null) { strategy.doJudge(context); } else { throw new IllegalArgumentException(\u0026#34;Unsupported language: \u0026#34; + language); } } } 通过这种策略模式的实现，我们可以很方便地添加新的编程语言判题策略，同时也使得代码的可维护性和可扩展性得到了显著提升。如果后续需要增加新的语言判题逻辑，只需要创建一个新的策略类并实现 JudgeStrategy 接口，然后在 JudgeManager 的 Map 中添加对应的映射关系即可，不会对现有的代码造成影响。\n(2) 然后，我们使用工厂模式简化代码沙箱调用实例的获取\n定义代码沙箱接口\n首先，我定义了一个代码沙箱接口 CodeSandbox。这个接口规定了代码沙箱必须具备的核心功能，即 execute 方法，该方法接收代码和输入作为参数，返回执行结果。通过这个接口，我们可以为不同类型的代码沙箱提供统一的调用方式。\n1 2 3 public interface CodeSandbox { ExecutionResult execute(String code, String input); } 实现具体的代码沙箱类\n我实现了具体的代码沙箱类。分别有 LocalCodeSandbox 用于本地代码沙箱执行，RemoteCodeSandbox 用于远程代码沙箱执行，以及 ThirdPartyCodeSandbox 用于调用第三方代码沙箱服务。每个类都实现了 CodeSandbox 接口，并在 execute 方法中编写了各自对应的执行逻辑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class LocalCodeSandbox implements CodeSandbox { @Override public ExecutionResult execute(String code, String input) { // 本地沙箱执行逻辑 } } public class RemoteCodeSandbox implements CodeSandbox { @Override public ExecutionResult execute(String code, String input) { // 远程沙箱执行逻辑 } } public class ThirdPartyCodeSandbox implements CodeSandbox { @Override public ExecutionResult execute(String code, String input) { // 第三方沙箱执行逻辑 } } 定义工厂类\n最后，为了方便获取不同类型的代码沙箱实例，我定义了一个工厂类CodeSandboxFactory。在这个工厂类中，有一个静态方法 getCodeSandbox，它接收一个表示沙箱类型的字符串作为参数。根据传入的类型，使用 switch 语句进行判断，然后返回相应的代码沙箱实例。如果传入的类型不被支持，会抛出一个 IllegalArgumentException 异常.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class CodeSandboxFactory { public static CodeSandbox getCodeSandbox(String type) { switch (type) { case \u0026#34;local\u0026#34;: return new LocalCodeSandbox(); case \u0026#34;remote\u0026#34;: return new RemoteCodeSandbox(); case \u0026#34;thirdParty\u0026#34;: return new ThirdPartyCodeSandbox(); default: throw new IllegalArgumentException(\u0026#34;Unsupported sandbox type: \u0026#34; + type); } } } 通过这种工厂模式的实现，我们在需要获取代码沙箱实例时，只需要调用 CodeSandboxFactory 的 getCodeSandbox 方法并传入相应的类型即可，无需关心具体的实例创建过程。而且，如果后续需要添加新的代码沙箱类型，只需要在工厂类的 switch 语句中添加相应的分支，同时实现对应的代码沙箱类，不会对其他部分的代码造成影响，大大提高了代码的可扩展性和可维护性。\n(3) 为了进一步优化判题机模块中代码沙箱调用的灵活性与可管理性，我采取了配置化代码沙箱类型的方案。\n实现动态切换代码沙箱的实现，全程无需修改代码，大大提高了系统的灵活性与稳定性。\n在 application.yml 配置文件中，我们添加了代码沙箱类型的配置项。\n1 2 sandbox: type: remote 代码读取配置\n在 Java 代码中，利用 Spring 框架提供的 @Value 注解，我们可以方便地读取配置文件中的 sandbox.type 值。示例代码如下：\n1 2 @Value(\u0026#34;${sandbox.type}\u0026#34;) private String sandboxType; 然后，在获取代码沙箱实例的方法中，我们利用前面提到的工厂类来获取相应类型的代码沙箱实例：\n1 2 3 public CodeSandbox getCodeSandbox() { return CodeSandboxFactory.getCodeSandbox(sandboxType); } 这里通过将读取到的 sandboxType 作为参数传递给 CodeSandboxFactory 的 getCodeSandbox 方法，就能获取到对应的代码沙箱实例。\n(4) 最后 我们使用代理模式增强代码沙箱的能力\n在调用代码沙箱前后进行日志记录等操作时，如果直接在代码沙箱调用实现类中编写，会导致代码耦合度高，后续修改和扩展困难。\n定义代理类\n我定义了一个代理类 CodeSandboxProxy，它实现了 CodeSandbox 接口。在这个代理类中，有一个成员变量 target，它是被代理的代码沙箱对象。通过构造函数将被代理的对象传入并赋值给 target。 在 execute 方法中，我在调用被代理对象的 execute 方法前后添加了日志记录的操作。具体来说，在调用之前，会调用 log 方法记录 “Executing code in sandbox\u0026hellip;”，表示代码沙箱开始执行代码；在调用之后，再次调用 log 方法记录 “Execution completed.”，表示代码执行完成。最后返回执行结果。log 方法中封装了具体的日志记录逻辑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class CodeSandboxProxy implements CodeSandbox { private CodeSandbox target; public CodeSandboxProxy(CodeSandbox target) { this.target = target; } @Override public ExecutionResult execute(String code, String input) { log(\u0026#34;Executing code in sandbox...\u0026#34;); ExecutionResult result = target.execute(code, input); log(\u0026#34;Execution completed.\u0026#34;); return result; } private void log(String message) { // 日志记录逻辑 } } 使用代理类\n在获取代码沙箱实例的方法 getCodeSandbox 中，首先通过 CodeSandboxFactory 工厂类根据配置的沙箱类型获取到具体的代码沙箱实例 target，然后将这个实例作为参数传递给 CodeSandboxProxy 代理类的构造函数，创建一个代理对象并返回。这样，后续调用代码沙箱的 execute 方法时，实际上调用的是代理对象的 execute 方法，从而实现了在代码沙箱执行前后添加日志记录等额外功能。\n1 2 3 4 public CodeSandbox getCodeSandbox() { CodeSandbox target = CodeSandboxFactory.getCodeSandbox(sandboxType); return new CodeSandboxProxy(target); } 通过代理模式，我们可以在不改变代码沙箱实现类的前提下，集中地为代码沙箱添加新的功能，比如日志记录、性能监控等。这样，代码沙箱的原有功能不会受到影响，同时又能轻松地扩展其能力。\n代理模式将日志记录逻辑与代码沙箱的执行逻辑分离开来。代码沙箱的实现类只需要专注于代码执行的核心逻辑，而日志记录等额外功能由代理类负责。这使得每个类的职责更加清晰明确，提高了代码的可维护性和可扩展性，也让代码结构更加合理。\n六、Java基础 1. JVM vs JDK vs JRE JVM（Java Virtual Machine） 是运⾏ Java 字节码的虚拟机。JVM 有针对不同系统的特定实现（Windows， Linux，macOS），⽬的是使⽤相同的字节码，它们都会给出相同的结果。字节码和不同系统的 JVM 实现是 Java 语⾔“⼀次编译，随处可以运⾏”的关键所在。JVM有多种实现，比如我们常用的HotSpot VM，还有J9 VM、Zing VM等。这些不同的实现提供了不同的性能优化和特性。\nJDK（Java Development Kit） 是Java开发工具包，它包含了JRE的所有内容，同时还包括编译器（javac）、调试器（jdb）、文档生成器（javadoc）等开发工具。JDK是Java开发者的必备工具，用于编写、编译和调试Java程序。如果你需要进行Java开发，那么安装JDK是必须的。\nJRE（Java Runtime Environment） 是Java运行时环境，它包含了运行已编译Java程序所需的所有内容，包括JVM、Java类库和一些基础工具。JRE主要用于运行Java程序，而不包含开发工具。如果你只需要运行Java程序，而不需要进行开发，那么安装JRE就足够了。\n在实际工作中，虽然JRE可以运行Java程序，但很多时候我们也会安装JDK，因为一些工具（如JSP容器）在运行时需要编译功能，这就需要JDK的支持。总的来说，JVM是运行Java程序的核心，JDK是开发Java程序的工具集，而JRE是运行Java程序的环境。\n2. 什么是字节码?采用字节码的好处是什么? 在 Java 中，JVM 可以理解的代码就叫做字节码（即扩展名为 .class 的⽂件），它不⾯向任何特定 的处理器，只⾯向虚拟机。Java 语⾔通过字节码的⽅式，在⼀定程度上解决了传统解释型语⾔执⾏ 效率低的问题，同时⼜保留了解释型语⾔可移植的特点。所以， Java 程序运⾏时相对来说还是⾼效 的（不过，和 C++，Rust，Go 等语⾔还是有⼀定差距的），⽽且，由于字节码并不针对⼀种特定的 机器，因此，Java 程序⽆须重新编译便可在多种不同操作系统的计算机上运⾏。\n3. Java 程序从源代码到运⾏的过程如下图所示 我们需要格外注意的是 .class-\u0026gt;机器码 这⼀步。在这⼀步 JVM 类加载器⾸先加载字节码⽂件，然后 通过解释器逐⾏解释执⾏，这种⽅式的执⾏速度会相对比较慢。⽽且，有些⽅法和代码块是经常需要 被调⽤的(也就是所谓的热点代码)，所以后⾯引进了 JIT（just-in-time compilation） 编译器，⽽ JIT 属于运⾏时编译。当 JIT 编译器完成第⼀次编译后，其会将字节码对应的机器码保存下来，下次可以 直接使⽤。⽽我们知道，机器码的运⾏效率肯定是⾼于 Java 解释器的。这也解释了我们为什么经常 会说 Java 是编译与解释共存的语⾔ 。\n3. 成员变量与局部变量的区别？ 语法形式 ：从语法形式上看，成员变量是属于类的，⽽局部变量是在代码块或⽅法中定义的变量或是⽅法的参数；成员变量可以被 public , private , static 等修饰符所修饰，⽽局部变量不能被访问控制修饰符及 static 所修饰；但是，成员变量和局部变量都能被 final 所修饰。 存储⽅式 ：从变量在内存中的存储⽅式来看,如果成员变量是使⽤ static 修饰的，那么这个成员变量是属于类的，如果没有使⽤ static 修饰，这个成员变量是属于实例的。⽽对象存在于堆内存，局部变量则存在于栈内存。 ⽣存时间 ：从变量在内存中的⽣存时间上看，成员变量是对象的⼀部分，它随着对象的创建⽽ 存在，⽽局部变量随着⽅法的调⽤⽽⾃动⽣成，随着⽅法的调⽤结束⽽消亡。 默认值 ：从变量是否有默认值来看，成员变量如果没有被赋初始值，则会⾃动以类型的默认值⽽赋值（⼀种情况例外:被 final 修饰的成员变量也必须显式地赋值），⽽局部变量则不会⾃动 赋值。 5. 静态变量有什么作用？ 共享数据： 静态变量属于类本身，而不是类的某个具体实例。因此，无论一个类创建了多少个对象，所有这些对象都共享同一份静态变量。这使得静态变量非常适合用于存储类级别的数据，这些数据对所有实例都是相同的。 节省内存： 由于静态变量是类级别的，它在内存中只有一份副本，无论创建多少个类的实例，都不会重复占用内存。这在处理大量对象时可以显著节省内存资源。 常量定义： 静态变量通常会被final关键字修饰，成为常量。这样可以确保这些变量的值在运行时不会被修改，从而提高代码的安全性和可维护性。 6. 静态方法和实例方法有何不同？ 调用方式： 静态方法：可以通过类名.方法名直接调用，无需创建类的实例。虽然也可以通过对象调用，但这种方式容易造成混淆，因此建议使用类名.方法名来调用静态方法。 实例方法：必须通过类的实例调用，即对象.方法名。实例方法依赖于具体的对象实例。 访问类成员的限制： 静态方法：只能访问类的静态成员（静态变量和静态方法），不能访问实例成员（实例变量和实例方法）。这是因为静态方法属于类本身，而不是某个具体实例。 实例方法：可以访问类的所有成员，包括静态成员和实例成员。实例方法依赖于具体的对象实例，因此可以访问该实例的所有成员。 与对象的关系： 静态方法：属于类本身，与具体的对象实例无关。无论创建多少个对象，静态方法都只有一份。 实例方法：属于具体的对象实例，每个对象实例都有自己的实例方法。 7. 重载和重写有什么区别？ 重载（Overloading）\n重载是指在同一个类中，允许定义多个同名方法，但这些方法的参数列表必须不同\n重载发生在编译期，编译器通过参数列表来区分不同的方法。\n重载就是同⼀个类中多个同名方法根据不同的传参来执行不同的逻辑处理。\n重写\n重写发生在运行期，是⼦类对父类的允许访问的方法的实现过程进行重新编写。\n方法名、参数列表必须相同，子类方法返回值类型应比父类方法返回值类型更小或相等，抛出的 异常范围小于等于父类，访问修饰符范围大于等于父类。如果方法的返回 类型是 void 和基本数据类型，则返回值重写时不可修改。但是如果方法的返回值是引用类型，重写 时是可以返回该引⽤类型的子类的。 如果父类方法访问修饰符为 private/final/static 则子类就不能重写该方法，但是被 static 修饰的方法能够被再次声明。 构造方法无法被重写 **口诀：**方法的重写要遵循“两同两小一大”\n“两同”即方法名相同、形参列表相同；\n“两小”指的是子类方法返回值类型应比父类方法返回值类型更小或相等，子类方法声明抛出的异常类应比父类方法声明抛出的异常类更小或相等；\n“一大”指的是子类方法的访问权限应比父类方法的访问权限更大或相等。\n8. Java 中的几种基本数据类型了解么？ Java 中有 8 种基本数据类型，分别为：\n4 种整数型： byte 、 short 、 int 、 long\n2 种浮点型： float （4）、 double（8）\n1 种字符类型：char（2）\n1 种布尔型： boolean\nbyte、short、int、long能表示的最大正数都减 1 了。这是为什么呢？这是因为在二进制补码表示法中，最高位是用来表示符号的（0 表示正数，1 表示负数），其余位表示数值部分。所以，如果我们要表示最大的正数，我们需要把除了最高位之外的所有位都设为 1。如果我们再加 1，就会导致溢出，变成一个负数。\n9. 基本类型和包装类型的区别？ 成员变量包装类型不赋值就是 null ，而基本类型有默认值且不是 null 。 包装类型可用于泛型，而基本类型不可以。 基本数据类型的局部变量存放在 Java 虚拟机栈中的局部变量表中，基本数据类型的成员变量（未被 static 修饰）存放在 Java 虚拟机的堆中。包装类型属于对象类型，我们知道几乎所有对象实例都存在于堆中。 相比于对象类型，基本数据类型占用的空间非常小。 ⚠ 注意：基本数据类型存放在栈中是一个常见的误区！基本数据类型的成员变量如果没有被 static 修饰的话（不建议这么使用，应该要使用基本数据类型对应的包装类型），就存放在堆中。\n10. 自动装箱与拆箱了解吗？原理是什么？ 装箱：将基本类型用它们对应的引用类型包装起来；\n拆箱：将包装类型转换为基本数据类型；\n装箱其实就是调用了 包装类的 valueOf() 方法，拆箱其实就是调用了 xxxValue() ⽅法。\nInteger i = 10 等价于 Integer i = Integer.valueOf(10) int n = i 等价于 int n = i.intValue() ; 11. 面向对象三大特征 1. 封装 封装是将对象的状态信息（即属性）隐藏在对象内部，不允许外部直接访问这些内部信息。但可以通过一些公开的方法来操作这些属性。例如，我们无法看到挂在墙上的空调内部的零件，但可以通过遥控器来控制空调。如果某些属性不想被外界访问，可以选择不提供相应的方法。但如果一个类没有任何可访问的方法，那么这个类就失去了意义。\n2. 继承 不同类型的对象通常有一些共同点。例如，小明、小红和小李都是学生，共享学生的一些特性（如班级、学号等）。同时，每个对象也有其独特的特性。继承是一种使用已存在的类定义作为基础来创建新类的技术。新类可以增加新的数据和功能，也可以使用父类的功能，但不能选择性地继承父类。继承可以快速创建新类，提高代码复用性，增强程序的可维护性，节省开发时间。\n关于继承的三个要点：\n子类拥有父类的所有属性和方法（包括私有属性和方法），但无法访问父类中的私有属性和方法。 子类可以拥有自己的属性和方法，即可以对父类进行扩展。 子类可以用自己的方式实现父类的方法。 3. 多态 多态表示一个对象可以具有多种状态，具体表现为父类的引用指向子类的实例。多态的特点包括：\n对象类型和引用类型之间必须存在继承（类）或实现（接口）的关系。 引用类型变量调用的方法在运行时才能确定。 多态不能调用“只在子类中存在而在父类中不存在”的方法。 如果子类重写了父类的方法，调用的是子类覆盖的方法；如果没有覆盖，则调用父类的方法。 12. 接口和抽象类有什么共同点和区别？ 共同点\n都不能被实例化。 都可以包含抽象方法。 都可以有默认实现的方法（Java 8 可以用default关键字在接口中定义默认方法）。 区别\n接口： 主要用于对类的行为进行约束，实现接口的类具有对应的行为。 一个类可以实现多个接口。 接口中的成员变量只能是public static final类型的，不能被修改且必须有初始值。 抽象类： 主要用于代码复用，强调的是所属关系。 一个类只能继承一个抽象类。 抽象类的成员变量默认是default，可以在子类中被重新定义或赋值。 13. 深拷贝、浅拷贝和引用拷贝的区别 引用拷贝是指两个不同的引用指向同一个对象。这种方式不会创建新的对象，只是将一个引用赋值给另一个引用。\n浅拷贝会在堆上创建一个新的对象，但不会复制对象内部的引用类型属性。也就是说，浅拷贝的对象和原对象共享内部的引用类型属性。\n深拷贝会完全复制整个对象，包括对象内部的所有引用类型属性。深拷贝的对象和原对象完全独立，不共享任何引用类型属性。\n14. == 和 equals() 的区别 == 的作用： 基本数据类型：比较两个值是否相等。 引用数据类型：比较两个引用是否指向同一个对象，即比较内存地址。 注意：Java中只有值传递，无论是比较基本数据类型还是引用数据类型，== 比较的都是值。对于引用类型，值是对象的内存地址。 equals() 的作用： 基本数据类型：equals() 方法不能用于基本数据类型，只能用于对象。 引用数据类型：equals() 方法用于比较两个对象的内容是否相等。equals() 方法存在于 Object 类中，所有类都继承自 Object 类，因此所有类都有 equals() 方法。 默认行为：Object 类中的 equals() 方法默认比较对象的内存地址，等同于 ==。 重写行为：通常我们会重写 equals() 方法来比较对象的属性是否相等。如果两个对象的属性相等，则返回 true，表示这两个对象相等。 15. hashCode() 有什么用？ hashCode() 的作用是获取哈希码（一个整数），也称为散列码。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 定义在 JDK 的 Object 类中，这就意味着 Java 中的任何类都包含有 hashCode() 方法。另外需要注意的是：Object 的 hashCode() 方法是本地方法，也就是用 C 语言或 C++ 实现的，该方法通常用来将对象的内存地址转换为整数之后返回。\n散列表存储的是键值对（key-value），它的特点是：能根据“键”快速检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象）\n为什么要有 hashCode()？\n我们以“HashSet 如何检查重复”为例来说明为什么要有 hashCode()。当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashCode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashCode 值作比较，如果没有相符的 hashCode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashCode 值的对象，这时会调用 equals() 方法来检查 hashCode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。这样我们大大减少了 equals 的次数，相应就大大提高了执行速度。\nhashCode() 和 equals() 都是用来比较两个对象是否相等的。那为什么 JDK 还要同时提供这两个方法呢？\n这是因为在一些容器（比如 HashMap、HashSet）中，有了 hashCode() 之后，判断元素是否在对应容器中的效率会更高（参考添加元素进 HashSet 的过程）！我们在前面也提到了添加元素进 HashSet 的过程，如果 HashSet 在对比的时候，同样的 hashCode 有多个对象，它会继续使用 equals() 来判断是否真的相同。也就是说 hashCode 帮助我们大大缩小了查找成本。\n那为什么不只提供 hashCode() 方法呢？这是因为两个对象的 hashCode 值相等并不代表两个对象就相等。那为什么两个对象有相同的 hashCode 值，它们也不一定相等呢？\n因为 hashCode() 所使用的哈希算法也许刚好会让多个对象传回相同的哈希值。越糟糕的哈希算法越容易碰撞，但这也与数据值域分布的特性有关（所谓哈希碰撞也就是指的是不同的对象得到相同的 hashCode）。\n为什么重写 equals() 时必须重写 hashCode() 方法？\n因为两个相等的对象的 hashCode 值必须是相等。也就是说如果 equals() 方法判断两个对象是相等的，那这两个对象的 hashCode 值也要相等。如果重写 equals() 时没有重写 hashCode() 方法的话就可能会导致 equals() 方法判断是相等的两个对象，hashCode 值却不相等。\n16. String、StringBuffer、StringBuilder 的区别？ 线程安全性\nString 中的对象是不可变的，也就可以理解为常量，线程安全。 AbstractStringBuilder 是 StringBuilder 与 StringBuffer 的公共父类，定义了一些字符串的基本操作，如 expandCapacity、append、insert、indexOf 等公共方法。 StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。 StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。 性能\n每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。 StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 String 为什么是不可变的？\n保存字符串的数组被 final 修饰且为私有的，并且 String 类没有提供/暴露修改这个字符串的方法。 String 类被 final 修饰导致其不能被继承，进而避免了子类破坏 String 不可变。 字符串拼接用“+” 还是 StringBuilder?\n字符串对象通过“+”的字符串拼接方式，实际上是通过 StringBuilder 调用 append() 方法实现的，拼接完成之后调用 toString() 得到一个 String 对象 。 不过，在循环内使用“+”进行字符串的拼接的话，存在比较明显的缺陷：编译器不会创建单个 StringBuilder 以复用，会导致创建过多的 StringBuilder 对象。如果直接使用 StringBuilder 对象进行字符串拼接的话，就不会存在这个问题了。 String#equals() 和 Object#equals() 有何区别？\nString 中的 equals 方法是被重写过的，比较的是 String 字符串的值是否相等。 Object 的 equals 方法比较的是对象的内存地址。 字符串常量池的作用了解吗？\n字符串常量池是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。 intern 方法有什么作用？\nString.intern() 是一个 native（本地）方法，其作用是将指定的字符串对象的引用保存在字符串常量池中，可以简单分为两种情况： 如果字符串常量池中保存了对应的字符串对象的引用，就直接返回该引用。 如果字符串常量池中没有保存了对应的字符串对象的引用，那就在常量池中创建一个指向该字符串对象的引用并返回。 17. Exception 和 Error 的区别 在 Java 里，所有异常都有一个共同的祖先，即java.lang包中的Throwable类。Throwable类有两个重要的子类：\nException：是程序本身可以处理的异常，能够通过catch语句来捕获。它又可细分为Checked Exception（受检查异常，必须处理）和Unchecked Exception（不受检查异常，可以不处理）。 Error：属于程序无法处理的错误，不建议通过catch捕获。例如Java虚拟机运行错误（Virtual MachineError）、虚拟机内存不够错误（OutOfMemoryError）、类定义错误（NoClassDefFoundError）等。当这些异常发生时，Java虚拟机（JVM）通常会选择终止线程。 18. Checked Exception 和 Unchecked Exception 的区别 Checked Exception（受检查异常）：在 Java 代码编译过程中，如果受检查异常没有被catch或者throws关键字处理，代码就无法通过编译。除了RuntimeException及其子类以外，其他的Exception类及其子类都属于受检查异常。常见的受检查异常有：与IO相关的异常、ClassNotFoundException、SQLException等。\nUnchecked Exception（不受检查异常）：在 Java 代码编译过程中，即使不处理不受检查异常，代码也能正常通过编译。\nRuntimeException及其子类都被统称为非受检查异常，常见的有：\nNullPointerException（空指针错误） IllegalArgumentException（参数错误，比如方法入参类型错误） NumberFormatException（字符串转换为数字格式错误，是IllegalArgumentException的子类） ArrayIndexOutOfBoundsException（数组越界错误） ClassCastException（类型转换错误） ArithmeticException（算术错误） SecurityException（安全错误，比如权限不够） UnsupportedOperationException（不支持的操作错误，比如重复创建同一用户 19. Throwable 类常用方法 String getMessage()：返回异常发生时的简要描述。 String toString()：返回异常发生时的详细信息。 String getLocalizedMessage()：返回异常对象的本地化信息。Throwable的子类覆盖这个方法，可以生成本地化信息。若子类没有覆盖该方法，则该方法返回的信息与getMessage()返回的结果相同。 void printStackTrace()：在控制台上打印Throwable对象封装的异常信息。 20. try-catch-finally 的使用 try 块：用于捕获异常。其后可以接零个或多个catch块，如果没有catch块，则必须跟一个finally块。 catch 块：用于处理try捕获到的异常。 finally 块：无论是否捕获或处理异常，finally块里的语句都会被执行。当在try块或catch块中遇到return语句时，finally语句块将在方法返回之前被执行。 注意：不要在finally语句块中使用return！当try语句和finally语句中都有return语句时，try语句块中的return语句会被忽略。这是因为try语句中的return返回值会先被暂存在一个本地变量中，当执行到finally语句中的return之后，这个本地变量的值就变为了finally语句中的return返回值。\n21. finally 中的代码一定会执行吗？ 不一定。在某些情况下，finally中的代码不会被执行，比如：\nfinally之前虚拟机被终止运行，例如使用System.exit(1)终止当前正在运行的 Java 虚拟机。 程序所在的线程死亡。 关闭 CPU。 22. 异常使用有哪些需要注意的地方？ 不要把异常定义为静态变量，因为这样会导致异常栈信息错乱。每次手动抛出异常，我们都需要手动 new 一个异常对象抛出。 抛出的异常信息一定要有意义。 建议抛出更加具体的异常，比如字符串转换为数字格式错误的时候应该抛出 NumberFormatException 而不是其父类 IllegalArgumentException。 使用日志打印异常之后就不要再抛出异常了（两者不要同时存在于一段代码逻辑中）。 23. 反射 定义：反射赋予了 Java 程序在运行时分析类以及执行类中方法的能力。借助反射，能够获取任意一个类的所有属性和方法，并且可以调用这些方法和属性。若深入研究框架底层原理或自行编写框架，对反射概念会较为熟悉，因其被称为框架的灵魂。 优缺点 优点：使代码更灵活，为各种框架实现开箱即用的功能提供便利。 缺点：增加安全问题，例如可无视泛型参数在编译时的安全检查；性能相对稍差，但对框架实际影响不大。 应用场景 在业务开发中，直接使用反射机制的场景较少。然而，众多框架如 Spring/Spring Boot、MyBatis 等大量运用了反射机制。 动态代理在这些框架中广泛使用，而动态代理的实现依赖反射。例如 JDK 实现动态代理的示例代码，通过反射类Method调用指定方法。 注解的实现也用到反射。以 Spring 为例，使用@Component注解声明一个类为 Spring Bean，通过@Value注解读取配置文件中的值，其原理是基于反射分析类，获取类、属性、方法及方法参数上的注解，进而进行后续处理。 24. 序列化与反序列化 如果我们需要持久化 Java 对象比如将 Java 对象保存在文件中，或者在网络传输 Java 对象，这些场景都需要用到序列化。\n定义 序列化：将数据结构或对象转换为二进制字节流的过程。当需要持久化 Java 对象，如保存在文件中或在网络传输 Java 对象时，会用到序列化。 反序列化：将序列化过程中生成的二进制字节流转换回数据结构或对象的过程。 不想序列化某些字段的处理方式：对于不想进行序列化的变量，使用transient关键字修饰。transient关键字作用为阻止实例中被其修饰的变量序列化；对象反序列化时，被transient修饰的变量值不会被持久化和恢复。需注意：transient只能修饰变量，不能修饰类和方法；被其修饰的变量，反序列化后值将被置为类型默认值（如int类型为 0）；static变量不属于任何对象，无论是否有transient修饰，均不会被序列化。 26. Java IO 流了解吗？ Java IO流概述：Java IO流是Java中用于处理输入输出的核心机制，数据输入到计算机内存的过程称为输入，从内存输出到外部存储（如文件、数据库、远程主机等）的过程称为输出。由于数据传输过程类似于水流，因此形象地称为IO流。Java IO流分为输入流和输出流，根据数据处理方式又分为字节流和字符流。 抽象基类：Java IO流的40多个类都是从4个抽象类基类中派生出来的，分别是InputStream和Reader（输入流的基类，前者是字节输入流，后者是字符输入流），以及OutputStream和Writer（输出流的基类，前者是字节输出流，后者是字符输出流）。 Buffered类的作用：为了提高IO操作的效率，Java提供了BufferedInputStream、BufferedOutputStream、BufferedReader和BufferedWriter这几个类。它们分别继承自对应的输入输出流类，并在内部使用缓冲区来减少物理读写次数。 对于输入流：BufferedInputStream和BufferedReader会在第一次读取数据时，将数据块一次性读入缓冲区，之后的读取操作先从缓冲区中获取数据，只有当缓冲区中的数据被读完后，才会再次从底层数据源读取数据填充缓冲区。这种方式减少了对底层数据源的频繁访问，提高了读取效率。例如，当读取大文件时，使用BufferedReader可以显著提升读取速度。 对于输出流：BufferedOutputStream和BufferedWriter会先将要写入的数据暂存到缓冲区中，当缓冲区满或者调用flush()方法时，才将缓冲区中的数据一次性写入目标存储。这样可以减少对目标存储的写入次数，提高写入效率，同时也能避免频繁写入导致的性能问题。比如在写入大量文本数据到文件时，使用BufferedWriter可以更高效地完成写入操作。 27. 为什么Java的I/O流要分为字节流和字符流？ 主要有以下两个原因：\n字符流涉及编码转换： 字符流是由Java虚拟机将字节转换得到的。这个转换过程涉及到字符编码（如UTF-8、ISO-8859-1等），而不同的编码方式会导致相同的字节序列被解释为不同的字符。因此，字符流的处理相对复杂，需要考虑编码问题，这个过程比较耗时。 例如，一个字节序列在UTF-8编码下可能表示一个字符，而在ISO-8859-1编码下可能表示另一个字符。字符流通过指定编码方式，确保字符的正确读取和写入。 字节流和字符流的适用场景不同： 字节流：适用于处理二进制数据，如文件的读写、网络通信等。字节流直接操作字节，不涉及编码转换，因此效率较高，适合处理二进制文件（如图片、视频等）。 字符流：适用于处理文本数据。字符流在处理文本时会自动处理编码问题，确保文本内容的正确性，适合处理文本文件（如.txt、.java等）。 28. 泛型 指定参数，编译器可以对泛型参数进行检测，并且通过泛型参数可以指定传入的对象类型。\n比如 ArrayList\u0026lt;Person\u0026gt; persons = new ArrayList\u0026lt;Person\u0026gt;() 这行代码就指明了该 ArrayList 对象只能传入 Person 对象，如果传入其他类型的对象就会报错。\n29. 为什么重写 equals () 就一定要重写 hashCode () 方法 在 Java 中，若仅重写 equals() 方法而不重写 hashCode() 方法，可能会导致 a.equals(b) 表达式为 true，但 a 和 b 的 hashCode 值却不同。这在使用散列集合（如 HashMap、HashSet 等）存储对象时会引发问题。因为散列集合利用 hashCode 计算键的存储位置，若存储两个相等的对象却有不同的 hashCode，它们会被存于哈希表的不同位置。当依据对象获取数据时，就会出现矛盾，即相同对象存于哈希表的不同位置，进而引发不可预期的错误。所以，为保证对象在散列集合中的正确存储和查找，重写 equals() 方法时必须重写 hashCode() 方法。\n30. Integer 和 int 的区别以及 Java 设计封装类的原因 区别\n初始值不同：Integer 作为引用类型，初始值为 null；int 作为基本数据类型，初始值为 0。 存储位置不同：Integer 对象存储在堆内存，int 类型的变量直接存储在栈空间。 类型及使用灵活性不同：Integer 是对象类型，封装了众多方法和属性，使用起来更加灵活；int 是基本数据类型，功能相对单一。 设计封装类的原因\nJava 是面向对象的编程语言，其操作大多基于对象。例如，集合类（如 List、Set 等）只能存储 Object 类型的元素，基本数据类型无法直接存储在集合中，必须使用对应的封装类。因此，Java 设计封装类的主要目的是让基本数据类型也能参与面向对象的操作，增强代码的灵活性和可扩展性。\n31. 如何理解Java对象的创建过程 类加载检查：当程序尝试实例化一个对象时，JVM 首先会检查该对象所属的类是否已经被加载到内存中。如果该类尚未被加载，JVM 会启动类加载机制，通过类加载器（ClassLoader）查找并加载对应的字节码文件（.class 文件）。在类加载过程中，会进行一系列的验证、准备和解析操作，为类的使用做好准备。例如，验证字节码文件的格式是否正确，为类的静态变量分配内存并设置初始值等。 内存分配：一旦类被成功加载，JVM 就会为新对象分配内存空间。对象所需的内存大小在类加载完成后就已经确定，JVM 会在堆内存中为其分配一块合适的内存区域。内存分配的方式通常有两种：指针碰撞和空闲列表。指针碰撞是指 JVM 维护一个指向堆内存中可用内存的指针，当需要分配内存时，就将指针移动相应的距离来为新对象分配空间；空闲列表则是 JVM 维护一个记录堆内存中可用内存块的列表，每次分配内存时，从列表中选择合适的内存块分配给对象。 初始化零值：在为对象分配完内存后，JVM 会将分配的内存空间初始化为零值（对于基本数据类型）或 null（对于引用数据类型）。这一步确保了对象的实例变量在被程序员显式赋值之前有一个默认的初始状态。例如，int 类型的实例变量会被初始化为 0，Object 类型的实例变量会被初始化为 null。 设置对象头：对象头是对象在内存中的一个重要组成部分，它包含了对象的一些元数据信息，如对象的哈希码（HashCode）、对象的分代年龄、锁状态标志等。JVM 会在这一步设置对象头中的这些信息，以便后续对对象的管理和操作。 执行构造方法：完成上述步骤后，JVM 会调用对象的构造方法（constructor），执行程序员在构造方法中编写的代码逻辑，对对象进行进一步的初始化。在构造方法中，程序员可以为对象的实例变量赋予特定的值，进行一些必要的资源初始化或其他操作，使对象处于可用的状态。 七、JVM基础 1. JVM 是什么？ 定义：JVM 即 Java Virtual Machine，是 Java 程序的运行环境，也是运行 Java 二进制字节码的环境。 好处：实现了 “一次编写，到处运行” 的特性，因为 JVM 屏蔽了底层操作系统的差异，使得 Java 程序在不同的操作系统上都能以相同的方式运行；具备自动内存管理和垃圾回收机制，减轻了开发者对内存管理的负担，提高了开发效率，并且降低了因内存管理不当导致的错误风险。 2. JVM 由哪些部分组成，运行流程是什么？ 组成部分 ClassLoader（类加载器）：负责加载 Java 类文件，将 Java 代码转换为字节码，使 JVM 能够识别和处理。 Runtime Data Area（运行时数据区，内存分区）：是 JVM 运行时管理内存的区域，包括堆、方法区、栈、本地方法栈和程序计数器等。 Execution Engine（执行引擎）：执行字节码指令，将字节码翻译为底层系统能够理解和执行的指令，最终交由 CPU 执行。 Native Method Library（本地库接口）：当 Java 程序需要调用其他语言（如 C、C++）编写的本地代码时，通过该接口实现调用，以完成一些 Java 语言本身无法直接实现的功能。 运行流程 类加载器把 Java 代码编译后的字节码文件加载到 JVM 中。 运行时数据区将字节码加载到内存中进行存储和管理。由于字节码是 JVM 的指令集规范，不能直接被底层系统执行，所以需要进一步处理。 执行引擎将字节码翻译为底层系统指令，在这个过程中可能会调用本地库接口来实现一些功能，最终由 CPU 执行这些指令，完成程序的运行。 3. 什么是程序计数器？ 定义：程序计数器是线程私有的内存区域，内部保存着字节码的行号，用于记录当前线程正在执行的字节码指令的地址。 作用：在多线程环境下，JVM 通过线程轮流切换并分配执行时间来实现多线程的并发执行。当一个线程的执行时间用完被挂起，处理器切换到其他线程执行后，再次切换回该线程时，就可以从程序计数器中获取上次执行的行号，从而继续向下执行，保证了线程执行的连续性和正确性。 特点：它是 JVM 规范中唯一一个没有规定会出现 OutOfMemoryError（OOM）的区域，并且该区域也不会进行垃圾回收（GC）。 查看工具：使用 javap -verbose xx.class 命令可以打印堆栈大小、局部变量的数量和方法的参数等信息，这对于了解程序的字节码结构和分析问题有一定帮助。 4. Java 堆是什么样的？ 概述：Java 堆是线程共享的内存区域，主要用于保存对象实例和数组等数据。当堆中没有足够的内存空间分配给新的对象实例，且无法再进行扩展时，就会抛出 OutOfMemoryError 异常。 分区 年轻代：被划分为三部分，分别是 Eden 区和两个大小相同的 Survivor 区（一般称为 From Survivor 和 To Survivor）。在垃圾收集过程中，新创建的对象通常会首先分配到 Eden 区，经过几次垃圾收集后，仍然存活在 Survivor 区的对象会根据 JVM 的策略被移动到老年代。 老年代：主要保存生命周期较长的对象，比如一些长时间存在的对象实例，这些对象在年轻代经过多次垃圾回收后依然存活，就会被移动到老年代。 元空间（Java 8 及以后）：在 Java 8 中，为了避免方法区（之前的永久代）出现 OOM 问题，将其移动到了本地内存，重新开辟了一块空间称为元空间。元空间主要保存**类信息、静态变量、常量、编译后的代码等数据。**它的大小默认仅受本地内存的限制，相比之前的永久代，更加灵活，减少了因永久代内存不足导致的 OOM 情况。 5. 什么是虚拟机栈？ 定义：每个线程运行时所需要的内存空间称为虚拟机栈，它遵循先进后出（FILO）的原则。每个栈由多个栈帧（frame）组成，每个栈帧对应着每次方法调用时所占用的内存。 栈帧相关：每个线程在任何时刻只能有一个活动栈帧，这个活动栈帧对应着当前正在执行的方法。当一个方法被调用时，就会创建一个新的栈帧并压入栈中；当方法执行完毕时，栈帧会从栈中弹出，释放相应的内存。 与垃圾回收的关系：垃圾回收主要针对堆内存，当栈帧弹栈后，其所占用的内存会自动释放，因此栈内存的管理相对简单，一般不需要垃圾回收机制来处理。 栈内存大小影响：栈内存并非越大越好。默认情况下，栈内存通常为 1024k。如果栈内存设置过大，会导致线程数变少。例如，假设机器总内存为 512m，按照默认栈内存 1024k 计算，能活动的线程数为 512 个；如果将栈内存改为 2048k，那么能活动的线程数就会减半。 局部变量线程安全性 如果方法内的局部变量没有逃离方法的作用范围，即该变量只在方法内部使用，那么它是线程安全的，因为不同线程不会同时访问到这个局部变量。 如果局部变量引用了对象，并且该引用逃离了方法的作用范围，例如作为方法的返回值被其他线程获取到，此时就需要考虑线程安全问题，因为多个线程可能会同时访问和修改这个对象，从而导致数据不一致或其他错误。 栈内存溢出情况 栈帧过多会导致栈内存溢出，典型的情况是递归调用。如果递归调用没有正确设置终止条件，会不断创建新的栈帧，最终导致栈内存耗尽，抛出 java.lang.StackOverFlowError 异常。 栈帧过大也可能导致栈内存溢出，因为每个栈帧占用的空间过大，会使得栈能够容纳的栈帧数量减少，从而更容易出现内存不足的情况。 栈帧的压入与弹出：方法调用的数据通过栈传递。每次方法调用，会对应一个栈帧被压入栈中；方法调用结束，对应的栈帧被弹出。\n栈帧的组成\n局部变量表：存放编译期可知的多种数据类型，包括基本数据类型（如 boolean、byte、char、short、int、float、long、double）以及对象引用（reference 类型，可能是指向对象起始地址的引用指针，也可能是指向代表对象的句柄或其他相关位置）。 操作数栈：作为方法调用的中转站，用于存储方法执行过程中产生的中间计算结果，计算时的临时变量也存放于此。 动态链接：主要用于当一个方法需要调用其他方法的场景。Class 文件常量池存有大量符号引用（如方法引用的符号引用），动态链接负责将常量池中指向方法的符号引用转换为内存地址中的直接引用，这一过程也称为动态连接。 方法返回地址：方法执行结束时，用于确定返回的位置。 6. JVM 运行时数据区有哪些组成部分，各自的作用是什么？ 堆：主要用于存储对象实例，是垃圾回收器管理的主要区域。对象的创建、存储和销毁等操作都与堆内存密切相关。 方法区：可以看作是堆的一部分，用于存储已被虚拟机加载的类信息、常量、静态变量以及即时编译器编译后的代码等。在 Java 8 之前，方法区的实现是永久代；Java 8 及以后，方法区由元空间实现，元空间使用本地内存，避免了永久代常见的 OOM 问题。 栈：解决程序运行时的方法调用和局部变量存储问题。栈中存储的是栈帧，每个栈帧包含局部变量表、操作数栈、动态链接、方法出口等信息。 本地方法栈：与栈的功能类似，主要用于执行本地方法，即 Java 调用非 Java 代码（如 C、C++ 代码）的接口。当 Java 程序需要调用本地方法时，会在本地方法栈中创建相应的栈帧来执行这些方法。 程序计数器：如前面所述，它是线程私有的，保存当前线程正在执行的字节码指令的地址，用于线程切换后恢复执行位置。 7. 解释一下方法区？ 概述 方法区是各个线程共享的内存区域，在虚拟机启动时创建，关闭虚拟机时释放。 主要存储类的信息（如类的结构、字段、方法等）、运行时常量池等数据。如果方法区域中的内存无法满足分配请求，就会抛出 OutOfMemoryError: Metaspace 异常（在 Java 8 及以后使用元空间实现方法区）。 常量池：可以看作是一张表，虚拟机指令根据这张表找到要执行的类名、方法名、参数类型、字面量等信息。通过 javap -v xx.class 命令可以查看字节码结构，包括类的基本信息、常量池和方法定义等。例如，对于一个包含 main 方法的 Application 类，执行该命令后，可以看到常量池中存储了类名、方法名、字段引用、字符串常量等信息，main 方法在执行时，需要到常量池中查找具体的类和方法地址进行调用。 运行时常量池：常量池是存在于 .class 文件中的，当该类被加载到 JVM 中时，它的常量池信息会被放入运行时常量池，并将其中的符号地址转换为真实地址，以便 JVM 能够正确执行字节码指令。 8. 什么是直接内存，它有什么特点和应用场景？ 定义：直接内存不受 JVM 内存回收管理，它是虚拟机使用的系统内存。 特点：常见于 NIO（New IO）操作中，用于数据缓冲区。直接内存的分配和回收成本相对较高，因为它需要与操作系统进行交互来申请和释放内存。但是，它的读写性能很高，这是因为它不需要在堆内存和系统内存之间进行数据拷贝，JVM 可以直接操作直接内存。 应用场景：以将本地电脑中一个较大的文件（如超过 100m 的视频文件）从一个磁盘挪到另一个磁盘为例，使用传统的 IO 操作和 NIO 操作进行对比。通过代码测试可以发现，使用传统 IO 操作的时间要比 NIO 操作的时间长很多，这是因为 NIO 操作利用了直接内存的特性，减少了数据拷贝的开销，从而提高了数据传输的效率。在传统阻塞 IO 中，数据需要先从磁盘读取到操作系统的缓冲区，再从操作系统缓冲区拷贝到 JVM 的堆内存，然后再进行后续处理；而在 NIO 中，数据可以直接读取到直接内存中，JVM 可以直接对其进行操作，大大提高了读写性能。 9. 堆栈的区别是什么？ 存储内容不同：栈内存一般用于存储局部变量和方法调用相关的信息，例如方法的参数、局部变量等；而堆内存主要用于存储 Java 对象和数组等数据。 内存管理方式不同：堆内存会进行 GC 垃圾回收，当对象不再被引用时，垃圾回收器会自动回收其占用的内存；而栈内存的管理相对简单，当栈帧弹栈时，其所占用的内存会自动释放，不需要垃圾回收机制。 线程相关性不同：栈内存是线程私有的，每个线程都有自己独立的栈，线程之间的栈内存相互隔离；而堆内存是线程共有的，多个线程可以同时访问和操作堆中的对象。 异常类型不同：如果栈内存不足，会抛出 java.lang.StackOverFlowError 异常，通常是由于递归调用过深或栈帧过大导致栈空间耗尽；如果堆内存不足，会抛出 java.lang.OutOfMemoryError 异常，例如创建过多的对象导致堆内存被耗尽。嘻嘻 10. 什么是类加载器，类加载器有哪些? 类加载器\nJVM只会运行二进制文件，而类加载器（ClassLoader）的主要作用就是将字节码文件加载到JVM中，从而让Java程序能够启动起来。现有的类加载器基本上都是java.lang.ClassLoader的子类，该类的主要职责就是用于将指定的类找到或生成对应的字节码文件，同时类加载器还会负责加载程序所需要的资源。\n类加载器种类\n类加载器根据各自加载范围的不同，划分为四种类加载器：\n启动类加载器(BootStrap ClassLoader)： 该类并不继承ClassLoader类，其是由C++编写实现。用于加载JAVA_HOME/jre/lib目录下的类库。 扩展类加载器(ExtClassLoader)： 该类是ClassLoader的子类，主要加载JAVA_HOME/jre/lib/ext目录中的类库。 应用类加载器(AppClassLoader)： 该类是ClassLoader的子类，主要用于加载classPath下的类，也就是加载开发者自己编写的Java类。 自定义类加载器： 开发者自定义类继承ClassLoader，实现自定义类加载规则。 类加载器的体系并不是“继承”体系，而是委派体系，类加载器首先会到自己的parent中查找类或者资源，如果找不到才会到自己本地查找。类加载器的委托行为动机是为了避免相同的类被加载多次。\n11. 什么是双亲委派模型？ 如果一个类加载器在接到加载类的请求时，它首先不会自己尝试去加载这个类，而是把这个请求任务委托给父类加载器去完成，依次递归，如果父类加载器可以完成类加载任务，就返回成功；只有父类加载器无法完成此加载任务时，才由下一级去加载。\n12. JVM为什么采用双亲委派机制 （1）通过双亲委派机制可以避免某一个类被重复加载，当父类已经加载后则无需重复加载，保证唯一性。\n（2）为了安全，保证类库API不会被修改\n13. 说一下类装载的执行过程？ 类从加载到虚拟机中开始，直到卸载为止，它的整个生命周期包括了：加载、验证、准备、解析、初始化、使用和卸载这7个阶段。其中，验证、准备和解析这三个部分统称为连接（linking）。\n加载: 查找和导入class文件 验证: 保证加载类的准确性 准备: 为类变量分配内存并设置类变量初始值 解析: 把类中的符号引用转换为直接引用 初始化: 对类的静态变量，静态代码块执行初始化操作 使用: JVM 开始从入口方法开始执行用户的程序代码 卸载: 当用户程序代码执行完毕后，IVM便开始销毁创建的Class对象。\n一、加载\n核心任务：通过类的全限定名（类的全名），获取该类的二进制数据流。这通常涉及到从文件系统、网络或其他存储位置读取类的字节码文件（.class文件）。接着，将类的二进制数据流解析为方法区内特定的数据结构，即构建起符合 Java 类模型的数据表示。最后，创建java.lang.Class类的实例，这个实例作为后续对该类各种数据（如字段、方法等）进行访问的入口。 示例说明：假设存在一个User类，类加载器会根据User类的全限定名找到对应的.class文件，读取其字节码数据，将其转换为 JVM 内部能够理解的类模型结构，并创建Class\u0026lt;User\u0026gt;实例，后续可以通过这个实例获取User类的相关信息。 二、连接\n验证 目的：确保被加载的类符合 JVM 规范，是安全可靠的，防止恶意或错误的字节码对 JVM 运行造成危害。 具体内容 文件格式验证：检查字节码文件是否符合Class文件的规范，例如文件的魔数、版本号、常量池格式等是否正确。 元数据验证：验证类的元数据信息，如类是否有父类（除Object外应都有父类）、是否继承了被final修饰的类（不允许继承）、类中的字段和方法是否与父类存在矛盾（如覆盖final方法或字段）等。 字节码验证：对字节码进行数据流和控制流分析，确保程序语义合法、逻辑正确，例如检查跳转指令是否指向合法的位置、操作数栈的操作是否正确等。 符号引用验证：验证符号引用的有效性，如类、字段、方法等的符号引用是否能正确解析到目标。 准备 内存分配：为类变量（被static修饰的变量）分配内存空间。此时，类变量会被赋予默认初始值，例如int类型变量初始化为0，boolean类型变量初始化为false等。 特殊情况：对于static且为final的基本类型变量，以及字符串常量，其值在编译期就已确定，会在准备阶段直接赋值。而对于static且为final的引用类型变量，赋值操作则在初始化阶段完成。 解析 任务：将类中的符号引用转换为直接引用。符号引用是一组用于描述所引用目标的符号，与虚拟机实现的内存布局无关；而直接引用是可以直接指向目标的指针、相对偏移量或能间接定位目标的句柄，与虚拟机内存布局直接相关。 示例：当一个方法中调用了其他方法时，方法名在编译期是符号引用，在解析阶段会将其转换为指向实际方法内存地址的直接引用，使得 JVM 能够直接调用该方法。 三、初始化\n**静态成员初始化：**对类的静态变量和静态代码块执行初始化操作。 父类优先：如果初始化一个类时，其父类尚未初始化，则优先初始化其父类。这保证了类继承体系中，父类的静态资源先被初始化，子类可以基于父类已初始化的状态进行自身的初始化。 顺序执行：当类中同时包含多个静态变量和静态代码块时，按照自上而下的顺序依次执行。例如，先定义的静态变量会先于后面的静态代码块以及后续定义的静态变量被初始化。 触发时机：初始化阶段通常在以下几种情况下触发：创建类的实例（使用new关键字）、调用类的静态方法、访问类的静态字段（除final常量外，因为其在准备阶段已赋值）、反射调用类等。 四、使用\n执行入口方法：JVM 从程序的入口方法（如main方法）开始执行用户的程序代码。这是程序运行的起点，后续的代码执行和逻辑处理都基于此展开。 调用静态成员：在程序执行过程中，可以调用类的静态成员信息，包括静态字段和静态方法。静态成员是类级别的资源，可被类的所有实例共享访问，常用于实现与类相关的通用功能或存储类级别的数据。 创建对象实例：使用new关键字为类创建对象实例。创建对象时，会在堆内存中分配空间，初始化对象的成员变量，并调用对象的构造函数完成对象的初始化。创建的对象实例可以访问类的非静态成员，执行对象特定的行为和操作。 五、卸载\n当用户程序代码执行完毕后，JVM 会开始销毁之前创建的Class对象。这包括释放与类相关的所有内存资源，如类的元数据信息（存储在方法区）、静态变量所占用的内存等。随着所有相关Class对象被销毁，负责运行程序的 JVM 也会退出内存，整个类加载的生命周期结束。\n通过对类加载各个阶段的详细了解，可以更好地理解 Java 程序在运行时的行为和机制，对于排查问题、优化性能等方面具有重要意义。\n14. 简述Java垃圾回收机制？（GC是什么？为什么要GC） 为了让程序员更专注于代码的实现，而不用过多的考虑内存释放的问题，所以，在Java语言中，有了自动的垃圾回收机制，也就是我们熟悉的GC(Garbage Collection)。\n有了垃圾回收机制后，程序员只需要关心内存的申请即可，内存的释放由系统自动识别完成。\n在进行垃圾回收时，不同的对象引用类型，GC会采用不同的回收时机\n换句话说，自动的垃圾回收的算法就会变得非常重要了，如果因为算法的不合理，导致内存资源一直没有释放，同样也可能会导致内存溢出的。\n15. 对象什么时候可以被垃圾器回收 简单一句就是：如果一个或多个对象没有任何的引用指向它了，那么这个对象现在就是垃圾，如果定位了垃圾，则有可能会被垃圾回收器回收。\n如果要定位什么是垃圾，有两种方式来确定，第一个是引用计数法，第二个是可达性分析算法。\n16. 定位垃圾的方法 1. 引用计数法\n原理：对象每被引用一次，其引用计数就递增一次；当引用计数为 0 时，该对象可被回收。例如String demo = new String(\u0026quot;123\u0026quot;);，此时demo对象引用计数为 1，当demo = null;时，demo对象引用计数降为 0，可被回收。 缺点：对象间存在循环引用时会失效。例如两个对象相互引用，即使它们不再被外部引用，引用计数也不会为 0，导致无法回收，引发内存泄漏。同时，每次对象引用状态改变都要更新计数器，有时间开销且浪费 CPU 资源，即便内存充足也持续统计。 2. 可达性分析算法\n原理：以 GC Roots 为根节点，通过引用关系向下遍历所有对象。若对象与根节点无直接或间接引用，则可被判定为垃圾回收对象。GC Roots 包括虚拟机栈（栈帧中的本地变量表）中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象以及本地方法栈中 JNI 引用的对象。 对象回收特殊情况：对象被标记为可回收后，若其finalize方法未执行，GC 时会先执行该方法。在finalize方法中，若设置对象与 GC ROOTS 产生关联，则 GC 再次判断时该对象可达，不会被回收；若仍不可达，则进行回收。且finalize方法对每个对象仅执行一次。 17. 垃圾回收算法 （一）标记清除算法\n流程：分标记和清除两个阶段。先根据可达性分析算法标记所有可回收对象，然后对标记对象进行回收。 优缺点：能解决引用计数法的循环引用问题，但效率低，标记和清除都需遍历所有对象，且 GC 时需停止应用程序，影响交互性。清理出的内存碎片化严重，因为被回收对象分散在内存各处，导致内存不连贯。 （二）复制算法\n流程：将内存空间一分为二，每次只使用其中一块。垃圾回收时，将正在使用块中的存活对象复制到另一块，然后清空当前使用块，两块内存角色交换，重复此过程。 适用场景及优缺点：当内存中垃圾对象较多，需复制的存活对象较少时效率高，且清理后内存无碎片。但同一时刻只能使用一半内存，内存使用率低。 （三）标记整理算法\n流程：在标记清除算法基础上改进。同样先标记可回收对象，清理阶段将存活对象向内存一端移动，然后清理边界以外的垃圾。 优缺点：解决了标记清除算法的内存碎片化问题，但多了对象移动步骤，效率会受一定影响。与复制算法相比，复制算法标记完就复制对象，而标记整理算法需等所有存活对象标记完毕后再整理。 （四）分代收集算法\n堆内存划分：Java 8 时，堆分为新生代和老年代，比例为 1:2。新生代又细分为 Eden 区、S0 区和 S1 区，比例为 8:1:1。Java 7 时还存在永久代。 不同 GC 类型 Minor GC（Young GC）：发生在新生代的垃圾回收，暂停时间短（STW, Stop-The-World）。新创建对象先分配到 Eden 区，Eden 区内存不足时，标记 Eden 区和 from 区（初始时无）的存活对象，用复制算法将其复制到 to 区，Eden 区和 from 区内存释放。经过多次回收，幸存区对象若熬过一定次数（最多 15 次）或因幸存区内存不足、大对象等原因，会晋升到老年代。 Major GC：发生在老年代的垃圾回收。 Full GC：新生代和老年代完整垃圾回收，暂停时间长，应尽量避免。 Mixed GC：新生代和老年代部分区域的垃圾回收，是 G1 收集器特有的。 18. 垃圾回收器 （一）串行垃圾收集器\n特点：使用单线程进行垃圾回收，适用于堆内存较小的个人电脑。 应用区域及算法：Serial 用于新生代，采用复制算法；Serial Old 用于老年代，采用标记 - 整理算法。垃圾回收时，Java 应用所有线程都要暂停（STW）等待回收完成。 （二）并行垃圾收集器\n特点：多线程进行垃圾回收，JDK8 默认使用。 应用区域及算法：Parallel New 作用于新生代，采用复制算法；Parallel Old 作用于老年代，采用标记 - 整理算法。同样在垃圾回收时，所有应用线程需暂停（STW）。 （三）CMS（并发）垃圾收集器\n特点：针对老年代，采用标记 - 清除算法，以获取最短回收停顿时间为目标，垃圾回收时应用仍能正常运行，停顿时间短，用户体验好。 （四）G1 垃圾收集器\n概述：应用于新生代和老年代，JDK9 之后默认使用。将内存划分为多个区域，每个区域可充当 eden、survivor、old、humongous（专为大对象准备）。采用复制算法，兼顾响应时间与吞吐量。分为新生代回收、并发标记、混合收集三个阶段，若并发失败（回收速度赶不上创建新对象速度），会触发 Full GC。 工作阶段 年轻代垃圾回收（Young Collection）：初始时所有区域空闲，创建对象存于伊甸园区。伊甸园需回收时，选一个空闲区域做幸存区，用复制算法复制存活对象，需暂停用户线程。后续伊甸园内存再不足时，将伊甸园及之前幸存区存活对象复制到新幸存区，较老对象晋升到老年代。 年轻代垃圾回收 + 并发标记（Young Collection + Concurrent Mark）：老年代占用内存超阈值（默认 45%）后触发并发标记，此时无需暂停用户线程。并发标记后有重新标记阶段解决漏标问题，需暂停用户线程。完成后确定老年代存活对象，进入混合收集阶段，根据暂停时间目标优先回收存活对象少的区域。 混合收集（Mixed Collection）：完成对象复制，释放内存，进入下一轮回收循环。 19、对象引用类型 （一）强引用\n只有所有 GC Roots 对象都不通过强引用引用该对象时，该对象才能被垃圾回收。例如User user = new User();，只要user引用存在，User对象就不会被回收。\n（二）软引用\n仅有软引用引用对象时，垃圾回收后若内存仍不足，会再次触发对该对象的回收。如User user = new User(); SoftReference softReference = new SoftReference(user);，在内存紧张时，软引用对象可能被回收。\n（三）弱引用\n仅有弱引用引用对象时，垃圾回收时无论内存是否充足，都会回收该对象。例如User user = new User(); WeakReference weakReference = new WeakReference(user);。ThreadLocal 使用弱引用，其内部Entry类的key为弱引用，value为强引用。当key被回收而value未清理时可能导致内存泄漏，因此使用 ThreadLocal 后建议调用清理方法。\n（四）虚引用\n必须配合引用队列使用，被引用对象回收时，虚引用会入队，由 Reference Handler 线程调用相关方法释放直接内存。\nJVM 调优实践 1. JVM 调优参数设置位置 Tomcat：要在 Tomcat 里设置 JVM 调优参数，得去修改TOMCAT_HOME/bin/catalina.sh文件。比如，你想设置堆的初始大小为 512MB，最大大小为 1024MB，就在文件里加上JAVA_OPTS=\u0026quot;-Xms512m -Xmx1024m\u0026quot; 。这样，Tomcat 启动时就会按照你设置的参数来分配堆内存。 Spring Boot 项目：在 Linux 系统下启动 Spring Boot 项目时，能直接在启动命令里加参数。像 nohup java -Xms512m -Xmx1024m -jar xxxx.jar --spring.profiles.active=prod \u0026amp; ，nohup 能让命令在后台一直运行，关了终端也不受影响，\u0026amp; 也是让命令在后台执行。这里同样设置了堆的初始和最大大小，还指定了项目运行环境是prod 。 2. 常用 JVM 调优参数 堆大小设置 -Xms ：用来设置堆的初始化大小。比如说 -Xms512m ，意思就是堆刚开始就分配 512MB 内存。通常为了不让垃圾收集器在初始大小和最大大小之间来回调整堆大小，浪费时间，会把 -Xms 和 -Xmx 设置成一样的值。 -Xmx ：这个是设置堆能达到的最大大小。例如 -Xmx1024m ，就是说堆最多可以使用 1024MB 内存。 新生代内存分配比例设置 -XX:SurvivorRatio ：它决定年轻代里 Eden 区和两个 Survivor 区的大小比例。默认是 8:1:1 。要是设置 -XXSurvivorRatio=3 ，那就表示年轻代里 survivor 区和 eden 区的比例是 2:3 。Java 官方一般会增大 Eden 区来减少 YGC（新生代垃圾回收）的次数，但 Eden 区太大，满了之后释放内存会变慢，程序暂停（STW）的时间就长，所以要根据实际程序情况来调整这个比例。 -XX:newSize ：设置年轻代的初始大小。 -XX:MaxNewSize ：设置年轻代能达到的最大大小。一般把这两个值设成一样，默认年轻代和老年代的空间比例是 1:2 ，通过这两个参数可以调整它们的大小。 线程堆栈设置 -Xss ：每个线程默认有 1M 的堆栈空间，用来放栈帧、调用参数、局部变量这些东西。但一般 256K 就够了。如果减少每个线程的堆栈大小，理论上能产生更多线程，不过这也受操作系统限制。比如 -Xss128k ，就是把每个线程的堆栈大小设成 128KB 。 对象晋升老年代相关设置 -Xmn ：设置年轻代的大小。合理设置 eden 区、survivor 区以及它们的使用率，能让年轻对象留在年轻代，避免 Full GC（全量垃圾回收）。 -XX:PetenureSizeThreshold ：指定对象晋升到老年代的大小门槛，单位是字节。比如 -XX:PetenureSizeThreshold=1000000 ，就是说对象大小超过 1MB，就直接在老年代分配内存，防止在年轻代频繁移动大对象，导致 Full GC。 -XX:MaxTenuringThreshold ：设置对象在 Survivor 区存活的最大年龄。年轻对象在 Eden 区经过第一次 GC 后还活着，就会被移到 Survivor 区，之后每 GC 一次年龄加 1 ，当年龄达到这个阈值，就会被移到老年区。要是想让对象留在年轻代，就设个大一点的阈值。 垃圾回收器选择设置 -XX:+UseParallelGC ：让年轻代使用并行垃圾回收收集器，这个收集器注重吞吐量，能减少垃圾回收的时间。 -XX:+UseParallelOldGC ：设置老年代也用并行垃圾回收收集器。 -XX:+UseConcMarkSweepGC ：让老年代用 CMS（Concurrent Mark Sweep）收集器，这个收集器能降低垃圾回收时程序暂停的时间。 内存分页设置 -XX:+LargePageSizeInBytes ：设置内存页的大小。用大的内存分页可以让 CPU 内存寻址能力变强，提高系统性能。 3. JVM 调优工具 命令行工具 jps（Java Process Status） ：它能输出 JVM 里正在运行的进程状态信息，通过它可以看到当前运行的 Java 进程以及相关信息。 jstack ：用来查看 Java 进程里线程的堆栈信息。使用方法是 jstack [option] \u0026lt;pid\u0026gt; ，\u0026lt;pid\u0026gt; 就是进程 ID 。通过分析线程堆栈，能找到线程死锁、长时间阻塞这些问题。 jmap可以生成堆转存快照。常见命令有： jmap -heap pid ：能显示 Java 堆的信息，像各代的大小、比例，还有使用情况。 jmap -dump:format=b,file=heap.hprof pid ：把 Java 堆内存以 hprof 二进制格式转储，并且保存成你指定的文件 heap.hprof 。 jstat是 JVM 的统计监测工具，能显示垃圾回收信息、类加载信息、新生代统计信息等。常见参数有： jstat -gcutil pid ：总结垃圾回收的统计信息，包括各代的使用率、GC 次数、GC 花的时间等。 jstat -gc pid ：详细输出垃圾回收统计信息，比如对象在各代之间怎么移动、怎么回收的。 jhat ：可以分析 jmap 生成的堆转存快照，但一般不推荐用它，现在常用 Eclipse Memory Analyzer 这类工具替代。 可视化工具 jconsole ：这是基于 JMX（Java Management Extensions）的图形化性能监控工具，可以监控 JVM 的内存、线程、类等。在 Java 安装目录的bin目录下，直接启动 jconsole.exe （Windows 系统）或者 jconsole （Linux 系统），连上目标 Java 进程，就能很直观地看到各种运行指标。 VisualVM ：是故障处理工具，能监控线程、内存情况，查看方法耗费 CPU 的时间，内存里的对象，已经被 GC 的对象，还能反向查看对象分配的堆栈。在 Java 安装目录的bin目录下启动 jvisualvm.exe （Windows 系统），它能加载离线的堆转存快照（.hprof文件）进行分析，方便找出内存泄漏这类问题。 4. Java 内存泄露排查思路 生成内存快照可以用jmap命令指定生成内存快照 dump 文件。但要是程序因为内存溢出已经中断了，\njmap就没法用了。\n这时候可以设置 VM 参数让程序自动生成 dump 文件，设置方法是：\n-XX:+HeapDumpOnOutOfMemoryError ：打开内存溢出时自动生成堆转储快照的功能。 -XX:HeapDumpPath=/home/app/dumps/ ：指定生成文件保存的目录是 /home/app/dumps/ 。 分析 dump 文件：用工具来分析 dump 文件，比如 JDK 自带的 VisualVM （也可以用 Eclipse Memory Analyzer 等）。 VisualVM 能加载离线的 dump 文件，如果是 Linux 系统里程序生成的 dump 文件，得先下载到本地（比如 Windows 环境），再用 VisualVM 打开分析。\n定位问题代码：通过查看堆信息，像对象数量、大小、引用关系这些，大概就能找到内存溢出是哪段代码导致的。\n修复问题：找到对应的代码，看看上下文，分析对象的生命周期和引用关系，然后修改导致内存泄漏的代码逻辑，比如释放掉没用的引用，优化对象创建和销毁的方式等。\n5. 服务器 CPU 持续飙高排查方案与思路 使用top命令查看 CPU 占用情况：在终端输入 top 命令，就能实时看到系统里各个进程的 CPU 占用率等信息，这样就能找出哪个进程占用 CPU 比较高。 确定高 CPU 占用进程 ID：从 top 命令的结果里，记下占用 CPU 高的那个进程的 ID 。 查看进程内线程信息：用 ps 命令查看这个进程里的线程信息，找出 CPU 占用高的线程。比如 ps H -eo pid,tid,%CPU | grep \u0026lt;进程ID\u0026gt; ，pid 是进程 ID ，tid 是线程 ID ，%CPU 是 CPU 使用率，这个命令能筛选出指定进程里每个线程的 CPU 使用情况。 转换线程 ID 为十六进制：通常日志里显示的线程 ID 是十六进制的，所以要把前面得到的十进制线程 ID 转换成十六进制。在 Linux 里用 printf \u0026quot;%x\\n\u0026quot; \u0026lt;线程ID\u0026gt; 这个命令就能转换。 定位问题代码行号：用 jstack 命令打印进程的堆栈信息，根据转换后的十六进制线程 ID 找到有问题的线程，进而找到问题代码在源码里的行号。执行 jstack \u0026lt;进程ID\u0026gt; 命令，分析输出的堆栈信息，找到线程执行的方法调用栈，就能确定是哪段代码导致 CPU 飙高，然后再分析代码逻辑，看看是不是有死循环、复杂计算没优化这些问题，找到原因后进行修复。 面试现场 一、JVM组成 面试官：JVM由那些部分组成，运行流程是什么？\n候选人:\n嗯，好的~~\n在JVM中共有四大部分，分别是ClassLoader（类加载器）、Runtime Data Area（运行时数据区，内存分区）、Execution Engine（执行引擎）、Native Method Library（本地库接口）\n它们的运行流程是：\n第一，类加载器（ClassLoader）把Java代码转换为字节码\n第二，运行时数据区（Runtime Data Area）把字节码加载到内存中，而字节码文件只是JVM的一套指令集规范，并不能直接交给底层系统去执行，而是有执行引擎运行\n第三，执行引擎（Execution Engine）将字节码翻译为底层系统指令，再交由CPU执行去执行，此时需要调用其他语言的本地库接口（Native Method Library）来实现整个程序的功能。\n面试官：好的，你能详细说一下 JVM 运行时数据区吗？\n候选人:\n嗯，好~\n运行时数据区包含了堆、方法区、栈、本地方法栈、程序计数器这几部分，每个功能作用不一样。\n堆解决的是对象实例存储的问题，垃圾回收器管理的主要区域。 方法区可以认为是堆的一部分，用于存储已被虚拟机加载的信息，常量、静态变量、即时编译器编译后的代码。 栈解决的是程序运行的问题，栈里面存的是栈帧，栈帧里面存的是局部变量表、操作数栈、动态链接、方法出口等信息。 本地方法栈与栈功能相同，本地方法栈执行的是本地方法，一个Java调用非Java代码的接口。 程序计数器（PC寄存器）程序计数器中存放的是当前线程所执行的字节码的行数。JVM工作时就是通过改变这个计数器的值来选取下一个需要执行的字节码指令。 面试官：好的，你再详细介绍一下程序计数器的作用？\n候选人:\n嗯，是这样~~\njava虚拟机对于多线程是通过线程轮流切换并且分配线程执行时间。在任何的一个时间点上，一个处理器只会处理执行一个线程，如果当前被执行的这个线程它所分配的执行时间用完了【挂起】。处理器会切换到另外的一个线程上来进行执行。并且这个线程的执行时间用完了，接着处理器就会又来执行被挂起的这个线程。这时候程序计数器就起到了关键作用，程序计数器在来回切换的线程中记录他上一次执行的行号，然后接着继续向下执行。\n面试官：你能给我详细的介绍Java堆吗?\n候选人:\n好的~\nJava中的堆术语线程共享的区域。主要用来保存对象实例，数组等，当堆中没有内存空间可分配给实例，也无法再扩展时，则抛出OutOfMemoryError异常。\n​ 在JAVA8中堆内会存在年轻代、老年代\n​ 1）Young区被划分为三部分，Eden区和两个大小严格相同的Survivor区，其中，Survivor区间中，某一时刻只有其中一个是被使用的，另外一个留做垃圾收集时复制对象用。在Eden区变满的时候， GC就会将存活的对象移到空闲的Survivor区间中，根据JVM的策略，在经过几次垃圾收集后，任然存活于Survivor的对象将被移动到Tenured区间。\n​ 2）Tenured区主要保存生命周期长的对象，一般是一些老的对象，当一些对象在Young复制转移一定的次数以后，对象就会被转移到Tenured区。\n面试官：能不能解释一下方法区？\n候选人:\n方法区（Method Area）是 Java 虚拟机（JVM）内存结构中的一个区域，它主要用于存储已被虚拟机加载的类信息（版本、字段、方法、接口等）、常量、静态变量、即时编译器编译后的代码等数据。方法区是所有线程共享的内存区域，它在虚拟机启动时创建，并且在虚拟机的生命周期内一直存在。\n需要注意的是，在 JDK 1.8 之前，方法区被称为永久代（Permanent Generation），它与堆内存的其他区域（如新生代、老年代）类似，是 JVM 的一部分。从 JDK 1.8 开始，永久代被移除，方法区被重新设计为元空间（Metaspace），元空间使用本地内存（Native Memory），而不是堆内存。\n面试官：你听过直接内存吗？\n候选人:\n直接内存也被称为堆外内存，它是一种位于 Java 虚拟机堆外的内存，通常通过 Java Native Interface（JNI）或者java.nio.ByteBuffer.allocateDirect() 方法进行分配。这种内存直接使用系统的本地内存，因此它不受 JVM 堆大小的限制，也不会受到垃圾回收（GC）机制的管理。由于直接内存是线程共享的，所以所有线程都可以访问其中的数据。此外，直接内存特别适合用于高性能的 I/O 操作，因为它能够减少数据在 JVM 堆和本地内存之间的拷贝，从而提高 I/O 操作的效率。不过，由于直接内存不受 GC 管理，开发者需要手动管理内存的分配和释放，否则可能会导致内存泄漏。\n面试官：Java 8 中将方法区从永久代迁移到元空间的改动带来了哪些好处和潜在影响？\n候选人\n在 Java 8 之前，方法区是通过 HotSpot 虚拟机的永久代来实现的，它存储了类的信息、常量、静态变量以及即时编译器编译后的代码等。由于永久代是 JVM 堆的一部分，它受到垃圾回收（GC）的管理，并且有一个 -XX:MaxPermSize 的上限。这导致在大量动态生成类时，很容易出现 OutOfMemoryError。虽然可以通过增大 -XX:MaxPermSize 来缓解，但很难确定一个合适的大小，因为它受到类的数量和常量数量的影响很大。\n从 Java 8 开始，方法区的实现被迁移到了本地内存中的元空间。元空间使用本地内存而不是 JVM 堆内存，因此它不受 -XX:MaxPermSize 的限制，也不受 JVM 垃圾回收机制的直接管理。这种改动带来了以下好处和潜在影响：\n好处\n减少 OutOfMemoryError：由于元空间使用本地内存，不再受 JVM 堆大小的限制，因此减少了因永久代空间不足而导致的 OutOfMemoryError。 更灵活的内存管理：元空间的大小可以通过 -XX:MaxMetaspaceSize 参数进行设置，但默认情况下，元空间会自动扩展，避免了手动调整内存大小的麻烦。 性能提升：由于元空间不再受 GC 的频繁管理，减少了 GC 的负担，从而提升了整体性能。 潜在影响\n内存使用增加：元空间使用本地内存，可能会导致系统内存的使用量增加，尤其是在类加载频繁的应用中。 监控和管理复杂性：由于元空间使用本地内存，监控和管理元空间的内存使用情况可能比监控永久代更加复杂。 兼容性问题：对于一些依赖于永久代特性的旧代码或工具，可能需要进行调整以适应新的元空间机制。 面试官：什么是虚拟机栈\n候选人:\n虚拟机栈是描述的是方法执行时的内存模型,是线程私有的，生命周期与线程相同，每个方法被执行的同时会创建栈桢。保存执行方法时的局部变量、动态连接信息、方法返回地址信息等等。方法开始执行的时候会进栈，方法执行完会出栈【相当于清空了数据】，所以这块区域不需要进行 GC。\n面试官：能说一下堆栈的区别是什么吗？\n候选人:\n嗯，好的，有这几个区别\n第一，栈内存一般会用来存储局部变量和方法调用，但堆内存是用来存储Java对象和数组的的。堆会GC垃圾回收，而栈不会。\n第二、栈内存是线程私有的，而堆内存是线程共有的。\n第三、两者异常错误不同，但如果栈内存或者堆内存不足都会抛出异常。\n栈空间不足：java.lang.StackOverFlowError。\n堆空间不足：java.lang.OutOfMemoryError。\n二、类加载器 面试官：什么是类加载器，类加载器有哪些?\n候选人:\n嗯，是这样的\nJVM只会运行二进制文件，而类加载器（ClassLoader）的主要作用就是将字节码文件加载到JVM中，从而让Java程序能够启动起来。\n常见的类加载器有4个\n第一个是启动类加载器(BootStrap ClassLoader)：其是由C++编写实现。用于加载JAVA_HOME/jre/lib目录下的类库。\n第二个是扩展类加载器(ExtClassLoader)：该类是ClassLoader的子类，主要加载JAVA_HOME/jre/lib/ext目录中的类库。\n第三个是应用类加载器(AppClassLoader)：该类是ClassLoader的子类，主要用于加载classPath下的类，也就是加载开发者自己编写的Java类。\n第四个是自定义类加载器：开发者自定义类继承ClassLoader，实现自定义类加载规则。\n面试官：说一下类装载的执行过程？\n候选人:\n嗯，这个过程还是挺多的。\n类从加载到虚拟机中开始，直到卸载为止，它的整个生命周期包括了：加载、验证、准备、解析、初始化、使用和卸载这7个阶段。其中，验证、准备和解析这三个部分统称为连接（linking）\n1.加载：查找和导入class文件\n2.验证：保证加载类的准确性\n3.准备：为类变量分配内存并设置类变量初始值\n4.解析：把类中的符号引用转换为直接引用\n5.初始化：对类的静态变量，静态代码块执行初始化操作\n6.使用：JVM 开始从入口方法开始执行用户的程序代码\n7.卸载：当用户程序代码执行完毕后，JVM 便开始销毁创建的 Class 对象，最后负责运行的 JVM 也退出内存\n面试官：什么是双亲委派模型？\n候选人:\n嗯，它是是这样的。\n如果一个类加载器收到了类加载的请求，它首先不会自己尝试加载这个类，而是把这请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传输到顶层的启动类加载器中，只有当父类加载器返回自己无法完成这个加载请求（它的搜索返回中没有找到所需的类）时，子类加载器才会尝试自己去加载\n面试官：JVM为什么采用双亲委派机制\n候选人:\n主要有两个原因。\n第一、通过双亲委派机制可以避免某一个类被重复加载，当父类已经加载后则无需重复加载，保证唯一性。\n第二、为了安全，保证类库API不会被修改\n三、垃圾回收 面试官：简述Java垃圾回收机制？（GC是什么？为什么要GC）\n候选人:\n嗯，是这样~~\n为了让程序员更专注于代码的实现，而不用过多的考虑内存释放的问题，所以，在Java语言中，有了自动的垃圾回收机制，也就是我们熟悉的GC(Garbage Collection)。\n有了垃圾回收机制后，程序员只需要关心内存的申请即可，内存的释放由系统自动识别完成。\n在进行垃圾回收时，不同的对象引用类型，GC会采用不同的回收时机\n面试官：强引用、软引用、弱引用、虚引用的区别？\n候选人:\n嗯嗯~\n强引用最为普通的引用方式，表示一个对象处于有用且必须的状态，如果一个对象具有强引用，则GC并不会回收它。即便堆中内存不足了，宁可出现OOM，也不会对其进行回收\n软引用表示一个对象处于有用且非必须状态，如果一个对象处于软引用，在内存空间足够的情况下，GC机制并不会回收它，而在内存空间不足时，则会在OOM异常出现之间对其进行回收。但值得注意的是，因为GC线程优先级较低，软引用并不会立即被回收。\n弱引用表示一个对象处于可能有用且非必须的状态。在GC线程扫描内存区域时，一旦发现弱引用，就会回收到弱引用相关联的对象。对于弱引用的回收，无关内存区域是否足够，一旦发现则会被回收。同样的，因为GC线程优先级较低，所以弱引用也并不是会被立刻回收。\n虚引用表示一个对象处于无用的状态。在任何时候都有可能被垃圾回收。虚引用的使用必须和引用队列Reference Queue联合使用\n面试官：对象什么时候可以被垃圾器回收\n候选人:\n思考一会~~\n如果一个或多个对象没有任何的引用指向它了，那么这个对象现在就是垃圾，如果定位了垃圾，则有可能会被垃圾回收器回收。\n如果要定位什么是垃圾，有两种方式来确定，第一个是引用计数法，第二个是可达性分析算法\n通常都使用可达性分析算法来确定是不是垃圾\n面试官： JVM 垃圾回收算法有哪些？\n候选人:\n我记得一共有四种，分别是标记清除算法、复制算法、标记整理算法、分代回收\n面试官： 你能详细聊一下分代回收吗？\n候选人:\n关于分代回收是这样的\n在java8时，堆被分为了两份：新生代和老年代，它们默认空间占用比例是1:2\n对于新生代，内部又被分为了三个区域。Eden区，S0区，S1区默认空间占用比例是8:1:1\n具体的工作机制是有些情况：\n1）当创建一个对象的时候，那么这个对象会被分配在新生代的Eden区。当Eden区要满了时候，触发YoungGC。\n2）当进行YoungGC后，此时在Eden区存活的对象被移动到S0区，并且当前对象的年龄会加1，清空Eden区。\n3）当再一次触发YoungGC的时候，会把Eden区中存活下来的对象和S0中的对象，移动到S1区中，这些对象的年龄会加1，清空Eden区和S0区。\n4）当再一次触发YoungGC的时候，会把Eden区中存活下来的对象和S1中的对象，移动到S0区中，这些对象的年龄会加1，清空Eden区和S1区。\n5）对象的年龄达到了某一个限定的值（默认15岁 ），那么这个对象就会进入到老年代中。\n当然也有特殊情况，如果进入Eden区的是一个大对象，在触发YoungGC的时候，会直接存放到老年代\n当老年代满了之后，触发FullGC。FullGC同时回收新生代和老年代，当前只会存在一个FullGC的线程进行执行，其他的线程全部会被挂起。 我们在程序中要尽量避免FullGC的出现。\n面试官：讲一下新生代、老年代、永久代的区别？\n候选人:\n嗯！是这样的，简单说就是\n新生代主要用来存放新生的对象。\n老年代主要存放应用中生命周期长的内存对象。\n永久代指的是永久保存区域。主要存放Class和Meta（元数据）的信息。在Java8中，永久代已经被移除，取而代之的是一个称之为“元数据区”（元空间）的区域。元空间和永久代类似，不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存的限制。\n面试官：说一下 JVM 有哪些垃圾回收器？\n候选人:\n在jvm中，实现了多种垃圾收集器，包括：串行垃圾收集器、并行垃圾收集器（JDK8默认）、CMS（并发）垃圾收集器、G1垃圾收集器（JDK9默认）\n面试官：Minor GC、Major GC、Full GC是什么\n候选人:\n嗯，其实它们指的是不同代之间的垃圾回收\nMinor GC 发生在新生代的垃圾回收，暂停时间短\nMajor GC 老年代区域的垃圾回收，老年代空间不足时，会先尝试触发Minor GC。Minor GC之后空间还不足，则会触发Major GC，Major GC速度比较慢，暂停时间长\nFull GC 新生代 + 老年代完整垃圾回收，暂停时间长，应尽力避免\n四、JVM实践（调优） 面试官：JVM 调优的参数可以在哪里设置参数值？\n候选人:\n我们当时的项目是springboot项目，可以在项目启动的时候，java -jar中加入参数就行了\n面试官：用的 JVM 调优的参数都有哪些？\n候选人:\n嗯，这些参数是比较多的\n我记得当时我们设置过堆的大小，像-Xms和-Xmx\n还有就是可以设置年轻代中Eden区和两个Survivor区的大小比例\n还有就是可以设置使用哪种垃圾回收器等等。具体的指令还真记不太清楚。\n面试官：嗯，好的，你们平时调试 JVM都用了哪些工具呢？\n候选人:\n嗯，我们一般都是使用jdk自带的一些工具，比如\njps 输出JVM中运行的进程状态信息\njstack查看java进程内线程的堆栈信息。\njmap 用于生成堆转存快照\njstat用于JVM统计监测工具\n还有一些可视化工具，像jconsole和VisualVM等\n面试官：假如项目中产生了java内存泄露，你说一下你的排查思路？\n候选人:\n嗯，这个我在之前项目排查过\n第一呢可以通过jmap指定打印他的内存快照 dump文件，不过有的情况打印不了，我们会设置vm参数让程序自动生成dump文件\n第二，可以通过工具去分析 dump文件，jdk自带的VisualVM就可以分析\n第三，通过查看堆信息的情况，可以大概定位内存溢出是哪行代码出了问题\n第四，找到对应的代码，通过阅读上下文的情况，进行修复即可\n面试官：好的，那现在再来说一种情况，就是说服务器CPU持续飙高，你的排查方案与思路？\n候选人:\n嗯，我思考一下~~\n可以这么做~~\n第一可以使用top命令查看占用cpu的情况\n第二通过top命令查看后，可以查看是哪一个进程占用cpu较高，记录这个进程id\n第三可以用 ps 命令查看这个进程里的线程信息，找出 CPU 占用高的线程。\n通常日志里显示的线程 ID 是十六进制的，所以要把前面得到的十进制线程 ID 转换成十六进制。\n第四用 jstack 命令打印进程的堆栈信息，根据转换后的十六进制线程 ID 找到有问题的线程，就可以进一步定位问题代码的行号。\n","date":"2025-04-22T00:00:00Z","image":"https://nova-bryan.github.io/p/java%E9%9D%A2%E8%AF%95/image_hu17089168107649188491.png","permalink":"https://nova-bryan.github.io/p/java%E9%9D%A2%E8%AF%95/","title":"Java面试"},{"content":"请求响应-概述 在上一次的课程中，我们开发了springbootweb的入门程序。 基于SpringBoot的方式开发一个web应用，浏览器发起请求 /hello 后 ，给浏览器返回字符串 “Hello World ~”。\n其实呢，是我们在浏览器发起请求，请求了我们的后端web服务器(也就是内置的Tomcat)。而我们在开发web程序时呢，定义了一个控制器类Controller，请求会被部署在Tomcat中的Controller接收，然后Controller再给浏览器一个响应，响应一个字符串 “Hello World”。 而在请求响应的过程中是遵循HTTP协议的。\n但是呢，这里要告诉大家的时，其实在Tomcat这类Web服务器中，是不识别我们自己定义的Controller的。但是我们前面讲到过Tomcat是一个Servlet容器，是支持Serlvet规范的，所以呢，在tomcat中是可以识别 Servlet程序的。 那我们所编写的XxxController 是如何处理请求的，又与Servlet之间有什么联系呢？\n其实呢，在SpringBoot进行web程序开发时，它内置了一个核心的Servlet程序 DispatcherServlet，称之为 核心控制器。 DispatcherServlet 负责接收页面发送的请求，然后根据执行的规则，将请求再转发给后面的请求处理器Controller，请求处理器处理完请求之后，最终再由DispatcherServlet给浏览器响应数据。\n那将来浏览器发送请求，会携带请求数据，包括：请求行、请求头；请求到达tomcat之后，tomcat会负责解析这些请求数据，然后呢将解析后的请求数据会传递给Servlet程序的HttpServletRequest对象，那也就意味着 HttpServletRequest 对象就可以获取到请求数据。 而Tomcat，还给Servlet程序传递了一个参数 HttpServletResponse，通过这个对象，我们就可以给浏览器设置响应数据 。\n那上述所描述的这种浏览器/服务器的架构模式呢，我们称之为：BS架构。\n• BS架构：Browser/Server，浏览器/服务器架构模式。客户端只需要浏览器，应用程序的逻辑和数据都存储在服务端。\n那今天呢，我们的课程内容主要就围绕着：请求、响应进行。 今天课程内容，主要包含三个部分：\n请求 响应 分层解耦 请求响应-请求-postman工具 Postman是一款功能强大的网页调试与发送网页HTTP请求的Chrome插件。\nPostman原是Chrome浏览器的插件，可以模拟浏览器向后端服务器发起任何形式(如:get、post)的HTTP请求\n使用Postman还可以在发起请求时，携带一些请求参数、请求头等信息\n作用：常用于进行接口测试\n特征\n简单 实用 美观 大方 安装\n双击资料中提供的Postman-win64-8.3.1-Setup.exe即可自动安装。\n安装完成之后，进入页面中会提示有新版本可以升级（无需升级）\n界面介绍:\n如果我们需要将测试的请求信息保存下来，就需要创建一个postman的账号，然后登录之后才可以。\n登录完成之后，可以创建工作空间：\n创建请求：\n点击\u0026quot;Save\u0026quot;，保存当前请求\n请求响应-请求-简单参数\u0026amp;实体参数 简单参数\n简单参数：在向服务器发起请求时，向服务器传递的是一些普通的请求数据。\n那么在后端程序中，如何接收传递过来的普通参数数据呢？\n我们在这里讲解两种方式：\n原始方式 SpringBoot方式 原始方式\n在原始的Web程序当中，需要通过Servlet中提供的API：HttpServletRequest（请求对象），获取请求的相关信息。比如获取请求参数：\nTomcat接收到http请求时：把请求的相关信息封装到HttpServletRequest对象中\n在Controller中，我们要想获取Request对象，可以直接在方法的形参中声明 HttpServletRequest 对象。然后就可以通过该对象来获取请求信息：\n1 2 //根据指定的参数名获取请求参数的数据值 String request.getParameter(\u0026#34;参数名\u0026#34;) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @RestController public class RequestController { //原始方式 @RequestMapping(\u0026#34;/simpleParam\u0026#34;) public String simpleParam(HttpServletRequest request){ // http://localhost:8080/simpleParam?name=Tom\u0026amp;age=10 // 请求参数： name=Tom\u0026amp;age=10 （有2个请求参数） // 第1个请求参数： name=Tom 参数名:name，参数值:Tom // 第2个请求参数： age=10 参数名:age , 参数值:10 String name = request.getParameter(\u0026#34;name\u0026#34;);//name就是请求参数名 String ageStr = request.getParameter(\u0026#34;age\u0026#34;);//age就是请求参数名 int age = Integer.parseInt(ageStr);//需要手动进行类型转换 System.out.println(name+\u0026#34; : \u0026#34;+age); return \u0026#34;OK\u0026#34;; } } 以上这种方式，我们仅做了解。（在以后的开发中不会使用到）\nSpringBoot方式\n在Springboot的环境中，对原始的API进行了封装，接收参数的形式更加简单。 如果是简单参数，参数名与形参变量名相同，定义同名的形参即可接收参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 @RestController public class RequestController { // http://localhost:8080/simpleParam?name=Tom\u0026amp;age=10 // 第1个请求参数： name=Tom 参数名:name，参数值:Tom // 第2个请求参数： age=10 参数名:age , 参数值:10 //springboot方式 @RequestMapping(\u0026#34;/simpleParam\u0026#34;) public String simpleParam(String name , Integer age ){//形参名和请求参数名保持一致 System.out.println(name+\u0026#34; : \u0026#34;+age); return \u0026#34;OK\u0026#34;; } } postman测试( GET 请求)：\npostman测试( POST请求 )：\n结论：不论是GET请求还是POST请求，对于简单参数来讲，只要保证==请求参数名和Controller方法中的形参名保持一致==，就可以获取到请求参数中的数据值。\n参数名不一致\n如果方法形参名称与请求参数名称不一致，controller方法中的形参还能接收到请求参数值吗？\n1 2 3 4 5 6 7 8 9 10 11 12 @RestController public class RequestController { // http://localhost:8080/simpleParam?name=Tom\u0026amp;age=20 // 请求参数名：name //springboot方式 @RequestMapping(\u0026#34;/simpleParam\u0026#34;) public String simpleParam(String username , Integer age ){//请求参数名和形参名不相同 System.out.println(username+\u0026#34; : \u0026#34;+age); return \u0026#34;OK\u0026#34;; } } 答案：运行没有报错。 controller方法中的username值为：null，age值为20\n结论：对于简单参数来讲，请求参数名和controller方法中的形参名不一致时，无法接收到请求数据 那么如果我们开发中，遇到了这种请求参数名和controller方法中的形参名不相同，怎么办？\n解决方案：可以使用Spring提供的@RequestParam注解完成映射\n在方法形参前面加上 @RequestParam 然后通过value属性执行请求参数名，从而完成映射。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 @RestController public class RequestController { // http://localhost:8080/simpleParam?name=Tom\u0026amp;age=20 // 请求参数名：name //springboot方式 @RequestMapping(\u0026#34;/simpleParam\u0026#34;) public String simpleParam(@RequestParam(\u0026#34;name\u0026#34;) String username , Integer age ){ System.out.println(username+\u0026#34; : \u0026#34;+age); return \u0026#34;OK\u0026#34;; } } 注意事项：\n@RequestParam中的required属性默认为true（默认值也是true），代表该请求参数必须传递，如果不传递将报错\n如果该参数是可选的，可以将required属性设置为false\n1 2 3 4 5 @RequestMapping(\u0026#34;/simpleParam\u0026#34;) public String simpleParam(@RequestParam(name = \u0026#34;name\u0026#34;, required = false) String username, Integer age){ System.out.println(username+ \u0026#34;:\u0026#34; + age); return \u0026#34;OK\u0026#34;; } 小结\n\\1. 原始方式获取请求参数\nController方法形参中声明HttpServletRequest对象 调用对象的getParameter(参数名) \\2. SpringBoot中接受简单参数\n请求参数名与方法形参变量名相同 会自动进行类型转换 \\3. @RequestParam注解\n方法形参名称与请求参数名称不匹配，通过该注解完成映射 该注解的required属性默认是true，代表请求参数必须传递 实体参数\n在使用简单参数做为数据传递方式时，前端传递了多少个请求参数，后端controller方法中的形参就要书写多少个。如果请求参数比较多，通过上述的方式一个参数一个参数的接收，会比较繁琐。\n此时，我们可以考虑将请求参数封装到一个实体类对象中。 要想完成数据封装，需要遵守如下规则：请求参数名与实体类的属性名相同\n简单实体对象\n定义POJO实体类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class User { private String name; private Integer age; public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } } Controller方法：\n1 2 3 4 5 6 7 8 9 @RestController public class RequestController { //实体参数：简单实体对象 @RequestMapping(\u0026#34;/simplePojo\u0026#34;) public String simplePojo(User user){ System.out.println(user); return \u0026#34;OK\u0026#34;; } } Postman测试：\n参数名和实体类属性名一致时 参数名和实体类属性名不一致时 复杂实体对象\n复杂实体对象指的是，在实体类中有一个或多个属性，也是实体对象类型的。如下：\nUser类中有一个Address类型的属性（Address是一个实体类） 复杂实体对象的封装，需要遵守如下规则：\n请求参数名与形参对象属性名相同，按照对象层次结构关系即可接收嵌套实体类属性参数。 定义POJO实体类：\nAddress实体类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class Address { private String province; private String city; public String getProvince() { return province; } public void setProvince(String province) { this.province = province; } public String getCity() { return city; } public void setCity(String city) { this.city = city; } @Override public String toString() { return \u0026#34;Address{\u0026#34; + \u0026#34;province=\u0026#39;\u0026#34; + province + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, city=\u0026#39;\u0026#34; + city + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } User实体类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class User { private String name; private Integer age; private Address address; //地址对象 public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } public Address getAddress() { return address; } public void setAddress(Address address) { this.address = address; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#34;, address=\u0026#34; + address + \u0026#39;}\u0026#39;; } } Controller方法：\n1 2 3 4 5 6 7 8 9 @RestController public class RequestController { //实体参数：复杂实体对象 @RequestMapping(\u0026#34;/complexPojo\u0026#34;) public String complexPojo(User user){ System.out.println(user); return \u0026#34;OK\u0026#34;; } } Postman测试：\n请求响应-请求-数组集合参数 数组\n数组参数：请求参数名与形参数组名称相同且请求参数为多个，定义数组类型形参即可接收参数\nController方法：\n1 2 3 4 5 6 7 8 9 @RestController public class RequestController { //数组集合参数 @RequestMapping(\u0026#34;/arrayParam\u0026#34;) public String arrayParam(String[] hobby){ System.out.println(Arrays.toString(hobby)); return \u0026#34;OK\u0026#34;; } } Postman测试：\n在前端请求时，有两种传递形式：\n方式一： xxxxxxxxxx?hobby=game\u0026amp;hobby=java\n方式二：xxxxxxxxxxxxx?hobby=game,java\n集合\n集合参数：请求参数名与形参集合对象名相同且请求参数为多个，@RequestParam 绑定参数关系\n默认情况下，请求中参数名相同的多个值，是封装到数组。如果要封装到集合，要使用@RequestParam绑定参数关系\nController方法：\n1 2 3 4 5 6 7 8 9 @RestController public class RequestController { //数组集合参数 @RequestMapping(\u0026#34;/listParam\u0026#34;) public String listParam(@RequestParam List\u0026lt;String\u0026gt; hobby){ System.out.println(hobby); return \u0026#34;OK\u0026#34;; } } Postman测试：\n方式一： xxxxxxxxxx?hobby=game\u0026amp;hobby=java\n方式二：xxxxxxxxxxxxx?hobby=game,java\n请求响应-请求-日期参数\u0026amp;json参数 日期参数\n上述演示的都是一些普通的参数，在一些特殊的需求中，可能会涉及到日期类型数据的封装。比如，如下需求：\n因为日期的格式多种多样（如：2022-12-12 10:05:45 、2022/12/12 10:05:45），那么对于日期类型的参数在进行封装的时候，需要通过@DateTimeFormat注解，以及其pattern属性来设置日期的格式。\n@DateTimeFormat注解的pattern属性中指定了哪种日期格式，前端的日期参数就必须按照指定的格式传递。 后端controller方法中，需要使用Date类型或LocalDateTime类型，来封装传递的参数。 Controller方法：\n1 2 3 4 5 6 7 8 9 @RestController public class RequestController { //日期时间参数 @RequestMapping(\u0026#34;/dateParam\u0026#34;) public String dateParam(@DateTimeFormat(pattern = \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;) LocalDateTime updateTime){ System.out.println(updateTime); return \u0026#34;OK\u0026#34;; } } Postman测试：\nJSON参数\n我们学习JSON格式参数，主要从以下两个方面着手：\nPostman在发送请求时，如何传递json格式的请求参数 在服务端的controller方法中，如何接收json格式的请求参数 Postman发送JSON格式数据：\n服务端Controller方法接收JSON格式数据：\n传递json格式的参数，在Controller中会使用实体类进行封装。 封装规则：JSON数据键名与形参对象属性名相同，定义POJO类型形参即可接收参数。需要使用 @RequestBody标识。 @RequestBody注解：将JSON数据映射到形参的实体类对象中（JSON中的key和实体类中的属性名保持一致） 实体类：Address\n1 2 3 4 5 6 public class Address { private String province; private String city; //省略GET , SET 方法 } 实体类：User\n1 2 3 4 5 6 7 public class User { private String name; private Integer age; private Address address; //省略GET , SET 方法 } Controller方法：\n1 2 3 4 5 6 7 8 9 @RestController public class RequestController { //JSON参数 @RequestMapping(\u0026#34;/jsonParam\u0026#34;) public String jsonParam(@RequestBody User user){ System.out.println(user); return \u0026#34;OK\u0026#34;; } } Postman测试：\n请求响应-请求-路径参数 在现在的开发中，经常还会直接在请求的URL中传递参数。例如：\n1 2 http://localhost:8080/user/1 http://localhost:880/user/1/0 上述的这种传递请求参数的形式呢，我们称之为：路径参数。\n学习路径参数呢，主要掌握在后端的controller方法中，如何接收路径参数。\n路径参数：\n前端：通过请求URL直接传递参数， 后端：使用{\u0026hellip;}来标识该路径参数，需要使用@PathVariable获取路径参数 Controller方法：\n1 2 3 4 5 6 7 8 9 @RestController public class RequestController { //路径参数 @RequestMapping(\u0026#34;/path/{id}\u0026#34;) public String pathParam(@PathVariable Integer id){ System.out.println(id); return \u0026#34;OK\u0026#34;; } } Postman测试：\n传递多个路径参数：\nPostman：\nController方法：\n1 2 3 4 5 6 7 8 9 @RestController public class RequestController { //路径参数 @RequestMapping(\u0026#34;/path/{id}/{name}\u0026#34;) public String pathParam2(@PathVariable Integer id, @PathVariable String name){ System.out.println(id+ \u0026#34; : \u0026#34; +name); return \u0026#34;OK\u0026#34;; } } 总结\n请求响应-响应-@ResponseBody\u0026amp;统一响应结果 响应\n前面我们学习过HTTL协议的交互方式：请求响应模式（有请求就有响应）\n那么Controller程序呢，除了接收请求外，还可以进行响应。\n@ResponseBody\n在我们前面所编写的controller方法中，都已经设置了响应数据。\ncontroller方法中的return的结果，怎么就可以响应给浏览器呢？\n答案：使用@ResponseBody注解\n@ResponseBody注解：\n类型：方法注解、类注解 位置：书写在Controller方法上或类上 作用：将方法返回值直接响应给浏览器 如果返回值类型是实体对象/集合，将会转换为JSON格式后在响应给浏览器 但是在我们所书写的Controller中，只在类上添加了@RestController注解、方法添加了@RequestMapping注解，并没有使用@ResponseBody注解，怎么给浏览器响应呢？\n1 2 3 4 5 6 7 8 @RestController public class HelloController { @RequestMapping(\u0026#34;/hello\u0026#34;) public String hello(){ System.out.println(\u0026#34;Hello World ~\u0026#34;); return \u0026#34;Hello World ~\u0026#34;; } } 原因：在类上添加的@RestController注解，是一个组合注解。\n@RestController = @Controller + @ResponseBody @RestController源码：\n1 2 3 4 5 6 7 8 9 10 11 @Target({ElementType.TYPE}) //元注解（修饰注解的注解） @Retention(RetentionPolicy.RUNTIME) //元注解 @Documented //元注解 @Controller @ResponseBody public @interface RestController { @AliasFor( annotation = Controller.class ) String value() default \u0026#34;\u0026#34;; } 结论：在类上添加@RestController就相当于添加了@ResponseBody注解。\n类上有@RestController注解或@ResponseBody注解时：表示当前类下所有的方法返回值做为响应数据 方法的返回值，如果是一个POJO对象或集合时，会先转换为JSON格式，在响应给浏览器 下面我们来测试下响应数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @RestController public class ResponseController { //响应字符串 @RequestMapping(\u0026#34;/hello\u0026#34;) public String hello(){ System.out.println(\u0026#34;Hello World ~\u0026#34;); return \u0026#34;Hello World ~\u0026#34;; } //响应实体对象 @RequestMapping(\u0026#34;/getAddr\u0026#34;) public Address getAddr(){ Address addr = new Address();//创建实体类对象 addr.setProvince(\u0026#34;广东\u0026#34;); addr.setCity(\u0026#34;深圳\u0026#34;); return addr; } //响应集合数据 @RequestMapping(\u0026#34;/listAddr\u0026#34;) public List\u0026lt;Address\u0026gt; listAddr(){ List\u0026lt;Address\u0026gt; list = new ArrayList\u0026lt;\u0026gt;();//集合对象 Address addr = new Address(); addr.setProvince(\u0026#34;广东\u0026#34;); addr.setCity(\u0026#34;深圳\u0026#34;); Address addr2 = new Address(); addr2.setProvince(\u0026#34;陕西\u0026#34;); addr2.setCity(\u0026#34;西安\u0026#34;); list.add(addr); list.add(addr2); return list; } } 在服务端响应了一个对象或者集合，那私前端获取到的数据是什么样子的呢？我们使用postman发送请求来测试下。测试效果如下：\n统一响应结果\n大家有没有发现一个问题，我们在前面所编写的这些Controller方法中，返回值各种各样，没有任何的规范。\n如果我们开发一个大型项目，项目中controller方法将成千上万，使用上述方式将造成整个项目难以维护。那在真实的项目开发中是什么样子的呢？\n在真实的项目开发中，无论是哪种方法，我们都会定义一个统一的返回结果。方案如下：\n前端：只需要按照统一格式的返回结果进行解析(仅一种解析方案)，就可以拿到数据。\n统一的返回结果使用类来描述，在这个结果中包含：\n响应状态码：当前请求是成功，还是失败 状态码信息：给页面的提示信息 返回的数据：给前端响应的数据（字符串、对象、集合） 定义在一个实体类Result来包含以上信息。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 public class Result { private Integer code;//响应码，1 代表成功; 0 代表失败 private String msg; //响应码 描述字符串 private Object data; //返回的数据 public Result() { } public Result(Integer code, String msg, Object data) { this.code = code; this.msg = msg; this.data = data; } public Integer getCode() { return code; } public void setCode(Integer code) { this.code = code; } public String getMsg() { return msg; } public void setMsg(String msg) { this.msg = msg; } public Object getData() { return data; } public void setData(Object data) { this.data = data; } //增删改 成功响应(不需要给前端返回数据) public static Result success(){ return new Result(1,\u0026#34;success\u0026#34;,null); } //查询 成功响应(把查询结果做为返回数据响应给前端) public static Result success(Object data){ return new Result(1,\u0026#34;success\u0026#34;,data); } //失败响应 public static Result error(String msg){ return new Result(0,msg,null); } } 改造Controller：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @RestController public class ResponseController { //响应统一格式的结果 @RequestMapping(\u0026#34;/hello\u0026#34;) public Result hello(){ System.out.println(\u0026#34;Hello World ~\u0026#34;); //return new Result(1,\u0026#34;success\u0026#34;,\u0026#34;Hello World ~\u0026#34;); return Result.success(\u0026#34;Hello World ~\u0026#34;); } //响应统一格式的结果 @RequestMapping(\u0026#34;/getAddr\u0026#34;) public Result getAddr(){ Address addr = new Address(); addr.setProvince(\u0026#34;广东\u0026#34;); addr.setCity(\u0026#34;深圳\u0026#34;); return Result.success(addr); } //响应统一格式的结果 @RequestMapping(\u0026#34;/listAddr\u0026#34;) public Result listAddr(){ List\u0026lt;Address\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); Address addr = new Address(); addr.setProvince(\u0026#34;广东\u0026#34;); addr.setCity(\u0026#34;深圳\u0026#34;); Address addr2 = new Address(); addr2.setProvince(\u0026#34;陕西\u0026#34;); addr2.setCity(\u0026#34;西安\u0026#34;); list.add(addr); list.add(addr2); return Result.success(list); } } 使用Postman测试：\n请求响应-响应-案例 案例 获取员工数据，返回统一响应结果，在页面渲染展示\n加载并解析emp.xml文件中的数据，完成数据处理，并在页面展示。 获取员工数据，返回统一响应结果，在页面渲染展示 步骤 获取员工数据，返回统一响应结果，在页面渲染展示\n在pom.xml文件中引入dom4j的依赖，用于解析XML文件 引入资料中提供的解析XML的工具类XMLParserUtils、对应的实体类Emp、XML文件 emp.xml 引入资料中提供的静态页面文件，放在resources下的static目录下 编写Controller程序，处理请求，响应数据 实现步骤\n\\1. 在pom.xml文件中引入dom4j的依赖，用于解析XML文件\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dom4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dom4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \\2. 引入资料中提供的：解析XML的工具类XMLParserUtils、实体类Emp、XML文件emp.xml\n\\3. 引入资料中提供的静态页面文件，放在resources下的static目录下\n\\4. 创建EmpController类，编写Controller程序，处理请求，响应数据\n代码实现\nContriller代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @RestController public class EmpController { @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result list(){ //1. 加载并解析emp.xml String file = this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); //System.out.println(file); List\u0026lt;Emp\u0026gt; empList = XmlParserUtils.parse(file, Emp.class); //2. 对数据进行转换处理 - gender, job empList.stream().forEach(emp -\u0026gt; { //处理 gender 1: 男, 2: 女 String gender = emp.getGender(); if(\u0026#34;1\u0026#34;.equals(gender)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(\u0026#34;2\u0026#34;.equals(gender)){ emp.setGender(\u0026#34;女\u0026#34;); } //处理job - 1: 讲师, 2: 班主任 , 3: 就业指导 String job = emp.getJob(); if(\u0026#34;1\u0026#34;.equals(job)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(\u0026#34;2\u0026#34;.equals(job)){ emp.setJob(\u0026#34;班主任\u0026#34;); }else if(\u0026#34;3\u0026#34;.equals(job)){ emp.setJob(\u0026#34;就业指导\u0026#34;); } }); //3. 响应数据 return Result.success(empList); } } 统一返回结果实体类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 public class Result { private Integer code ;//1 成功 , 0 失败 private String msg; //提示信息 private Object data; //数据 date public Result() { } public Result(Integer code, String msg, Object data) { this.code = code; this.msg = msg; this.data = data; } public Integer getCode() { return code; } public void setCode(Integer code) { this.code = code; } public String getMsg() { return msg; } public void setMsg(String msg) { this.msg = msg; } public Object getData() { return data; } public void setData(Object data) { this.data = data; } public static Result success(Object data){ return new Result(1, \u0026#34;success\u0026#34;, data); } public static Result success(){ return new Result(1, \u0026#34;success\u0026#34;, null); } public static Result error(String msg){ return new Result(0, msg, null); } } 测试\n代码编写完毕之后，我们就可以运行引导类，启动服务进行测试了。\n使用Postman测试：\n打开浏览器，在浏览器地址栏输入： http://localhost:8080/emp.html\n问题分析\n上述案例的功能，我们虽然已经实现，但是呢，我们会发现案例中：解析XML数据，获取数据的代码，处理数据的逻辑的代码，给页面响应的代码全部都堆积在一起了，全部都写在controller方法中了。\n当前程序的这个业务逻辑还是比较简单的，如果业务逻辑再稍微复杂一点，我们会看到Controller方法的代码量就很大了。\n当我们要修改操作数据部分的代码，需要改动Controller 当我们要完善逻辑处理部分的代码，需要改动Controller 当我们需要修改数据响应的代码，还是需要改动Controller 这样呢，就会造成我们整个工程代码的复用性比较差，而且代码难以维护。 那如何解决这个问题呢？其实在现在的开发中，有非常成熟的解决思路，那就是分层开发。\n分层解耦-三层架构 三层架构\n在我们进行程序设计以及程序开发时，尽可能让每一个接口、类、方法的职责更单一些（单一职责原则）。\n单一职责原则：一个类或一个方法，就只做一件事情，只管一块功能。\n这样就可以让类、接口、方法的复杂度更低，可读性更强，扩展性更好，也更利用后期的维护。\n我们之前开发的程序呢，并不满足单一职责原则。下面我们来分析下之前的程序：\n那其实我们上述案例的处理逻辑呢，从组成上看可以分为三个部分：\n数据访问：负责业务数据的维护操作，包括增、删、改、查等操作。 逻辑处理：负责业务逻辑处理的代码。 请求处理、响应数据：负责，接收页面的请求，给页面响应数据。 按照上述的三个组成部分，在我们项目开发中呢，可以将代码分为三层：\nController：控制层。接收前端发送的请求，对请求进行处理，并响应数据。 Service：业务逻辑层。处理具体的业务逻辑。 Dao：数据访问层(Data Access Object)，也称为持久层。负责数据访问操作，包括数据的增、删、改、查。 基于三层架构的程序执行流程：\n前端发起的请求，由Controller层接收（Controller响应数据给前端） Controller层调用Service层来进行逻辑处理（Service层处理完后，把处理结果返回给Controller层） Serivce层调用Dao层（逻辑处理过程中需要用到的一些数据要从Dao层获取） Dao层操作文件中的数据（Dao拿到的数据会返回给Service层） 思考：按照三层架构的思想，如何要对业务逻辑(Service层)进行变更，会影响到Controller层和Dao层吗？\n答案：不会影响。 （程序的扩展性、维护性变得更好了）\n代码拆分\n我们使用三层架构思想，来改造下之前的程序：\n控制层包名：xxxx.controller 业务逻辑层包名：xxxx.service 数据访问层包名：xxxx.dao **控制层：**接收前端发送的请求，对请求进行处理，并响应数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @RestController public class EmpController { //业务层对象 private EmpService empService = new EmpServiceA(); @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result list(){ //1. 调用service层, 获取数据 List\u0026lt;Emp\u0026gt; empList = empService.listEmp(); //3. 响应数据 return Result.success(empList); } } **业务逻辑层：**处理具体的业务逻辑\n业务接口 1 2 3 4 5 //业务逻辑接口（制定业务标准） public interface EmpService { //获取员工列表 public List\u0026lt;Emp\u0026gt; listEmp(); } 业务实现类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 //业务逻辑实现类（按照业务标准实现） public class EmpServiceA implements EmpService { //dao层对象 private EmpDao empDao = new EmpDaoA(); @Override public List\u0026lt;Emp\u0026gt; listEmp() { //1. 调用dao, 获取数据 List\u0026lt;Emp\u0026gt; empList = empDao.listEmp(); //2. 对数据进行转换处理 - gender, job empList.stream().forEach(emp -\u0026gt; { //处理 gender 1: 男, 2: 女 String gender = emp.getGender(); if(\u0026#34;1\u0026#34;.equals(gender)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(\u0026#34;2\u0026#34;.equals(gender)){ emp.setGender(\u0026#34;女\u0026#34;); } //处理job - 1: 讲师, 2: 班主任 , 3: 就业指导 String job = emp.getJob(); if(\u0026#34;1\u0026#34;.equals(job)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(\u0026#34;2\u0026#34;.equals(job)){ emp.setJob(\u0026#34;班主任\u0026#34;); }else if(\u0026#34;3\u0026#34;.equals(job)){ emp.setJob(\u0026#34;就业指导\u0026#34;); } }); return empList; } } **数据访问层：**负责数据的访问操作，包含数据的增、删、改、查\n数据访问接口 1 2 3 4 5 //数据访问层接口（制定标准） public interface EmpDao { //获取员工列表数据 public List\u0026lt;Emp\u0026gt; listEmp(); } 数据访问实现类 1 2 3 4 5 6 7 8 9 10 11 //数据访问实现类 public class EmpDaoA implements EmpDao { @Override public List\u0026lt;Emp\u0026gt; listEmp() { //1. 加载并解析emp.xml String file = this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; empList = XmlParserUtils.parse(file, Emp.class); return empList; } } 三层架构的好处：\n复用性强 便于维护 利用扩展 分层解耦=分层解耦（IOC-DI引入） 分层解耦\n内聚：软件中各个功能模块内部的功能联系。 耦合：衡量软件中各个层/模块之间的依赖、关联的程度。 软件设计原则：高内聚低耦合。\n高内聚指的是：一个模块中各个元素之间的联系的紧密程度，如果各个元素(语句、程序段)之间的联系程度越高，则内聚性越高，即 \u0026ldquo;高内聚\u0026rdquo;。\n低耦合指的是：软件中各个层、模块之间的依赖关联程序越低越好。\n程序中高内聚的体现：\nEmpServiceA类中只编写了和员工相关的逻辑处理代码 程序中耦合代码的体现：\n把业务类变为EmpServiceB时，需要修改controller层中的代码 高内聚、低耦合的目的是使程序模块的可重用性、移植性大大增强。\n解耦思路\n之前我们在编写代码时，需要什么对象，就直接new一个就可以了。 这种做法呢，层与层之间代码就耦合了，当service层的实现变了之后， 我们还需要修改controller层的代码。\n那应该怎么解耦呢？\n首先不能在EmpController中使用new对象。代码如下： 此时，就存在另一个问题了，不能new，就意味着没有业务层对象（程序运行就报错），怎么办呢？ 我们的解决思路是： 提供一个容器，容器中存储一些对象(例：EmpService对象) controller程序从容器中获取EmpService类型的对象 我们想要实现上述解耦操作，就涉及到Spring中的两个核心概念：\n控制反转： Inversion Of Control，简称IOC。对象的创建控制权由程序自身转移到外部（容器），这种思想称为控制反转。\n对象的创建权由程序员主动创建转移到容器(由容器创建、管理对象)。这个容器称为：IOC容器或Spring容器\n依赖注入： Dependency Injection，简称DI。容器为应用程序提供运行时，所依赖的资源，称之为依赖注入。\n程序运行时需要某个资源，此时容器就为其提供这个资源。\n例：EmpController程序运行时需要EmpService对象，Spring容器就为其提供并注入EmpService对象\nIOC容器中创建、管理的对象，称之为：bean对象\n分层解耦-IOC\u0026amp;DI-入门 IOC\u0026amp;DI入门\n任务：完成Controller层、Service层、Dao层的代码解耦\n思路：\n删除Controller层、Service层中new对象的代码\nService层及Dao层的实现类，交给IOC容器管理\n为Controller及Service注入运行时依赖的对象\nController程序中注入依赖的Service层对象 Service程序中注入依赖的Dao层对象 第1步：删除Controller层、Service层中new对象的代码\n第2步：Service层及Dao层的实现类，交给IOC容器管理\n使用Spring提供的注解：@Component ，就可以实现类交给IOC容器管理 第3步：为Controller及Service注入运行时依赖的对象\n使用Spring提供的注解：@Autowired ，就可以实现程序运行时IOC容器自动注入需要的依赖对象 完整的三层代码：\nController层： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @RestController public class EmpController { @Autowired //运行时,从IOC容器中获取该类型对象,赋值给该变量 private EmpService empService ; @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result list(){ //1. 调用service, 获取数据 List\u0026lt;Emp\u0026gt; empList = empService.listEmp(); //3. 响应数据 return Result.success(empList); } } Service层： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @Component //将当前对象交给IOC容器管理,成为IOC容器的bean public class EmpServiceA implements EmpService { @Autowired //运行时,从IOC容器中获取该类型对象,赋值给该变量 private EmpDao empDao ; @Override public List\u0026lt;Emp\u0026gt; listEmp() { //1. 调用dao, 获取数据 List\u0026lt;Emp\u0026gt; empList = empDao.listEmp(); //2. 对数据进行转换处理 - gender, job empList.stream().forEach(emp -\u0026gt; { //处理 gender 1: 男, 2: 女 String gender = emp.getGender(); if(\u0026#34;1\u0026#34;.equals(gender)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(\u0026#34;2\u0026#34;.equals(gender)){ emp.setGender(\u0026#34;女\u0026#34;); } //处理job - 1: 讲师, 2: 班主任 , 3: 就业指导 String job = emp.getJob(); if(\u0026#34;1\u0026#34;.equals(job)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(\u0026#34;2\u0026#34;.equals(job)){ emp.setJob(\u0026#34;班主任\u0026#34;); }else if(\u0026#34;3\u0026#34;.equals(job)){ emp.setJob(\u0026#34;就业指导\u0026#34;); } }); return empList; } } Dao层： 1 2 3 4 5 6 7 8 9 10 11 @Component //将当前对象交给IOC容器管理,成为IOC容器的bean public class EmpDaoA implements EmpDao { @Override public List\u0026lt;Emp\u0026gt; listEmp() { //1. 加载并解析emp.xml String file = this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; empList = XmlParserUtils.parse(file, Emp.class); return empList; } } 运行测试：\n启动SpringBoot引导类，打开浏览器，输入：http://localhost:8080/emp.html 分层解耦-IOC\u0026amp;DI-IOC详解 bean的声明\n前面我们提到IOC控制反转，就是将对象的控制权交给Spring的IOC容器，由IOC容器创建及管理对象。IOC容器创建的对象称为bean对象。\n在之前的入门案例中，要把某个对象交给IOC容器管理，需要在类上添加一个注解：@Component\n而Spring框架为了更好的标识web应用程序开发当中，bean对象到底归属于哪一层，又提供了@Component的衍生注解：\n@Controller （标注在控制层类上） @Service （标注在业务层类上） @Repository （标注在数据访问层类上） 修改入门案例代码：\n*Controller层：* 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @RestController //@RestController = @Controller + @ResponseBody public class EmpController { @Autowired //运行时,从IOC容器中获取该类型对象,赋值给该变量 private EmpService empService ; @RequestMapping(\u0026#34;/listEmp\u0026#34;) public Result list(){ //1. 调用service, 获取数据 List\u0026lt;Emp\u0026gt; empList = empService.listEmp(); //3. 响应数据 return Result.success(empList); } } Service层： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @Service public class EmpServiceA implements EmpService { @Autowired //运行时,从IOC容器中获取该类型对象,赋值给该变量 private EmpDao empDao ; @Override public List\u0026lt;Emp\u0026gt; listEmp() { //1. 调用dao, 获取数据 List\u0026lt;Emp\u0026gt; empList = empDao.listEmp(); //2. 对数据进行转换处理 - gender, job empList.stream().forEach(emp -\u0026gt; { //处理 gender 1: 男, 2: 女 String gender = emp.getGender(); if(\u0026#34;1\u0026#34;.equals(gender)){ emp.setGender(\u0026#34;男\u0026#34;); }else if(\u0026#34;2\u0026#34;.equals(gender)){ emp.setGender(\u0026#34;女\u0026#34;); } //处理job - 1: 讲师, 2: 班主任 , 3: 就业指导 String job = emp.getJob(); if(\u0026#34;1\u0026#34;.equals(job)){ emp.setJob(\u0026#34;讲师\u0026#34;); }else if(\u0026#34;2\u0026#34;.equals(job)){ emp.setJob(\u0026#34;班主任\u0026#34;); }else if(\u0026#34;3\u0026#34;.equals(job)){ emp.setJob(\u0026#34;就业指导\u0026#34;); } }); return empList; } } Dao层： 1 2 3 4 5 6 7 8 9 10 11 @Repository public class EmpDaoA implements EmpDao { @Override public List\u0026lt;Emp\u0026gt; listEmp() { //1. 加载并解析emp.xml String file = this.getClass().getClassLoader().getResource(\u0026#34;emp.xml\u0026#34;).getFile(); System.out.println(file); List\u0026lt;Emp\u0026gt; empList = XmlParserUtils.parse(file, Emp.class); return empList; } } 要把某个对象交给IOC容器管理，需要在对应的类上加上如下注解之一：\n注解 说明 位置 @Controller @Component的衍生注解 标注在控制器类上 @Service @Component的衍生注解 标注在业务类上 @Repository @Component的衍生注解 标注在数据访问类上（由于与mybatis整合，用的少） @Component 声明bean的基础注解 不属于以上三类时，用此注解 查看源码\n在IOC容器中，每一个Bean都有一个属于自己的名字，可以通过注解的value属性指定bean的名字。如果没有指定，默认为类名首字母小写。\n注意事项:\n声明bean的时候，可以通过value属性指定bean的名字，如果没有指定，默认为类名首字母小写。\n使用以上四个注解都可以声明bean，但是在springboot集成web开发中，声明控制器bean只能用@Controller。\n组件扫描\n问题：使用前面学习的四个注解声明的bean，一定会生效吗？\n答案：不一定。（原因：bean想要生效，还需要被组件扫描）\n下面我们通过修改项目工程的目录结构，来测试bean对象是否生效：\n运行程序后，报错：\n为什么没有找到bean对象呢？\n使用四大注解声明的bean，要想生效，还需要被组件扫描注解@ComponentScan扫描 解决方案：手动添加@ComponentScan注解，指定要扫描的包 （==仅做了解，不推荐==）\n推荐做法（如下图）：\n将我们定义的controller，service，dao这些包呢，都放在引导类所在包com.itheima的子包下，这样我们定义的bean就会被自动的扫描到 分****层解耦-IOC\u0026amp;DI-DI详解 依赖注入，是指IOC容器要为应用程序去提供运行时所依赖的资源，而资源指的就是对象。\n在入门程序案例中，我们使用了@Autowired这个注解，完成了依赖注入的操作，而这个Autowired翻译过来叫：自动装配。\n@Autowired注解，默认是按照类型进行自动装配的（去IOC容器中找某个类型的对象，然后完成注入操作）\n入门程序举例：在EmpController运行的时候，就要到IOC容器当中去查找EmpService这个类型的对象，而我们的IOC容器中刚好有一个EmpService这个类型的对象，所以就找到了这个类型的对象完成注入操作。\n那如果在IOC容器中，存在多个相同类型的bean对象，会出现什么情况呢？\n程序运行会报错\n如何解决上述问题呢？Spring提供了以下几种解决方案：\n@Primary @Qualifier @Resource 使用@Primary注解：当存在多个相同类型的Bean注入时，加上@Primary注解，来确定默认的实现。\n使用@Qualifier注解：指定当前要注入的bean对象。 在@Qualifier的value属性中，指定注入的bean的名称。\n@Qualifier注解不能单独使用，必须配合@Autowired使用 使用@Resource注解：是按照bean的名称进行注入。通过name属性指定要注入的bean的名称。\n面试题 ： @Autowird 与 @Resource的区别\n@Autowired 是spring框架提供的注解，而@Resource是JDK提供的注解\n@Autowired 默认是按照类型注入，而@Resource是按照名称注入\n","date":"2025-04-13T16:01:23+08:00","image":"https://nova-bryan.github.io/p/%E8%AF%B7%E6%B1%82%E5%93%8D%E5%BA%94%E5%88%86%E5%B1%82%E8%A7%A3%E8%80%A6/image_hu17089168107649188491.png","permalink":"https://nova-bryan.github.io/p/%E8%AF%B7%E6%B1%82%E5%93%8D%E5%BA%94%E5%88%86%E5%B1%82%E8%A7%A3%E8%80%A6/","title":"请求响应,分层解耦"},{"content":"事务回顾 在数据库阶段我们已学习过事务了，我们讲到：\n事务是一组操作的集合，它是一个不可分割的工作单位。事务会把所有的操作作为一个整体，一起向数据库提交或者是撤销操作请求。所以这组操作要么同时成功，要么同时失败。\n怎么样来控制这组操作，让这组操作同时成功或同时失败呢？此时就要涉及到事务的具体操作了。\n事务的操作主要有三步：\n开启事务（一组操作开始前，开启事务）：start transaction / begin ; 提交事务（这组操作全部成功后，提交事务）：commit ; 回滚事务（中间任何一个操作出现异常，回滚事务）：rollback ; Spring事务管理-案例 简单的回顾了事务的概念以及事务的基本操作之后，接下来我们看一个事务管理案例：解散部门 （解散部门就是删除部门）\n需求：当部门解散了不仅需要把部门信息删除了，还需要把该部门下的员工数据也删除了。\n步骤：\n根据ID删除部门数据 根据部门ID删除该部门下的员工 代码实现：\n1.DeptServiceImpl\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Slf4j @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; @Autowired private EmpMapper empMapper; //根据部门id，删除部门信息及部门下的所有员工 @Override public void delete(Integer id){ //根据部门id删除部门信息 deptMapper.deleteById(id); //删除部门下的所有员工信息 empMapper.deleteByDeptId(id); } } 2.DeptMapper\n1 2 3 4 5 6 7 8 9 @Mapper public interface DeptMapper { /** * 根据id删除部门信息 * @param id 部门id */ @Delete(\u0026#34;delete from dept where id = #{id}\u0026#34;) void deleteById(Integer id); } 3.EmpMapper\n1 2 3 4 5 6 7 8 @Mapper public interface EmpMapper { //根据部门id删除部门下所有员工 @Delete(\u0026#34;delete from emp where dept_id=#{deptId}\u0026#34;) public int deleteByDeptId(Integer deptId); } 重启SpringBoot服务，使用postman测试部门删除：\n代码正常情况下，dept表和Emp表中的数据已删除\n修改DeptServiceImpl类中代码，添加可能出现异常的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Slf4j @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; @Autowired private EmpMapper empMapper; //根据部门id，删除部门信息及部门下的所有员工 @Override public void delete(Integer id){ //根据部门id删除部门信息 deptMapper.deleteById(id); //模拟：异常发生 int i = 1/0; //删除部门下的所有员工信息 empMapper.deleteByDeptId(id); } } 重启SpringBoot服务，使用postman测试部门删除：\n查看数据库表：\n删除了2号部门 2号部门下的员工数据没有删除 以上程序出现的问题：即使程序运行抛出了异常，部门依然删除了，但是部门下的员工却没有删除，造成了数据的不一致。\n原因分析 原因：\n先执行根据id删除部门的操作，这步执行完毕，数据库表 dept 中的数据就已经删除了。 执行 1/0 操作，抛出异常 抛出异常之前，下面所有的代码都不会执行了，根据部门ID删除该部门下的员工，这个操作也不会执行 。 此时就出现问题了，部门删除了，部门下的员工还在，业务操作前后数据不一致。\n而要想保证操作前后，数据的一致性，就需要让解散部门中涉及到的两个业务操作，要么全部成功，要么全部失败 。 那我们如何，让这两个操作要么全部成功，要么全部失败呢 ？\n那就可以通过事务来实现，因为一个事务中的多个业务操作，要么全部成功，要么全部失败。\n此时，我们就需要在delete删除业务功能中添加事务。\n在方法运行之前，开启事务，如果方法成功执行，就提交事务，如果方法执行的过程当中出现异常了，就回滚事务。\n思考：开发中所有的业务操作，一旦我们要进行控制事务，是不是都是这样的套路？\n答案：是的。\n所以在spring框架当中就已经把事务控制的代码都已经封装好了，并不需要我们手动实现。我们使用了spring框架，我们只需要通过一个简单的注解@Transactional就搞定了。\nTransactionla注解 @Transactional作用：就是在当前这个方法执行开始之前来开启事务，方法执行完毕之后提交事务。如果在这个方法执行的过程当中出现了异常，就会进行事务的回滚操作。\n@Transactional注解：我们一般会在业务层当中来控制事务，因为在业务层当中，一个业务功能可能会包含多个数据访问的操作。在业务层来控制事务，我们就可以将多个数据访问操作控制在一个事务范围内。\n@Transactional注解书写位置：\n方法 当前方法交给spring进行事务管理 类 当前类中所有的方法都交由spring进行事务管理 接口 接口下所有的实现类当中所有的方法都交给spring 进行事务管理 接下来，我们就可以在业务方法delete上加上 @Transactional 来控制事务 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Slf4j @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; @Autowired private EmpMapper empMapper; @Override @Transactional //当前方法添加了事务管理 public void delete(Integer id){ //根据部门id删除部门信息 deptMapper.deleteById(id); //模拟：异常发生 int i = 1/0; //删除部门下的所有员工信息 empMapper.deleteByDeptId(id); } } 在业务功能上添加@Transactional注解进行事务管理后，我们重启SpringBoot服务，使用postman测试：\n添加Spring事务管理后，由于服务端程序引发了异常，所以事务进行回滚。\n说明：可以在application.yml配置文件中开启事务管理日志，这样就可以在控制看到和事务相关的日志信息了\n1 2 3 4 #spring事务管理日志 logging: level: org.springframework.jdbc.support.JdbcTransactionManager: debug 事务管理-事务进阶-rollbackFor属性 前面我们通过spring事务管理注解@Transactional已经控制了业务层方法的事务。接下来我们要来详细的介绍一下@Transactional事务管理注解的使用细节。我们这里主要介绍@Transactional注解当中的两个常见的属性：\n异常回滚的属性：rollbackFor 事务传播行为：propagation 我们先来学习下rollbackFor属性。\n我们在之前编写的业务方法上添加了@Transactional注解，来实现事务管理。\n1 2 3 4 5 6 7 8 9 10 11 @Transactional public void delete(Integer id){ //根据部门id删除部门信息 deptMapper.deleteById(id); //模拟：异常发生 int i = 1/0; //删除部门下的所有员工信息 empMapper.deleteByDeptId(id); } 以上业务功能delete()方法在运行时，会引发除0的算数运算异常(运行时异常)，出现异常之后，由于我们在方法上加了@Transactional注解进行事务管理，所以发生异常会执行rollback回滚操作，从而保证事务操作前后数据是一致的。\n下面我们在做一个测试，我们修改业务功能代码，在模拟异常的位置上直接抛出Exception异常（编译时异常）\n1 2 3 4 5 6 7 8 9 10 11 12 13 @Transactional public void delete(Integer id) throws Exception { //根据部门id删除部门信息 deptMapper.deleteById(id); //模拟：异常发生 if(true){ throw new Exception(\u0026#34;出现异常了~~~\u0026#34;); } //删除部门下的所有员工信息 empMapper.deleteByDeptId(id); } 说明：在service中向上抛出一个Exception编译时异常之后，由于是controller调用service，所以在controller中要有异常处理代码，此时我们选择在controller中继续把异常向上抛。\n1 2 3 4 5 6 7 8 9 @DeleteMapping(\u0026#34;/depts/{id}\u0026#34;) public Result delete(@PathVariable Integer id) throws Exception { //日志记录 log.info(\u0026#34;根据id删除部门\u0026#34;); //调用service层功能 deptService.delete(id); //响应 return Result.success(); } 重新启动服务后测试：\n抛出异常之后事务会不会回滚\n现有表中数据：\n使用postman测试，删除5号部门\n发生了Exception异常，但事务依然提交了\ndept表中数据：\n通过以上测试可以得出一个结论：默认情况下，只有出现RuntimeException(运行时异常)才会回滚事务。\n假如我们想让所有的异常都回滚，需要来配置@Transactional注解当中的rollbackFor属性，通过rollbackFor这个属性可以指定出现何种异常类型回滚事务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Slf4j @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; @Autowired private EmpMapper empMapper; @Override @Transactional(rollbackFor=Exception.class) public void delete(Integer id){ //根据部门id删除部门信息 deptMapper.deleteById(id); //模拟：异常发生 int num = id/0; //删除部门下的所有员工信息 empMapper.deleteByDeptId(id); } } 接下来我们重新启动服务，测试删除部门的操作：\n控制台日志：执行了删除3号部门的操作， 因为异常又进行了事务回滚\n数据表：3号部门没有删除\n结论：\n在Spring的事务管理中，默认只有运行时异常 RuntimeException才会回滚。 如果还需要回滚指定类型的异常，可以通过rollbackFor属性来指定。 事务管理-事务进阶-propagation属性 介绍 我们接着继续学习@Transactional注解当中的第二个属性propagation，这个属性是用来配置事务的传播行为的。\n什么是事务的传播行为呢？\n就是当一个事务方法被另一个事务方法调用时，这个事务方法应该如何进行事务控制。 例如：两个事务方法，一个A方法，一个B方法。在这两个方法上都添加了@Transactional注解，就代表这两个方法都具有事务，而在A方法当中又去调用了B方法。\n所谓事务的传播行为，指的就是在A方法运行的时候，首先会开启一个事务，在A方法当中又调用了B方法， B方法自身也具有事务，那么B方法在运行的时候，到底是加入到A方法的事务当中来，还是B方法在运行的时候新建一个事务？这个就涉及到了事务的传播行为。\n我们要想控制事务的传播行为，在@Transactional注解的后面指定一个属性propagation，通过 propagation 属性来指定传播行为。接下来我们就来介绍一下常见的事务传播行为。\n属性值 含义 REQUIRED 【默认值】需要事务，有则加入，无则创建新事务 REQUIRES_NEW 需要新事务，无论有无，总是创建新事务 SUPPORTS 支持事务，有则加入，无则在无事务状态中运行 NOT_SUPPORTED 不支持事务，在无事务状态下运行,如果当前存在已有事务,则挂起当前事务 MANDATORY 必须有事务，否则抛异常 NEVER 必须没事务，否则抛异常 对于这些事务传播行为，我们只需要关注以下两个就可以了：\nREQUIRED（默认值） REQUIRES_NEW 案例 **需求：**解散部门时需要记录操作日志\n由于解散部门是一个非常重要而且非常危险的操作，所以在业务当中要求每一次执行解散部门的操作都需要留下痕迹，就是要记录操作日志。而且还要求无论是执行成功了还是执行失败了，都需要留下痕迹。\n步骤：\n执行解散部门的业务：先删除部门，再删除部门下的员工（前面已实现） 记录解散部门的日志，到日志表（未实现） 准备工作：\n创建数据库表 dept_log 日志表： 1 2 3 4 5 create table dept_log( id int auto_increment comment \u0026#39;主键ID\u0026#39; primary key, create_time datetime null comment \u0026#39;操作时间\u0026#39;, description varchar(300) null comment \u0026#39;操作描述\u0026#39; )comment \u0026#39;部门操作日志表\u0026#39;; 2. 引入资料中提供的实体类：DeptLog\n1 2 3 4 5 6 7 8 @Data @NoArgsConstructor @AllArgsConstructor public class DeptLog { private Integer id; private LocalDateTime createTime; private String description; } 3. 引入资料中提供的Mapper接口：DeptLogMapper\n1 2 3 4 5 6 7 @Mapper public interface DeptLogMapper { @Insert(\u0026#34;insert into dept_log(create_time,description) values(#{createTime},#{description})\u0026#34;) void insert(DeptLog log); } 4. 引入资料中提供的业务接口：DeptLogService\n1 2 3 public interface DeptLogService { void insert(DeptLog deptLog); } 5. 引入资料中提供的业务实现类：DeptLogServiceImpl\n1 2 3 4 5 6 7 8 9 10 11 12 @Service public class DeptLogServiceImpl implements DeptLogService { @Autowired private DeptLogMapper deptLogMapper; @Transactional //事务传播行为：有事务就加入、没有事务就新建事务 @Override public void insert(DeptLog deptLog) { deptLogMapper.insert(deptLog); } } 代码实现:\n业务实现类：DeptServiceImpl\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Slf4j @Service //@Transactional //当前业务实现类中的所有的方法，都添加了spring事务管理机制 public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; @Autowired private EmpMapper empMapper; @Autowired private DeptLogService deptLogService; //根据部门id，删除部门信息及部门下的所有员工 @Override @Log @Transactional(rollbackFor = Exception.class) public void delete(Integer id) throws Exception { try { //根据部门id删除部门信息 deptMapper.deleteById(id); //模拟：异常 if(true){ throw new Exception(\u0026#34;出现异常了~~~\u0026#34;); } //删除部门下的所有员工信息 empMapper.deleteByDeptId(id); }finally { //不论是否有异常，最终都要执行的代码：记录日志 DeptLog deptLog = new DeptLog(); deptLog.setCreateTime(LocalDateTime.now()); deptLog.setDescription(\u0026#34;执行了解散部门的操作，此时解散的是\u0026#34;+id+\u0026#34;号部门\u0026#34;); //调用其他业务类中的方法 deptLogService.insert(deptLog); } } //省略其他代码... } 测试:\n重新启动SpringBoot服务，测试删除3号部门后会发生什么？\n执行了删除3号部门操作 执行了插入部门日志操作 程序发生Exception异常 执行事务回滚（删除、插入操作因为在一个事务范围内，两个操作都会被回滚） 然后在dept_log表中没有记录日志数据\n原因分析:\n接下来我们就需要来分析一下具体是什么原因导致的日志没有成功的记录。\n在执行delete操作时开启了一个事务 当执行insert操作时，insert设置的事务传播行是默认值REQUIRED，表示有事务就加入，没有则新建事务 此时：delete和insert操作使用了同一个事务，同一个事务中的多个操作，要么同时成功，要么同时失败，所以当异常发生时进行事务回滚，就会回滚delete和insert操作 解决方案：\n在DeptLogServiceImpl类中insert方法上，添加@Transactional(propagation = Propagation.REQUIRES_NEW)\nPropagation.REQUIRES_NEW ：不论是否有事务，都创建新事务 ，运行在一个独立的事务中。\n1 2 3 4 5 6 7 8 9 10 11 12 @Service public class DeptLogServiceImpl implements DeptLogService { @Autowired private DeptLogMapper deptLogMapper; @Transactional(propagation = Propagation.REQUIRES_NEW)//事务传播行为：不论是否有事务，都新建事务 @Override public void insert(DeptLog deptLog) { deptLogMapper.insert(deptLog); } } 重启SpringBoot服务，再次测试删除3号部门：\n那此时，DeptServiceImpl中的delete方法运行时，会开启一个事务。 当调用 deptLogService.insert(deptLog) 时，也会创建一个新的事务，那此时，当insert方法运行完毕之后，事务就已经提交了。 即使外部的事务出现异常，内部已经提交的事务，也不会回滚了，因为是两个独立的事务。\n到此事务传播行为已演示完成，事务的传播行为我们只需要掌握两个：REQUIRED、REQUIRES_NEW。\nREQUIRED ：大部分情况下都是用该传播行为即可。 REQUIRES_NEW ：当我们不希望事务之间相互影响时，可以使用该传播行为。比如：下订单前需要记录日志，不论订单保存成功与否，都需要保证日志记录能够记录成功。 AOP基础-快速入门 AOP概述 什么是AOP？\nAOP英文全称：Aspect Oriented Programming（面向切面编程、面向方面编程），其实说白了，面向切面编程就是面向特定方法编程。 那什么又是面向方法编程呢，为什么又需要面向方法编程呢？来我们举个例子做一个说明：\n比如，我们这里有一个项目，项目中开发了很多的业务功能。\n然而有一些业务功能执行效率比较低，执行耗时较长，我们需要针对于这些业务方法进行优化。 那首先第一步就需要定位出执行耗时比较长的业务方法，再针对于业务方法再来进行优化。\n此时我们就需要统计当前这个项目当中每一个业务方法的执行耗时。那么统计每一个业务方法的执行耗时该怎么实现？\n可能多数人首先想到的就是在每一个业务方法运行之前，记录这个方法运行的开始时间。在这个方法运行完毕之后，再来记录这个方法运行的结束时间。拿结束时间减去开始时间，不就是这个方法的执行耗时吗？\n以上分析的实现方式是可以解决需求问题的。但是对于一个项目来讲，里面会包含很多的业务模块，每个业务模块又包含很多增删改查的方法，如果我们要在每一个模块下的业务方法中，添加记录开始时间、结束时间、计算执行耗时的代码，就会让程序员的工作变得非常繁琐。\n而AOP面向方法编程，就可以做到在不改动这些原始方法的基础上，针对特定的方法进行功能的增强。\nAOP的作用：在程序运行期间在不修改源代码的基础上对已有方法进行增强（无侵入性: 解耦）\n我们要想完成统计各个业务方法执行耗时的需求，我们只需要定义一个模板方法，将记录方法执行耗时这一部分公共的逻辑代码，定义在模板方法当中，在这个方法开始运行之前，来记录这个方法运行的开始时间，在方法结束运行的时候，再来记录方法运行的结束时间，中间就来运行原始的业务方法。\n而中间运行的原始业务方法，可能是其中的一个业务方法，比如：我们只想通过 部门管理的 list 方法的执行耗时，那就只有这一个方法是原始业务方法。 而如果，我们是先想统计所有部门管理的业务方法执行耗时，那此时，所有的部门管理的业务方法都是 原始业务方法。 那面向这样的指定的一个或多个方法进行编程，我们就称之为 面向切面编程。\n那此时，当我们再调用部门管理的 list 业务方法时啊，并不会直接执行 list 方法的逻辑，而是会执行我们所定义的 模板方法 ， 然后再模板方法中：\n记录方法运行开始时间 运行原始的业务方法（那此时原始的业务方法，就是 list 方法） 记录方法运行结束时间，计算方法执行耗时 不论，我们运行的是那个业务方法，最后其实运行的就是我们定义的模板方法，而在模板方法中，就完成了原始方法执行耗时的统计操作 。(那这样呢，我们就通过一个模板方法就完成了指定的一个或多个业务方法执行耗时的统计)\n而大家会发现，这个流程，我们是不是似曾相识啊？\n对了，就是和我们之前所学习的动态代理技术是非常类似的。 我们所说的模板方法，其实就是代理对象中所定义的方法，那代理对象中的方法以及根据对应的业务需要， 完成了对应的业务功能，当运行原始业务方法时，就会运行代理对象中的方法，从而实现统计业务方法执行耗时的操作。\n其实，AOP面向切面编程和OOP面向对象编程一样，它们都仅仅是一种编程思想，而动态代理技术是这种思想最主流的实现方式。而Spring的AOP是Spring框架的高级技术，旨在管理bean对象的过程中底层使用动态代理机制，对特定的方法进行编程(功能增强)。\nAOP的优势：\n减少重复代码 提高开发效率 维护方便 AOP快速入门 在了解了什么是AOP后，我们下面通过一个快速入门程序，体验下AOP的开发，并掌握Spring中AOP的开发步骤。\n**需求：**统计各个业务层方法执行耗时。\n实现步骤：\n导入依赖：在pom.xml中导入AOP的依赖 编写AOP程序：针对于特定方法根据业务需要进行编程 为演示方便，可以自建新项目或导入提供的springboot-aop-quickstart项目工程\npom.xml\n1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; AOP程序：TimeAspect\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Component @Aspect //当前类为切面类 @Slf4j public class TimeAspect { @Around(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public Object recordTime(ProceedingJoinPoint pjp) throws Throwable { //记录方法执行开始时间 long begin = System.currentTimeMillis(); //执行原始方法 Object result = pjp.proceed(); //记录方法执行结束时间 long end = System.currentTimeMillis(); //计算方法执行耗时 log.info(pjp.getSignature()+\u0026#34;执行耗时: {}毫秒\u0026#34;,end-begin); return result; } } 重新启动SpringBoot服务测试程序：\n查询3号部门信息 我们可以再测试下：查询所有部门信息（同样执行AOP程序）\n我们通过AOP入门程序完成了业务方法执行耗时的统计，那其实AOP的功能远不止于此，常见的应用场景如下：\n记录系统的操作日志 权限控制 事务管理：我们前面所讲解的Spring事务管理，底层其实也是通过AOP来实现的，只要添加@Transactional注解之后，AOP程序自动会在原始方法运行前先来开启事务，在原始方法运行完毕之后提交或回滚事务 这些都是AOP应用的典型场景。\n通过入门程序，我们也应该感受到了AOP面向切面编程的一些优势：\n代码无侵入：没有修改原始的业务方法，就已经对原始的业务方法进行了功能的增强或者是功能的改变 减少了重复代码 提高开发效率 维护方便 AOP基础-核心概念 通过SpringAOP的快速入门，感受了一下AOP面向切面编程的开发方式。下面我们再来学习AOP当中涉及到的一些核心概念。\n1. 连接点：JoinPoint，可以被AOP控制的方法（暗含方法执行时的相关信息）\n连接点指的是可以被aop控制的方法。例如：入门程序当中所有的业务方法都是可以被aop控制的方法\n在SpringAOP提供的JoinPoint当中，封装了连接点方法在执行时的相关信息。（后面会有具体的讲解）\n2. 通知：Advice，指哪些重复的逻辑，也就是共性功能（最终体现为一个方法）\n在入门程序中是需要统计各个业务方法的执行耗时的，此时我们就需要在这些业务方法运行开始之前，先记录这个方法运行的开始时间，在每一个业务方法运行结束的时候，再来记录这个方法运行的结束时间。\n但是在AOP面向切面编程当中，我们只需要将这部分重复的代码逻辑抽取出来单独定义。抽取出来的这一部分重复的逻辑，也就是共性的功能。\n3. 切入点：PointCut，匹配连接点的条件，通知仅会在切入点方法执行时被应用\n在通知当中，我们所定义的共性功能到底要应用在哪些方法上？此时就涉及到了切入点pointcut概念。切入点指的是匹配连接点的条件。通知仅会在切入点方法运行时才会被应用。\n在aop的开发当中，我们通常会通过一个切入点表达式来描述切入点(后面会有详解)。\n假如：切入点表达式改为DeptServiceImpl.list()，此时就代表仅仅只有list这一个方法是切入点。只有list()方法在运行的时候才会应用通知。\n4. 切面：Aspect，描述通知与切入点的对应关系（通知+切入点）\n当通知和切入点结合在一起，就形成了一个切面。通过切面就能够描述当前aop程序需要针对于哪个原始方法，在什么时候执行什么样的操作。\n切面所在的类，我们一般称为切面类（被@Aspect注解标识的类）\n5. 目标对象：Target，通知所应用的对象\n目标对象指的就是通知所应用的对象，我们就称之为目标对象。\nAOP的核心概念我们介绍完毕之后，接下来我们再来分析一下我们所定义的通知是如何与目标对象结合在一起，对目标对象当中的方法进行功能增强的。\nSpring的AOP底层是基于动态代理技术来实现的，也就是说在程序运行的时候，会自动的基于动态代理技术为目标对象生成一个对应的代理对象。在代理对象当中就会对目标对象当中的原始方法进行功能的增强。\nAOP进阶-通知类型 在入门程序当中，我们已经使用了一种功能最为强大的通知类型：Around环绕通知。\n1 2 3 4 5 6 7 8 9 10 11 12 @Around(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public Object recordTime(ProceedingJoinPoint pjp) throws Throwable { //记录方法执行开始时间 long begin = System.currentTimeMillis(); //执行原始方法 Object result = pjp.proceed(); //记录方法执行结束时间 long end = System.currentTimeMillis(); //计算方法执行耗时 log.info(pjp.getSignature()+\u0026#34;执行耗时: {}毫秒\u0026#34;,end-begin); return result; } 只要我们在通知方法上加上了@Around注解，就代表当前通知是一个环绕通知。\nSpring中AOP的通知类型：\n@Around：环绕通知，此注解标注的通知方法在目标方法前、后都被执行 @Before：前置通知，此注解标注的通知方法在目标方法前被执行 @After ：后置通知，此注解标注的通知方法在目标方法后被执行，无论是否有异常都会执行 @AfterReturning ： 返回后通知，此注解标注的通知方法在目标方法后被执行，有异常不会执行 @AfterThrowing ： 异常后通知，此注解标注的通知方法发生异常后执行 下面我们通过代码演示，来加深对于不同通知类型的理解：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 @Slf4j @Component @Aspect public class MyAspect1 { //前置通知 @Before(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void before(JoinPoint joinPoint){ log.info(\u0026#34;before ...\u0026#34;); } //环绕通知 @Around(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { log.info(\u0026#34;around before ...\u0026#34;); //调用目标对象的原始方法执行 Object result = proceedingJoinPoint.proceed(); //原始方法如果执行时有异常，环绕通知中的后置代码不会在执行了 log.info(\u0026#34;around after ...\u0026#34;); return result; } //后置通知 @After(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void after(JoinPoint joinPoint){ log.info(\u0026#34;after ...\u0026#34;); } //返回后通知（程序在正常执行的情况下，会执行的后置通知） @AfterReturning(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void afterReturning(JoinPoint joinPoint){ log.info(\u0026#34;afterReturning ...\u0026#34;); } //异常通知（程序在出现异常的情况下，执行的后置通知） @AfterThrowing(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void afterThrowing(JoinPoint joinPoint){ log.info(\u0026#34;afterThrowing ...\u0026#34;); } } 重新启动SpringBoot服务，进行测试：\n1. 没有异常情况下：\n使用postman测试查询所有部门数据 查看idea中控制台日志输出\n程序没有发生异常的情况下，@AfterThrowing标识的通知方法不会执行。\n2. 出现异常情况下：\n修改DeptServiceImpl业务实现类中的代码： 添加异常\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Slf4j @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; @Override public List\u0026lt;Dept\u0026gt; list() { List\u0026lt;Dept\u0026gt; deptList = deptMapper.list(); //模拟异常 int num = 10/0; return deptList; } //省略其他代码... } 重新启动SpringBoot服务，测试发生异常情况下通知的执行：\n查看idea中控制台日志输出 程序发生异常的情况下：\n@AfterReturning标识的通知方法不会执行，@AfterThrowing标识的通知方法执行了 @Around环绕通知中原始方法调用时有异常，通知中的环绕后的代码逻辑也不会在执行了 （因为原始方法调用已经出异常了） 在使用通知时的注意事项：\n@Around环绕通知需要自己调用 ProceedingJoinPoint.proceed() 来让原始方法执行，其他通知不需要考虑目标方法执行 @Around环绕通知方法的返回值，必须指定为Object，来接收原始方法的返回值，否则原始方法执行完毕，是获取不到返回值的。 五种常见的通知类型，我们已经测试完毕了，此时我们再来看一下刚才所编写的代码，有什么问题吗？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //前置通知 @Before(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) //环绕通知 @Around(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) //后置通知 @After(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) //返回后通知（程序在正常执行的情况下，会执行的后置通知） @AfterReturning(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) //异常通知（程序在出现异常的情况下，执行的后置通知） @AfterThrowing(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) 我们发现啊，每一个注解里面都指定了切入点表达式，而且这些切入点表达式都一模一样。此时我们的代码当中就存在了大量的重复性的切入点表达式，假如此时切入点表达式需要变动，就需要将所有的切入点表达式一个一个的来改动，就变得非常繁琐了。\n怎么来解决这个切入点表达式重复的问题？ 答案就是：抽取\nSpring提供了@PointCut注解，该注解的作用是将公共的切入点表达式抽取出来，需要用到时引用该切入点表达式即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @Slf4j @Component @Aspect public class MyAspect1 { //切入点方法（公共的切入点表达式） @Pointcut(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) private void pt(){ } //前置通知（引用切入点） @Before(\u0026#34;pt()\u0026#34;) public void before(JoinPoint joinPoint){ log.info(\u0026#34;before ...\u0026#34;); } //环绕通知 @Around(\u0026#34;pt()\u0026#34;) public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { log.info(\u0026#34;around before ...\u0026#34;); //调用目标对象的原始方法执行 Object result = proceedingJoinPoint.proceed(); //原始方法在执行时：发生异常 //后续代码不在执行 log.info(\u0026#34;around after ...\u0026#34;); return result; } //后置通知 @After(\u0026#34;pt()\u0026#34;) public void after(JoinPoint joinPoint){ log.info(\u0026#34;after ...\u0026#34;); } //返回后通知（程序在正常执行的情况下，会执行的后置通知） @AfterReturning(\u0026#34;pt()\u0026#34;) public void afterReturning(JoinPoint joinPoint){ log.info(\u0026#34;afterReturning ...\u0026#34;); } //异常通知（程序在出现异常的情况下，执行的后置通知） @AfterThrowing(\u0026#34;pt()\u0026#34;) public void afterThrowing(JoinPoint joinPoint){ log.info(\u0026#34;afterThrowing ...\u0026#34;); } } 需要注意的是：当切入点方法使用private修饰时，仅能在当前切面类中引用该表达式， 当外部其他切面类中也要引用当前类中的切入点表达式，就需要把private改为public，而在引用的时候，具体的语法为：\n全类名.方法名()，具体形式如下：\n1 2 3 4 5 6 7 8 9 10 @Slf4j @Component @Aspect public class MyAspect2 { //引用MyAspect1切面类中的切入点表达式 @Before(\u0026#34;com.itheima.aspect.MyAspect1.pt()\u0026#34;) public void before(){ log.info(\u0026#34;MyAspect2 -\u0026gt; before ...\u0026#34;); } } AOP进阶-通知顺序 讲解完了Spring中AOP所支持的5种通知类型之后，接下来我们再来研究通知的执行顺序。\n当在项目开发当中，我们定义了多个切面类，而多个切面类中多个切入点都匹配到了同一个目标方法。此时当目标方法在运行的时候，这多个切面类当中的这些通知方法都会运行。\n此时我们就有一个疑问，这多个通知方法到底哪个先运行，哪个后运行？ 下面我们通过程序来验证（这里呢，我们就定义两种类型的通知进行测试，一种是前置通知@Before，一种是后置通知@After）\n定义多个切面类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Slf4j @Component @Aspect public class MyAspect2 { //前置通知 @Before(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void before(){ log.info(\u0026#34;MyAspect2 -\u0026gt; before ...\u0026#34;); } //后置通知 @After(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void after(){ log.info(\u0026#34;MyAspect2 -\u0026gt; after ...\u0026#34;); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Slf4j @Component @Aspect public class MyAspect3 { //前置通知 @Before(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void before(){ log.info(\u0026#34;MyAspect3 -\u0026gt; before ...\u0026#34;); } //后置通知 @After(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void after(){ log.info(\u0026#34;MyAspect3 -\u0026gt; after ...\u0026#34;); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Slf4j @Component @Aspect public class MyAspect4 { //前置通知 @Before(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void before(){ log.info(\u0026#34;MyAspect4 -\u0026gt; before ...\u0026#34;); } //后置通知 @After(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void after(){ log.info(\u0026#34;MyAspect4 -\u0026gt; after ...\u0026#34;); } } 重新启动SpringBoot服务，测试通知的执行顺序：\n备注：\n把DeptServiceImpl实现类中模拟异常的代码删除或注释掉。 注释掉其他切面类(把@Aspect注释即可)，仅保留MyAspect2、MyAspect3、MyAspect4 ，这样就可以清晰看到执行的结果，而不被其他切面类干扰。 使用postman测试查询所有部门数据 查看idea中控制台日志输出\n通过以上程序运行可以看出在不同切面类中，默认按照切面类的类名字母排序：\n目标方法前的通知方法：字母排名靠前的先执行 目标方法后的通知方法：字母排名靠前的后执行 如果我们想控制通知的执行顺序有两种方式：\n修改切面类的类名（这种方式非常繁琐、而且不便管理） 使用Spring提供的@Order注解 使用@Order注解，控制通知的执行顺序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Slf4j @Component @Aspect @Order(2) //切面类的执行顺序（前置通知：数字越小先执行; 后置通知：数字越小越后执行） public class MyAspect2 { //前置通知 @Before(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void before(){ log.info(\u0026#34;MyAspect2 -\u0026gt; before ...\u0026#34;); } //后置通知 @After(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void after(){ log.info(\u0026#34;MyAspect2 -\u0026gt; after ...\u0026#34;); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Slf4j @Component @Aspect @Order(3) //切面类的执行顺序（前置通知：数字越小先执行; 后置通知：数字越小越后执行） public class MyAspect3 { //前置通知 @Before(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void before(){ log.info(\u0026#34;MyAspect3 -\u0026gt; before ...\u0026#34;); } //后置通知 @After(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void after(){ log.info(\u0026#34;MyAspect3 -\u0026gt; after ...\u0026#34;); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Slf4j @Component @Aspect @Order(1) //切面类的执行顺序（前置通知：数字越小先执行; 后置通知：数字越小越后执行） public class MyAspect4 { //前置通知 @Before(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void before(){ log.info(\u0026#34;MyAspect4 -\u0026gt; before ...\u0026#34;); } //后置通知 @After(\u0026#34;execution(* com.itheima.service.*.*(..))\u0026#34;) public void after(){ log.info(\u0026#34;MyAspect4 -\u0026gt; after ...\u0026#34;); } } 重新启动SpringBoot服务，测试通知执行顺序：\n通知的执行顺序大家主要知道两点即可：\n不同的切面类当中，默认情况下通知的执行顺序是与切面类的类名字母排序是有关系的 可以在切面类上面加上@Order注解，来控制不同的切面类通知的执行顺序 AOP进阶-切入点表达式-execution 从AOP的入门程序到现在，我们一直都在使用切入点表达式来描述切入点。下面我们就来详细的介绍一下切入点表达式的具体写法。\n切入点表达式：\n描述切入点方法的一种表达式 作用：主要用来决定项目中的哪些方法需要加入通知 常见形式： execution(……)：根据方法的签名来匹配 2. @annotation(……) ：根据注解匹配\n首先我们先学习第一种最为常见的execution切入点表达式。\nexecution主要根据方法的返回值、包名、类名、方法名、方法参数等信息来匹配，语法为：\n1 execution(访问修饰符? 返回值 包名.类名.?方法名(方法参数) throws 异常?) 其中带?的表示可以省略的部分\n访问修饰符：可省略（比如: public、protected） 包名.类名： 可省略 throws 异常：可省略（注意是方法上声明抛出的异常，不是实际抛出的异常） 示例：\n1 @Before(\u0026#34;execution(void com.itheima.service.impl.DeptServiceImpl.delete(java.lang.Integer))\u0026#34;) 可以使用通配符描述切入点\n* ：单个独立的任意符号，可以通配任意返回值、包名、类名、方法名、任意类型的一个参数，也可以通配包、类、方法名的一部分 .. ：多个连续的任意符号，可以通配任意层级的包，或任意类型、任意个数的参数 切入点表达式的语法规则：\n方法的访问修饰符可以省略 返回值可以使用*号代替（任意返回值类型） 包名可以使用*号代替，代表任意包（一层包使用一个*） 使用..配置包名，标识此包以及此包下的所有子包 类名可以使用*号代替，标识任意类 方法名可以使用*号代替，表示任意方法 可以使用 * 配置参数，一个任意类型的参数 可以使用.. 配置参数，任意个任意类型的参数 切入点表达式示例\n省略方法的修饰符号 1 execution(void com.itheima.service.impl.DeptServiceImpl.delete(java.lang.Integer)) 使用*代替返回值类型 1 execution(* com.itheima.service.impl.DeptServiceImpl.delete(java.lang.Integer)) 使用*代替包名（一层包使用一个*） 1 execution(* com.itheima.*.*.DeptServiceImpl.delete(java.lang.Integer)) 使用..省略包名 1 execution(* com..DeptServiceImpl.delete(java.lang.Integer)) 使用*代替类名 1 execution(* com..*.delete(java.lang.Integer)) 使用*代替方法名 1 execution(* com..*.*(java.lang.Integer)) 使用 * 代替参数 1 execution(* com.itheima.service.impl.DeptServiceImpl.delete(*)) 使用..省略参数 1 execution(* com..*.*(..)) 注意事项：\n根据业务需要，可以使用 且（\u0026amp;\u0026amp;）、或（||）、非（!） 来组合比较复杂的切入点表达式。 1 execution(* com.itheima.service.DeptService.list(..)) || execution(* com.itheima.service.DeptService.delete(..)) 切入点表达式的书写建议：\n所有业务方法名在命名时尽量规范，方便切入点表达式快速匹配。如：查询类方法都是 find 开头，更新类方法都是update开头 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 //业务类 @Service public class DeptServiceImpl implements DeptService { public List\u0026lt;Dept\u0026gt; findAllDept() { //省略代码... } public Dept findDeptById(Integer id) { //省略代码... } public void updateDeptById(Integer id) { //省略代码... } public void updateDeptByMoreCondition(Dept dept) { //省略代码... } //其他代码... } 1 2 //匹配DeptServiceImpl类中以find开头的方法 execution(* com.itheima.service.impl.DeptServiceImpl.find*(..)) 描述切入点方法通常基于接口描述，而不是直接描述实现类，增强拓展性 1 execution(* com.itheima.service.DeptService.*(..)) 在满足业务需要的前提下，尽量缩小切入点的匹配范围。如：包名匹配尽量不使用 ..，使用 * 匹配单个包 1 execution(* com.itheima.*.*.DeptServiceImpl.find*(..)) AOP进阶-切入点表达式-@annotation 已经学习了execution切入点表达式的语法。那么如果我们要匹配多个无规则的方法，比如：list()和 delete()这两个方法。这个时候我们基于execution这种切入点表达式来描述就不是很方便了。而在之前我们是将两个切入点表达式组合在了一起完成的需求，这个是比较繁琐的。\n我们可以借助于另一种切入点表达式annotation来描述这一类的切入点，从而来简化切入点表达式的书写。\n实现步骤：\n编写自定义注解 在业务类要做为连接点的方法上添加自定义注解 自定义注解：MyLog\n1 2 3 4 @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface MyLog { } 业务类：DeptServiceImpl\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @Slf4j @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; @Override @MyLog //自定义注解（表示：当前方法属于目标方法） public List\u0026lt;Dept\u0026gt; list() { List\u0026lt;Dept\u0026gt; deptList = deptMapper.list(); //模拟异常 //int num = 10/0; return deptList; } @Override @MyLog //自定义注解（表示：当前方法属于目标方法） public void delete(Integer id) { //1. 删除部门 deptMapper.delete(id); } @Override public void save(Dept dept) { dept.setCreateTime(LocalDateTime.now()); dept.setUpdateTime(LocalDateTime.now()); deptMapper.save(dept); } @Override public Dept getById(Integer id) { return deptMapper.getById(id); } @Override public void update(Dept dept) { dept.setUpdateTime(LocalDateTime.now()); deptMapper.update(dept); } } 切面类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Slf4j @Component @Aspect public class MyAspect6 { //针对list方法、delete方法进行前置通知和后置通知 //前置通知 @Before(\u0026#34;@annotation(com.itheima.anno.MyLog)\u0026#34;) public void before(){ log.info(\u0026#34;MyAspect6 -\u0026gt; before ...\u0026#34;); } //后置通知 @After(\u0026#34;@annotation(com.itheima.anno.MyLog)\u0026#34;) public void after(){ log.info(\u0026#34;MyAspect6 -\u0026gt; after ...\u0026#34;); } } 重启SpringBoot服务，测试查询所有部门数据，查看控制台日志：\n到此我们两种常见的切入点表达式我已经介绍完了。\nexecution切入点表达式 根据我们所指定的方法的描述信息来匹配切入点方法，这种方式也是最为常用的一种方式 如果我们要匹配的切入点方法的方法名不规则，或者有一些比较特殊的需求，通过execution切入点表达式描述比较繁琐 annotation 切入点表达式 基于注解的方式来匹配切入点方法。这种方式虽然多一步操作，我们需要自定义一个注解，但是相对来比较灵活。我们需要匹配哪个方法，就在方法上加上对应的注解就可以了 AOP进阶-连接点 讲解完了切入点表达式之后，接下来我们再来讲解最后一个部分连接点。我们前面在讲解AOP核心概念的时候，我们提到过什么是连接点，连接点可以简单理解为可以被AOP控制的方法。\n我们目标对象当中所有的方法是不是都是可以被AOP控制的方法。而在SpringAOP当中，连接点又特指方法的执行。\n在Spring中用JoinPoint抽象了连接点，用它可以获得方法执行时的相关信息，如目标类名、方法名、方法参数等。\n对于@Around通知，获取连接点信息只能使用ProceedingJoinPoint类型 对于其他四种通知，获取连接点信息只能使用JoinPoint，它是ProceedingJoinPoint的父类型 示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @Slf4j @Component @Aspect public class MyAspect7 { @Pointcut(\u0026#34;@annotation(com.itheima.anno.MyLog)\u0026#34;) private void pt(){} //前置通知 @Before(\u0026#34;pt()\u0026#34;) public void before(JoinPoint joinPoint){ log.info(joinPoint.getSignature().getName() + \u0026#34; MyAspect7 -\u0026gt; before ...\u0026#34;); } //后置通知 @Before(\u0026#34;pt()\u0026#34;) public void after(JoinPoint joinPoint){ log.info(joinPoint.getSignature().getName() + \u0026#34; MyAspect7 -\u0026gt; after ...\u0026#34;); } //环绕通知 @Around(\u0026#34;pt()\u0026#34;) public Object around(ProceedingJoinPoint pjp) throws Throwable { //获取目标类名 String name = pjp.getTarget().getClass().getName(); log.info(\u0026#34;目标类名：{}\u0026#34;,name); //目标方法名 String methodName = pjp.getSignature().getName(); log.info(\u0026#34;目标方法名：{}\u0026#34;,methodName); //获取方法执行时需要的参数 Object[] args = pjp.getArgs(); log.info(\u0026#34;目标方法参数：{}\u0026#34;, Arrays.toString(args)); //执行原始方法 Object returnValue = pjp.proceed(); return returnValue; } } 重新启动SpringBoot服务，执行查询部门数据的功能：\nAOP案例-记录操作日志 需求 需求：将案例中增、删、改相关接口的操作日志记录到数据库表中\n就是当访问部门管理和员工管理当中的增、删、改相关功能接口时，需要详细的操作日志，并保存在数据表中，便于后期数据追踪。 操作日志信息包含：\n操作人、操作时间、执行方法的全类名、执行方法名、方法运行时参数、返回值、方法执行时长 所记录的日志信息包括当前接口的操作人是谁操作的，什么时间点操作的，以及访问的是哪个类当中的哪个方法，在访问这个方法的时候传入进来的参数是什么，访问这个方法最终拿到的返回值是什么，以及整个接口方法的运行时长是多长时间。\n分析 问题1：项目当中增删改相关的方法是不是有很多？\n很多 问题2：我们需要针对每一个功能接口方法进行修改，在每一个功能接口当中都来记录这些操作日志吗？\n这种做法比较繁琐 以上两个问题的解决方案：可以使用AOP解决(每一个增删改功能接口中要实现的记录操作日志的逻辑代码是相同)。\n可以把这部分记录操作日志的通用的、重复性的逻辑代码抽取出来定义在一个通知方法当中，我们通过AOP面向切面编程的方式，在不改动原始功能的基础上来对原始的功能进行增强。目前我们所增强的功能就是来记录操作日志，所以也可以使用AOP的技术来实现。使用AOP的技术来实现也是最为简单，最为方便的。\n问题3：既然要基于AOP面向切面编程的方式来完成的功能，那么我们要使用 AOP五种通知类型当中的哪种通知类型？\n答案：环绕通知 所记录的操作日志当中包括：操作人、操作时间，访问的是哪个类、哪个方法、方法运行时参数、方法的返回值、方法的运行时长。\n方法返回值，是在原始方法执行后才能获取到的。\n方法的运行时长，需要原始方法运行之前记录开始时间，原始方法运行之后记录结束时间。通过计算获得方法的执行耗时。\n基于以上的分析我们确定要使用Around环绕通知。\n问题4：最后一个问题，切入点表达式我们该怎么写？\n答案：使用annotation来描述表达式 要匹配业务接口当中所有的增删改的方法，而增删改方法在命名上没有共同的前缀或后缀。此时如果使用execution切入点表达式也可以，但是会比较繁琐。 当遇到增删改的方法名没有规律时，就可以使用 annotation切入点表达式\n步骤 简单分析了一下大概的实现思路后，接下来我们就要来完成案例了。案例的实现步骤其实就两步：\n准备工作 引入AOP的起步依赖 导入资料中准备好的数据库表结构，并引入对应的实体类 编码实现 自定义注解@Log 定义切面类，完成记录操作日志的逻辑 实现 准备工作\n1.AOP起步依赖\n1 2 3 4 5 \u0026lt;!--AOP起步依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \\2. 导入资料中准备好的数据库表结构，并引入对应的实体类\n数据表\n1 2 3 4 5 6 7 8 9 10 11 -- 操作日志表 create table operate_log( id int unsigned primary key auto_increment comment \u0026#39;ID\u0026#39;, operate_user int unsigned comment \u0026#39;操作人\u0026#39;, operate_time datetime comment \u0026#39;操作时间\u0026#39;, class_name varchar(100) comment \u0026#39;操作的类名\u0026#39;, method_name varchar(100) comment \u0026#39;操作的方法名\u0026#39;, method_params varchar(1000) comment \u0026#39;方法参数\u0026#39;, return_value varchar(2000) comment \u0026#39;返回值\u0026#39;, cost_time bigint comment \u0026#39;方法执行耗时, 单位:ms\u0026#39; ) comment \u0026#39;操作日志表\u0026#39;; 实体类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //操作日志实体类 @Data @NoArgsConstructor @AllArgsConstructor public class OperateLog { private Integer id; //主键ID private Integer operateUser; //操作人ID private LocalDateTime operateTime; //操作时间 private String className; //操作类名 private String methodName; //操作方法名 private String methodParams; //操作方法参数 private String returnValue; //操作方法返回值 private Long costTime; //操作耗时 } Mapper接口\n1 2 3 4 5 6 7 8 9 @Mapper public interface OperateLogMapper { //插入日志数据 @Insert(\u0026#34;insert into operate_log (operate_user, operate_time, class_name, method_name, method_params, return_value, cost_time) \u0026#34; + \u0026#34;values (#{operateUser}, #{operateTime}, #{className}, #{methodName}, #{methodParams}, #{returnValue}, #{costTime});\u0026#34;) public void insert(OperateLog log); } 编码实现\n自定义注解@Log 1 2 3 4 5 6 7 8 /** * 自定义Log注解 */ @Target({ElementType.METHOD}) @Documented @Retention(RetentionPolicy.RUNTIME) public @interface Log { } 修改业务实现类，在增删改业务方法上添加@Log注解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Slf4j @Service public class EmpServiceImpl implements EmpService { @Autowired private EmpMapper empMapper; @Override @Log public void update(Emp emp) { emp.setUpdateTime(LocalDateTime.now()); //更新修改时间为当前时间 empMapper.update(emp); } @Override @Log public void save(Emp emp) { //补全数据 emp.setCreateTime(LocalDateTime.now()); emp.setUpdateTime(LocalDateTime.now()); //调用添加方法 empMapper.insert(emp); } @Override @Log public void delete(List\u0026lt;Integer\u0026gt; ids) { empMapper.delete(ids); } //省略其他代码... } 以同样的方式，修改EmpServiceImpl业务类\n定义切面类，完成记录操作日志的逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 @Slf4j @Component @Aspect //切面类 public class LogAspect { @Autowired private HttpServletRequest request; @Autowired private OperateLogMapper operateLogMapper; @Around(\u0026#34;@annotation(com.itheima.anno.Log)\u0026#34;) public Object recordLog(ProceedingJoinPoint joinPoint) throws Throwable { //操作人ID - 当前登录员工ID //获取请求头中的jwt令牌, 解析令牌 String jwt = request.getHeader(\u0026#34;token\u0026#34;); Claims claims = JwtUtils.parseJWT(jwt); Integer operateUser = (Integer) claims.get(\u0026#34;id\u0026#34;); //操作时间 LocalDateTime operateTime = LocalDateTime.now(); //操作类名 String className = joinPoint.getTarget().getClass().getName(); //操作方法名 String methodName = joinPoint.getSignature().getName(); //操作方法参数 Object[] args = joinPoint.getArgs(); String methodParams = Arrays.toString(args); long begin = System.currentTimeMillis(); //调用原始目标方法运行 Object result = joinPoint.proceed(); long end = System.currentTimeMillis(); //方法返回值 String returnValue = JSONObject.toJSONString(result); //操作耗时 Long costTime = end - begin; //记录操作日志 OperateLog operateLog = new OperateLog(null,operateUser,operateTime,className,methodName,methodParams,returnValue,costTime); operateLogMapper.insert(operateLog); log.info(\u0026#34;AOP记录操作日志: {}\u0026#34; , operateLog); return result; } } 代码实现细节： 获取request对象，从请求头中获取到jwt令牌，解析令牌获取出当前用户的id。\n重启SpringBoot服务，测试操作日志记录功能：\n添加一个新的部门 数据表 ","date":"2025-04-13T16:01:23+08:00","image":"https://nova-bryan.github.io/p/%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E5%92%8Caop/image_hu17089168107649188491.png","permalink":"https://nova-bryan.github.io/p/%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E5%92%8Caop/","title":"事务管理和AOP"},{"content":"题目 答案： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 import java.util.*; public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); // 读取输入 int n = sc.nextInt(); // 矿洞数 int m = sc.nextInt(); // 最大步数 int[] L = new int[2000005]; // 记录左侧矿洞 int[] R = new int[2000005]; // 记录右侧矿洞 int[] Ls = new int[2000005]; // 左侧前缀和 int[] Rs = new int[2000005]; // 右侧前缀和 int zero = 0; // 记录起点 0 处的矿洞数量 // 读取矿洞信息 for (int i = 0; i \u0026lt; n; i++) { int t = sc.nextInt(); if (t \u0026lt; 0) { L[-t]++; // 左侧 } else if (t \u0026gt; 0) { R[t]++; // 右侧 } else { zero++; // 记录起点0 } } // 计算前缀和 for (int i = 1; i \u0026lt;= 2000000; i++) { Ls[i] = L[i] + Ls[i - 1]; Rs[i] = R[i] + Rs[i - 1]; } int ans = 0; // 记录最大可收集矿石数 // 枚举向左走的步数 for (int i = 0; i \u0026lt;= m; i++) { int j = (m - i) / 2; // 剩余步数一半用于回头 if (i \u0026lt; j) j = m - 2 * i; // 计算当前走法的矿石数 int sums = Rs[i] + Ls[Math.max(0, j)]; ans = Math.max(ans, sums); } ans += zero; // 加上起点0的矿石数量 // 输出答案 System.out.println(ans); } } ","date":"2025-04-10T00:00:00Z","image":"https://nova-bryan.github.io/p/acwing-5995.%E6%8C%96%E7%9F%BF/image_hu7343995253115549451.png","permalink":"https://nova-bryan.github.io/p/acwing-5995.%E6%8C%96%E7%9F%BF/","title":"AcWing 5995.挖矿"},{"content":"题目： 答案： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Solution { static List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; ans; public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; pathSum(TreeNode root, int targetSum) { if (root == null) return ans; ans=new ArrayList\u0026lt;\u0026gt;(); dfs(new ArrayList\u0026lt;\u0026gt;(),root,0,targetSum); return ans; } public static void dfs(List\u0026lt;Integer\u0026gt; list,TreeNode node,int sum,int targetSum){ if (node==null){ return; } list.add(node.val); sum += node.val; if (node.left == null \u0026amp;\u0026amp; node.right == null \u0026amp;\u0026amp; sum == targetSum) { ans.add(new ArrayList\u0026lt;\u0026gt;(list)); // 这里一定要 new 一个副本 } dfs(list,node.left,sum,targetSum); dfs(list,node.right,sum,targetSum); list.remove(list.size()-1); } } ","date":"2025-04-09T00:00:00Z","image":"https://nova-bryan.github.io/p/leetcode113.%E8%B7%AF%E5%BE%84%E6%80%BB%E5%90%88ii/image_hu7343995253115549451.png","permalink":"https://nova-bryan.github.io/p/leetcode113.%E8%B7%AF%E5%BE%84%E6%80%BB%E5%90%88ii/","title":"LeetCode113.路径总合II"},{"content":"题目： 答案： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 import java.util.ArrayList; import java.util.List; class Solution { static boolean flag = false; static boolean[][] isFlag; public boolean exist(char[][] board, String word) { flag = false; // 每次调用要重置 isFlag = new boolean[board.length][board[0].length]; List\u0026lt;Character\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; word.length(); i++) { list.add(word.charAt(i)); } // 从每一个点开始尝试匹配 for (int i = 0; i \u0026lt; board.length; i++) { for (int j = 0; j \u0026lt; board[0].length; j++) { dfs(i, j, board, list, 0); // 第0个字符开始匹配 if (flag) return true; } } return false; } public static void dfs(int i, int j, char[][] board, List\u0026lt;Character\u0026gt; list, int index) { // 如果已经全部匹配完了 if (index == list.size()) { flag = true; return; } // 越界 + 已访问 + 当前字符不匹配 if (i \u0026lt; 0 || i \u0026gt;= board.length || j \u0026lt; 0 || j \u0026gt;= board[0].length || isFlag[i][j] || board[i][j] != list.get(index)) { return; } isFlag[i][j] = true; // 递归向四个方向搜索 dfs(i + 1, j, board, list, index + 1); dfs(i - 1, j, board, list, index + 1); dfs(i, j + 1, board, list, index + 1); dfs(i, j - 1, board, list, index + 1); isFlag[i][j] = false; // 回溯 } } ","date":"2025-04-09T00:00:00Z","image":"https://nova-bryan.github.io/p/leetcode79.%E5%8D%95%E8%AF%8D%E6%90%9C%E7%B4%A2/image_hu7343995253115549451.png","permalink":"https://nova-bryan.github.io/p/leetcode79.%E5%8D%95%E8%AF%8D%E6%90%9C%E7%B4%A2/","title":"LeetCode79.单词搜索"},{"content":"题目 答案 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Solution { TreeNode prev = null; public boolean isValidBST(TreeNode root) { return inorder(root); } public boolean inorder(TreeNode node) { if (node == null) return true; // 左子树 if (!inorder(node.left)) return false; // 当前节点必须大于中序遍历的前一个节点 if (prev != null \u0026amp;\u0026amp; node.val \u0026lt;= prev.val) return false; prev = node; // 更新前一个节点 // 右子树 return inorder(node.right); } } ","date":"2025-04-09T00:00:00Z","image":"https://nova-bryan.github.io/p/leetcode98.%E9%AA%8C%E8%AF%81%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image_hu7343995253115549451.png","permalink":"https://nova-bryan.github.io/p/leetcode98.%E9%AA%8C%E8%AF%81%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/","title":"LeetCode98.验证二叉搜索树"},{"content":"题目: 博主解题思路： 整体思路：\n本题是一个关于两头奶牛分蛋糕的博弈问题，关键在于分析在双方都采取最优策略的情况下，如何计算出贝茜和埃尔茜最终吃到的蛋糕量。由于贝茜先行动（堆叠相邻蛋糕），埃尔茜后行动（选择最左或最右蛋糕藏起来），且最终贝茜吃剩下的一个蛋糕，埃尔茜吃藏起来的蛋糕，所以核心是找出埃尔茜能藏起来的最大蛋糕量，再用蛋糕总量减去埃尔茜的量，即可得到贝茜的量。\n具体步骤\n处理多组测试用例 首先读取测试用例的数量 T，然后对每个测试用例进行处理。对于每个测试用例，先读取蛋糕的数量 N。\n计算前缀和 使用前缀和数组 s 来方便计算区间内蛋糕的总量。前缀和数组 s[i] 表示前 i 个蛋糕的大小之和。通过遍历输入的蛋糕大小数组，计算出前缀和数组： 1 2 3 4 long[] s = new long[n + 1]; String[] split = br.readLine().split(\u0026#34; \u0026#34;); for (int i = 1; i \u0026lt;= n; i++) s[i] = Long.parseLong(split[i - 1]) + s[i - 1]; 确定埃尔茜藏蛋糕的次数 每一轮埃尔茜藏一个蛋糕，最终只剩下一个蛋糕给贝茜吃，所以埃尔茜藏蛋糕的次数为 (n - 1) / 2，记为 eTotal。\n找出埃尔茜能藏起来的最大蛋糕量 埃尔茜藏蛋糕的过程可以看作是从蛋糕序列的左右两端选取一些连续的蛋糕。我们通过枚举不同的组合，找出能使埃尔茜藏起来的蛋糕总量最大的情况。具体做法是，枚举从左边选取 i 个蛋糕，从右边选取 eTotal - i 个蛋糕的所有可能组合，计算这些组合的蛋糕总量，并取最大值作为埃尔茜能藏起来的最大蛋糕量 e：\n1 2 3 4 int eTotal = n - 1 \u0026gt;\u0026gt; 1; long e = 0; for (int i = 0; i \u0026lt;= eTotal; i++) e = Math.max(e, s[i] + (s[n] - s[n - eTotal + i])); 计算贝茜吃到的蛋糕量 用所有蛋糕的总量 s[n] 减去埃尔茜藏起来的最大蛋糕量 e，即可得到贝茜吃到的蛋糕量 b：\n1 long b = s[n] - e; 输出结果 对于每个测试用例，输出贝茜和埃尔茜分别吃到的蛋糕量 b 和 e。\n总结\n通过上述步骤，我们利用前缀和数组来高效计算区间内蛋糕的总量，通过枚举不同的左右两端蛋糕组合，找出埃尔茜能藏起来的最大蛋糕量，进而计算出贝茜吃到的蛋糕量，从而解决了该博弈问题。\n答案： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import java.io.*; public class Main { public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(System.out)); int t = Integer.parseInt(br.readLine()); while (t-- != 0) { int n = Integer.parseInt(br.readLine()); long[] s = new long[n + 1]; String[] split = br.readLine().split(\u0026#34; \u0026#34;); for (int i = 1; i \u0026lt;= n; i++) s[i] = Long.parseLong(split[i - 1]) + s[i - 1]; int eTotal = n - 1 \u0026gt;\u0026gt; 1; long e = 0; for (int i = 0; i \u0026lt;= eTotal; i++) e = Math.max(e, s[i] + (s[n] - s[n - eTotal + i])); long b = s[n] - e; bw.write(b + \u0026#34; \u0026#34; + e); bw.newLine(); } br.close(); bw.close(); } }\t","date":"2025-03-26T00:00:00Z","image":"https://nova-bryan.github.io/p/acwing-6118.-%E8%9B%8B%E7%B3%95%E6%B8%B8%E6%88%8F/image_hu7343995253115549451.png","permalink":"https://nova-bryan.github.io/p/acwing-6118.-%E8%9B%8B%E7%B3%95%E6%B8%B8%E6%88%8F/","title":"AcWing 6118. 蛋糕游戏"},{"content":"题目 博主解题思路： ​\t首先熟读题目后，发现要求的是，一段定长字符串中的abb形式的定长字串，如果定长字串的数量大于等于F的话，那么就可以列为一组答案，值得注意的是，字符串中可能存在至多一个字符与原始字符串不用，也就是说，可以在字串中更改一个字符，如果字符更改后的关联的定长字串的数量能大于等于F，那么也可以列入答案当中，那么思路就很明显了，首先，我们定义一个cnt数组，用来统计原字符串中的定长字串数量，再依次改变原字符串中的每一个字符，共有25种更改情况，每次改变字符，都会改变三个定长字串，如：\n值得注意的是，每次我们更改字符之前，我们将原来的关联的三个字串数量-1，这样子我们修改之后，得到新字串，加入到字串数量中，才能有效的判断是否出现了有效的答案字串，不然就会多加1，在改变字符之后，对应的三个新字串数量加一，判断是否有答案字串，如果有答案字串，那么就标记一下（开辟一个新的数组来记录答案字串），更新完之后，再减去字串数量-1，最后恢复现场，将原字符放回原位，并更新原字串数量，这样子就能达到至多只有一个字符改变的效果，最后统计答案字串数量，并输出答案子串\n说实话这个题目难度对目前的我来说难度还是比较大，但是搞懂本题之后，对我的思维拓展还是比较大，模拟题目或者需要重复执行类似操作的题目，可以开辟一个更新函数来重复操作，直观并且更为简洁\n答案： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 import java.util.Scanner; public class Main{ private static final int N = 20010; // N 设为静态常量 private static final int M = 26; private static Integer n; private static Integer m; private static char[] s; private static int[][] cnt=new int[M][M]; private static boolean[][] ans=new boolean[M][M]; public static void main(String agrs[]){ Scanner sc=new Scanner(System.in); n =sc.nextInt(); m=sc.nextInt(); sc.nextLine(); String S=sc.nextLine(); s=S.toCharArray(); //先将字符转换为数字 for (int i = 0; i \u0026lt; s.length; i++) s[i]-=\u0026#39;a\u0026#39;; //先统计原字符串中的哞叫可能 update(0,n-1,1); for (int i = 0; i \u0026lt; n; i++) { char t=s[i]; update(i-2,i+2,-1); for (int j = 0; j \u0026lt; 26; j++) { if (j!=t){ s[i]= (char) j; update(i-2,i+2,1); update(i-2,i+2,-1); } } s[i]=t; update(i-2,i+2,1); } int res=0; for (int i = 0; i \u0026lt; 26; i++) { for (int j = 0; j \u0026lt; 26 ; j++) { if (ans[i][j]) res++; } } System.out.println(res); for (int i = 0; i \u0026lt; 26; i++) { for (int j = 0; j \u0026lt; 26 ; j++) { if (ans[i][j]) { System.out.println(String.format(\u0026#34;%c%c%c\u0026#34;, (char) (i + \u0026#39;a\u0026#39;), (char) (j + \u0026#39;a\u0026#39;), (char) (j + \u0026#39;a\u0026#39;))); } } } } public static void update(int l,int r,int v){ l=Math.max(l,0); r=Math.min(r,n-1); for (int i = l; i+2 \u0026lt;= r ; i++) { char a=s[i],b=s[i+1],c=s[i+2]; if(a!=b\u0026amp;\u0026amp;b==c){ cnt[a][b]+=v; if (cnt[a][b]\u0026gt;=m) ans[a][b]=true; } } } } ","date":"2025-03-24T00:00:00Z","image":"https://nova-bryan.github.io/p/acwing-6123.-%E5%93%9E%E5%8F%AB%E6%97%B6%E9%97%B4/image_hu7343995253115549451.png","permalink":"https://nova-bryan.github.io/p/acwing-6123.-%E5%93%9E%E5%8F%AB%E6%97%B6%E9%97%B4/","title":"AcWing 6123. 哞叫时间"},{"content":"Markdown 基本语法 Markdown是一种轻量级标记语言，排版语法简洁，让人们更多地关注内容本身而非排版。它使用易读易写的纯文本格式编写文档，可与HTML混编，可导出 HTML、PDF 以及本身的 .md 格式的文件。因简洁、高效、易读、易写，Markdown被大量使用，如Github、Wikipedia、简书等。\n在线体验一下 Markdown在线编辑器 (opens new window)。\n千万不要被「标记」、「语言」吓到，Markdown的语法十分简单，常用的标记符号不超过十个，用于日常写作记录绰绰有余，不到半小时就能完全掌握。\n就是这十个不到的标记符号，却能让人优雅地沉浸式记录，专注内容而不是纠结排版，达到「心中无尘，码字入神」的境界。\nMarkdown 标题语法 要创建标题，请在单词或短语前面添加井号 (#) 。# 的数量代表了标题的级别。例如，添加三个 # 表示创建一个三级标题 (\u0026lt;h3\u0026gt;) (例如：### My Header)。\nMarkdown语法 HTML 预览效果 # Heading level 1 \u0026lt;h1\u0026gt;Heading level 1\u0026lt;/h1\u0026gt; Heading level 1 ## Heading level 2 \u0026lt;h2\u0026gt;Heading level 2\u0026lt;/h2\u0026gt; Heading level 2 ### Heading level 3 \u0026lt;h3\u0026gt;Heading level 3\u0026lt;/h3\u0026gt; Heading level 3 #### Heading level 4 \u0026lt;h4\u0026gt;Heading level 4\u0026lt;/h4\u0026gt; Heading level 4 ##### Heading level 5 \u0026lt;h5\u0026gt;Heading level 5\u0026lt;/h5\u0026gt; Heading level 5 ###### Heading level 6 \u0026lt;h6\u0026gt;Heading level 6\u0026lt;/h6\u0026gt; Heading level 6 可选语法 还可以在文本下方添加任意数量的 == 号来标识一级标题，或者 \u0026ndash; 号来标识二级标题。\nMarkdown语法 HTML 预览效果 Heading level 1=============== \u0026lt;h1\u0026gt;Heading level 1\u0026lt;/h1\u0026gt; Heading level 1 Heading level 2--------------- \u0026lt;h2\u0026gt;Heading level 2\u0026lt;/h2\u0026gt; Heading level 2 最佳实践 不同的 Markdown 应用程序处理 # 和标题之间的空格方式并不一致。为了兼容考虑，请用一个空格在 # 和标题之间进行分隔。\n✅ Do this ❌ Don\u0026rsquo;t do this # Here's a Heading #Here's a Heading Markdown 段落 要创建段落，请使用空白行将一行或多行文本进行分隔。\nMarkdown语法 HTML 预览效果 I really like using Markdown.I think I'll use it to format all of my documents from now on. \u0026lt;p\u0026gt;I really like using Markdown.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;I think I'll use it to format all of my documents from now on.\u0026lt;/p\u0026gt; I really like using Markdown.I think I\u0026rsquo;ll use it to format all of my documents from now on. 段落（Paragraph）用法的最佳实 不要用空格（spaces）或制表符（ tabs）缩进段落。\n✅ Do this ❌ Don\u0026rsquo;t do this Don't put tabs or spaces in front of your paragraphs.Keep lines left-aligned like this. This can result in unexpected formatting problems. Don't add tabs or spaces in front of paragraphs. Markdown 换行语法 在一行的末尾添加两个或多个空格，然后按回车键,即可创建一个换行(\u0026lt;br\u0026gt;)。\nMarkdown语法 HTML 预览效果 This is the first line. And this is the second line. \u0026lt;p\u0026gt;This is the first line.\u0026lt;br\u0026gt;And this is the second line.\u0026lt;/p\u0026gt; This is the first line. And this is the second line. 换行（Line Break）用法的最佳实践 几乎每个 Markdown 应用程序都支持两个或多个空格进行换行，称为 结尾空格（trailing whitespace) 的方式，但这是有争议的，因为很难在编辑器中直接看到空格，并且很多人在每个句子后面都会有意或无意地添加两个空格。由于这个原因，你可能要使用除结尾空格以外的其它方式来换行。幸运的是，几乎每个 Markdown 应用程序都支持另一种换行方式：HTML 的 \u0026lt;br\u0026gt; 标签。\n为了兼容性，请在行尾添加“结尾空格”或 HTML 的 \u0026lt;br\u0026gt; 标签来实现换行。\n还有两种其他方式我并不推荐使用。CommonMark 和其它几种轻量级标记语言支持在行尾添加反斜杠 (\\) 的方式实现换行，但是并非所有 Markdown 应用程序都支持此种方式，因此从兼容性的角度来看，不推荐使用。并且至少有两种轻量级标记语言支持无须在行尾添加任何内容，只须键入回车键（return）即可实现换行。\n✅ Do this ❌ Don\u0026rsquo;t do this First line with two spaces after. And the next line.First line with the HTML tag after.\u0026lt;br\u0026gt;And the next line. First line with a backslash after.\\And the next line.First line with nothing after.And the next line. Markdown 强调语法 通过将文本设置为粗体或斜体来强调其重要性。\n粗体（Bold） 要加粗文本，请在单词或短语的前后各添加两个星号（asterisks）或下划线（underscores）。如需加粗一个单词或短语的中间部分用以表示强调的话，请在要加粗部分的两侧各添加两个星号（asterisks）。\nMarkdown语法 HTML 预览效果 I just love **bold text**. I just love \u0026lt;strong\u0026gt;bold text\u0026lt;/strong\u0026gt;. I just love bold text. I just love __bold text__. I just love \u0026lt;strong\u0026gt;bold text\u0026lt;/strong\u0026gt;. I just love bold text. Love**is**bold Love\u0026lt;strong\u0026gt;is\u0026lt;/strong\u0026gt;bold Loveisbold 粗体（Bold）用法最佳实践 Markdown 应用程序在如何处理单词或短语中间的下划线上并不一致。为兼容考虑，在单词或短语中间部分加粗的话，请使用星号（asterisks）。\n✅ Do this ❌ Don\u0026rsquo;t do this Love**is**bold Love__is__bold 斜体（Italic） 要用斜体显示文本，请在单词或短语前后添加一个星号（asterisk）或下划线（underscore）。要斜体突出单词的中间部分，请在字母前后各添加一个星号，中间不要带空格。\nMarkdown语法 HTML 预览效果 Italicized text is the *cat's meow*. Italicized text is the \u0026lt;em\u0026gt;cat's meow\u0026lt;/em\u0026gt;. Italicized text is the cat’s meow. Italicized text is the _cat's meow_. Italicized text is the \u0026lt;em\u0026gt;cat's meow\u0026lt;/em\u0026gt;. Italicized text is the cat’s meow. A*cat*meow A\u0026lt;em\u0026gt;cat\u0026lt;/em\u0026gt;meow Acatmeow 斜体（Italic）用法的最佳实践 要同时用粗体和斜体突出显示文本，请在单词或短语的前后各添加三个星号或下划线。要加粗并用斜体显示单词或短语的中间部分，请在要突出显示的部分前后各添加三个星号，中间不要带空格。\n✅ Do this ❌ Don\u0026rsquo;t do this A*cat*meow A_cat_meow 粗体（Bold）和斜体（Italic） 要同时用粗体和斜体突出显示文本，请在单词或短语的前后各添加三个星号或下划线。要加粗并用斜体显示单词或短语的中间部分，请在要突出显示的部分前后各添加三个星号，中间不要带空格。\nMarkdown语法 HTML 预览效果 This text is ***really important***. This text is \u0026lt;strong\u0026gt;\u0026lt;em\u0026gt;really important\u0026lt;/em\u0026gt;\u0026lt;/strong\u0026gt;. This text is *really important*. This text is ___really important___. This text is \u0026lt;strong\u0026gt;\u0026lt;em\u0026gt;really important\u0026lt;/em\u0026gt;\u0026lt;/strong\u0026gt;. This text is *really important*. This text is __*really important*__. This text is \u0026lt;strong\u0026gt;\u0026lt;em\u0026gt;really important\u0026lt;/em\u0026gt;\u0026lt;/strong\u0026gt;. This text is *really important*. This text is **_really important_**. This text is \u0026lt;strong\u0026gt;\u0026lt;em\u0026gt;really important\u0026lt;/em\u0026gt;\u0026lt;/strong\u0026gt;. This text is *really important*. This is really***very***important text. This is really\u0026lt;strong\u0026gt;\u0026lt;em\u0026gt;very\u0026lt;/em\u0026gt;\u0026lt;/strong\u0026gt;important text. This is really***very***important text. 粗体（Bold）和斜体（Italic）用法的最佳实践 Markdown 应用程序在处理单词或短语中间添加的下划线上并不一致。为了实现兼容性，请使用星号将单词或短语的中间部分加粗并以斜体显示，以示重要。\n✅ Do this ❌ Don\u0026rsquo;t do this This is really***very***important text. This is really___very___important text. Markdown 引用语法 要创建块引用，请在段落前添加一个 \u0026gt; 符号。\n1 \u0026gt; Dorothy followed her through many of the beautiful rooms in her castle. 渲染效果如下所示：\nDorothy followed her through many of the beautiful rooms in her castle.\n多个段落的块引用\n块引用可以包含多个段落。为段落之间的空白行添加一个 \u0026gt; 符号。\n1 2 3 \u0026gt; Dorothy followed her through many of the beautiful rooms in her castle. \u0026gt; \u0026gt; The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. 渲染效果如下：\nDorothy followed her through many of the beautiful rooms in her castle.\nThe Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood.\n嵌套块引用\n块引用可以嵌套。在要嵌套的段落前添加一个 \u0026gt;\u0026gt; 符号。\n1 2 3 \u0026gt; Dorothy followed her through many of the beautiful rooms in her castle. \u0026gt; \u0026gt;\u0026gt; The Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood. 渲染效果如下：\nDorothy followed her through many of the beautiful rooms in her castle.\nThe Witch bade her clean the pots and kettles and sweep the floor and keep the fire fed with wood.\n带有其它元素的块引用\n块引用可以包含其他 Markdown 格式的元素。并非所有元素都可以使用，你需要进行实验以查看哪些元素有效。\n1 2 3 4 5 6 \u0026gt; #### The quarterly results look great! \u0026gt; \u0026gt; - Revenue was off the chart. \u0026gt; - Profits were higher than ever. \u0026gt; \u0026gt; *Everything* is going according to **plan**. 渲染效果如下：\nThe quarterly results look great! Revenue was off the chart. Profits were higher than ever. Everything is going according to plan.\nMarkdown 列表语法 可以将多个条目组织成有序或无序列表。\n有序列表 要创建有序列表，请在每个列表项前添加数字并紧跟一个英文句点。数字不必按数学顺序排列，但是列表应当以数字 1 起始。\nMarkdown语法 HTML 预览效果 1. First item2. Second item3. Third item4. Fourth item \u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;First item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Second item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Third item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Fourth item\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt; First itemSecond itemThird itemFourth item 1. First item1. Second item1. Third item1. Fourth item \u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;First item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Second item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Third item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Fourth item\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt; First itemSecond itemThird itemFourth item 1. First item8. Second item3. Third item5. Fourth item \u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;First item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Second item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Third item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Fourth item\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt; First itemSecond itemThird itemFourth item 1. First item2. Second item3. Third item 1. Indented item 2. Indented item4. Fourth item \u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;First item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Second item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Third item\u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;Indented item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Indented item\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Fourth item\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt; First itemSecond itemThird itemIndented itemIndented itemFourth item 有序列表最佳实践 CommonMark and a few other lightweight markup languages let you use a parenthesis ()) as a delimiter (e.g., 1) First item), but not all Markdown applications support this, so it isn’t a great option from a compatibility perspective. For compatibility, use periods only.\n✅ Do this ❌ Don\u0026rsquo;t do this 1. First item2. Second item 1) First item2) Second item 无序列表 要创建无序列表，请在每个列表项前面添加破折号 (-)、星号 (*) 或加号 (+) 。缩进一个或多个列表项可创建嵌套列表。\nMarkdown语法 HTML 预览效果 - First item- Second item- Third item- Fourth item \u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;First item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Second item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Third item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Fourth item\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt; First itemSecond itemThird itemFourth item * First item* Second item* Third item* Fourth item \u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;First item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Second item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Third item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Fourth item\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt; First itemSecond itemThird itemFourth item + First item+ Second item+ Third item+ Fourth item \u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;First item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Second item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Third item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Fourth item\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt; First itemSecond itemThird itemFourth item - First item- Second item- Third item - Indented item - Indented item- Fourth item \u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;First item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Second item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Third item\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;Indented item\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Indented item\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Fourth item\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt; First itemSecond itemThird itemIndented itemIndented itemFourth item 无序列表最佳实践 Markdown applications don’t agree on how to handle different delimiters in the same list. For compatibility, don\u0026rsquo;t mix and match delimiters in the same list — pick one and stick with it.\n✅ Do this ❌ Don\u0026rsquo;t do this - First item- Second item- Third item- Fourth item + First item* Second item- Third item+ Fourth item 在列表中嵌套其他元素 要在保留列表连续性的同时在列表中添加另一种元素，请将该元素缩进四个空格或一个制表符，如下例所示：\n段落 1 2 3 4 5 6 * This is the first list item. * Here\u0026#39;s the second list item. I need to add another paragraph below the second list item. * And here\u0026#39;s the third list item. 渲染效果如下：\nThis is the first list item.\nHere\u0026rsquo;s the second list item.\nI need to add another paragraph below the second list item.\nAnd here\u0026rsquo;s the third list item.\n引用块 1 2 3 4 5 6 * This is the first list item. * Here\u0026#39;s the second list item. \u0026gt; A blockquote would look great below the second list item. * And here\u0026#39;s the third list item. 渲染效果如下：\nThis is the first list item.\nHere\u0026rsquo;s the second list item.\nA blockquote would look great below the second list item.\nAnd here\u0026rsquo;s the third list item.\n代码块 代码块通常采用四个空格或一个制表符缩进。当它们被放在列表中时，请将它们缩进八个空格或两个制表符。\n1 2 3 4 5 6 7 8 9 1. Open the file. 2. Find the following code block on line 21: \u0026amp;lt;html\u0026gt; \u0026amp;lt;head\u0026gt; \u0026amp;lt;title\u0026gt;Test\u0026amp;lt;/title\u0026gt; \u0026amp;lt;/head\u0026gt; 3. Update the title to match the name of your website. 渲染效果如下：\nOpen the file.\nFind the following code block on line 21:\n1 2 3 4 \u0026amp;lt;html\u0026gt; \u0026amp;lt;head\u0026gt; \u0026amp;lt;title\u0026gt;Test\u0026amp;lt;/title\u0026gt; \u0026amp;lt;/head\u0026gt; Update the title to match the name of your website.\n图片 1 2 3 4 5 6 1. Open the file containing the Linux mascot. 2. Marvel at its beauty. ![Tux, the Linux mascot](/assets/images/tux.png) 3. Close the file. 渲染效果如下：\nOpen the file containing the Linux mascot.\nMarvel at its beauty.\nClose the file.\n列表 You can nest an unordered list in an ordered list, or vice versa.\n1 2 3 4 5 6 1. First item 2. Second item 3. Third item - Indented item - Indented item 4. Fourth item 渲染效果如下：\nFirst item Second item Third item Indented item Indented item Fourth item Markdown 代码语法 要将单词或短语表示为代码，请将其包裹在反引号 (```) 中。\nMarkdown语法 HTML 预览效果 At the command prompt, type nano. At the command prompt, type \u0026lt;code\u0026gt;nano\u0026lt;/code\u0026gt;. At the command prompt, type nano. 转义反引号 如果你要表示为代码的单词或短语中包含一个或多个反引号，则可以通过将单词或短语包裹在双反引号(````)中。\nMarkdown语法 HTML 预览效果 Use `code` in your Markdown file. \u0026lt;code\u0026gt;Use code in your Markdown file.\u0026lt;/code\u0026gt; Use code in your Markdown file. 代码块 要创建代码块，请将代码块的每一行缩进至少四个空格或一个制表符。\n1 2 3 4 \u0026amp;lt;html\u0026gt; \u0026amp;lt;head\u0026gt; \u0026amp;lt;/head\u0026gt; \u0026amp;lt;/html\u0026gt; 渲染效果如下：\n1 2 3 4 \u0026amp;lt;html\u0026gt; \u0026amp;lt;head\u0026gt; \u0026amp;lt;/head\u0026gt; \u0026amp;lt;/html\u0026gt; Note: 要创建不用缩进的代码块，请使用 围栏式代码块（fenced code blocks）.\nMarkdown 分隔线语法 要创建分隔线，请在单独一行上使用三个或多个星号 (***)、破折号 (---) 或下划线 (___) ，并且不能包含其他内容。\n1 2 3 4 5 *** --- _________________ 以上三个分隔线的渲染效果看起来都一样：\n分隔线（Horizontal Rule）用法最佳实践 为了兼容性，请在分隔线的前后均添加空白行。\n✅ Do this ❌ Don\u0026rsquo;t do this Try to put a blank line before...---...and after a horizontal rule. Without blank lines, this would be a heading.---Don't do this! Markdown 链接语法 链接文本放在中括号内，链接地址放在后面的括号中，链接title可选。\n超链接Markdown语法代码：[超链接显示名](超链接地址 \u0026quot;超链接title\u0026quot;)\n对应的HTML代码：\u0026lt;a href=\u0026quot;超链接地址\u0026quot; title=\u0026quot;超链接title\u0026quot;\u0026gt;超链接显示名\u0026lt;/a\u0026gt;\n1 这是一个链接 [Markdown语法](https://markdown.com.cn)。 渲染效果如下：\n这是一个链接 Markdown语法 (opens new window)。\n给链接增加 Title 链接title是当鼠标悬停在链接上时会出现的文字，这个title是可选的，它放在圆括号中链接地址后面，跟链接地址之间以空格分隔。\n1 这是一个链接 [Markdown语法](https://markdown.com.cn \u0026#34;最好的markdown教程\u0026#34;)。 渲染效果如下：\n这是一个链接 Markdown语法 (opens new window)。\n网址和Email地址 使用尖括号可以很方便地把URL或者email地址变成可点击的链接。\n1 2 \u0026lt;https://markdown.com.cn\u0026gt; \u0026lt;fake@example.com\u0026gt; 渲染效果如下：\nhttps://markdown.com.cn(opens new window) fake@example.com\n带格式化的链接 强调 链接, 在链接语法前后增加星号。 要将链接表示为代码，请在方括号中添加反引号。\n1 2 3 I love supporting the **[EFF](https://eff.org)**. This is the *[Markdown Guide](https://www.markdownguide.org)*. See the section on [`code`](#code). 渲染效果如下：\nI love supporting the EFF (opens new window). This is the Markdown Guide (opens new window). See the section on code.\n引用类型链接 引用样式链接是一种特殊的链接，它使URL在Markdown中更易于显示和阅读。参考样式链接分为两部分：与文本保持内联的部分以及存储在文件中其他位置的部分，以使文本易于阅读。\n链接的第一部分格式 引用类型的链接的第一部分使用两组括号进行格式设置。第一组方括号包围应显示为链接的文本。第二组括号显示了一个标签，该标签用于指向您存储在文档其他位置的链接。\n尽管不是必需的，可以在第一组和第二组括号之间包含一个空格。第二组括号中的标签不区分大小写，可以包含字母，数字，空格或标点符号。\n以下示例格式对于链接的第一部分效果相同：\n[hobbit-hole][1] [hobbit-hole] [1] 链接的第二部分格式 引用类型链接的第二部分使用以下属性设置格式：\n放在括号中的标签，其后紧跟一个冒号和至少一个空格（例如[label]:）。 链接的URL，可以选择将其括在尖括号中。 链接的可选标题，可以将其括在双引号，单引号或括号中。 以下示例格式对于链接的第二部分效果相同：\n[1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle \u0026quot;Hobbit lifestyles\u0026quot; [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle 'Hobbit lifestyles' [1]: https://en.wikipedia.org/wiki/Hobbit#Lifestyle (Hobbit lifestyles) [1]: \u0026lt;https://en.wikipedia.org/wiki/Hobbit#Lifestyle\u0026gt; \u0026quot;Hobbit lifestyles\u0026quot; [1]: \u0026lt;https://en.wikipedia.org/wiki/Hobbit#Lifestyle\u0026gt; 'Hobbit lifestyles' [1]: \u0026lt;https://en.wikipedia.org/wiki/Hobbit#Lifestyle\u0026gt; (Hobbit lifestyles) 可以将链接的第二部分放在Markdown文档中的任何位置。有些人将它们放在出现的段落之后，有些人则将它们放在文档的末尾（例如尾注或脚注）。\n链接最佳实践 不同的 Markdown 应用程序处理URL中间的空格方式不一样。为了兼容性，请尽量使用%20代替空格。\n✅ Do this ❌ Don\u0026rsquo;t do this [link](https://www.example.com/my%20great%20page) [link](https://www.example.com/my great page) Markdown 图片语法 要添加图像，请使用感叹号 (!), 然后在方括号增加替代文本，图片链接放在圆括号里，括号里的链接后可以增加一个可选的图片标题文本。\n插入图片Markdown语法代码：![图片alt](图片链接 \u0026quot;图片title\u0026quot;)。\n对应的HTML代码：\u0026lt;img src=\u0026quot;图片链接\u0026quot; alt=\u0026quot;图片alt\u0026quot; title=\u0026quot;图片title\u0026quot;\u0026gt;\n1 ![这是图片](/assets/img/philly-magic-garden.jpg \u0026#34;Magic Gardens\u0026#34;) 渲染效果如下：\n链接图片 给图片增加链接，请将图像的Markdown 括在方括号中，然后将链接添加在圆括号中。\n1 [![沙漠中的岩石图片](/assets/img/shiprock.jpg \u0026#34;Shiprock\u0026#34;)](https://markdown.com.cn) 渲染效果如下：\nMarkdown 转义字符语法 要显示原本用于格式化 Markdown 文档的字符，请在字符前面添加反斜杠字符 \\ 。\n1 \\* Without the backslash, this would be a bullet in an unordered list. 渲染效果如下：\n* Without the backslash, this would be a bullet in an unordered list.\n可做转义的字符 以下列出的字符都可以通过使用反斜杠字符从而达到转义目的。\nCharacter Name \\ backslash ` backtick (see also escaping backticks in code) * asterisk _ underscore { } curly braces [ ] brackets ( ) parentheses # pound sign + plus sign - minus sign (hyphen) . dot ! exclamation mark | pipe (see also escaping pipe in tables) 特殊字符自动转义 在 HTML 文件中，有两个字符需要特殊处理： \u0026lt; 和 \u0026amp; 。 \u0026lt; 符号用于起始标签，\u0026amp; 符号则用于标记 HTML 实体，如果你只是想要使用这些符号，你必须要使用实体的形式，像是 \u0026lt; 和 \u0026amp;。\n\u0026amp; 符号其实很容易让写作网页文件的人感到困扰，如果你要打「AT\u0026amp;T」 ，你必须要写成「AT\u0026amp;T」 ，还得转换网址内的 \u0026amp; 符号，如果你要链接到：\n1 http://images.google.com/images?num=30\u0026amp;q=larry+bird 你必须要把网址转成：\n1 http://images.google.com/images?num=30\u0026amp;amp;q=larry+bird 才能放到链接标签的 href 属性里。不用说也知道这很容易忘记，这也可能是 HTML 标准检查所检查到的错误中，数量最多的。\nMarkdown 允许你直接使用这些符号，它帮你自动转义字符。如果你使用 \u0026amp; 符号的作为 HTML 实体的一部分，那么它不会被转换，而在其它情况下，它则会被转换成 \u0026amp;。所以你如果要在文件中插入一个著作权的符号，你可以这样写：\n1 \u0026amp;copy; Markdown 将不会对这段文字做修改，但是如果你这样写：\n1 AT\u0026amp;T Markdown 就会将它转为：\n1 AT\u0026amp;amp;T 类似的状况也会发生在 \u0026lt; 符号上，因为 Markdown 支持 行内 HTML ，如果你使用 \u0026lt; 符号作为 HTML 标签的分隔符，那 Markdown 也不会对它做任何转换，但是如果你是写：\n1 4 \u0026lt; 5 Markdown 将会把它转换为：\n1 4 \u0026amp;lt; 5 需要特别注意的是，在 Markdown 的块级元素和内联元素中， \u0026lt; 和 \u0026amp; 两个符号都会被自动转换成 HTML 实体，这项特性让你可以很容易地用 Markdown 写 HTML。（在 HTML 语法中，你要手动把所有的 \u0026lt; 和 \u0026amp; 都转换为 HTML 实体。）\nMarkdown 内嵌 HTML 标签 对于 Markdown 涵盖范围之外的标签，都可以直接在文件里面用 HTML 本身。如需使用 HTML，不需要额外标注这是 HTML 或是 Markdown，只需 HTML 标签添加到 Markdown 文本中即可。\n行级內联标签 HTML 的行级內联标签如 \u0026lt;span\u0026gt;、\u0026lt;cite\u0026gt;、\u0026lt;del\u0026gt; 不受限制，可以在 Markdown 的段落、列表或是标题里任意使用。依照个人习惯，甚至可以不用 Markdown 格式，而采用 HTML 标签来格式化。例如：如果比较喜欢 HTML 的 \u0026lt;a\u0026gt; 或 \u0026lt;img\u0026gt; 标签，可以直接使用这些标签，而不用 Markdown 提供的链接或是图片语法。当你需要更改元素的属性时（例如为文本指定颜色或更改图像的宽度），使用 HTML 标签更方便些。\nHTML 行级內联标签和区块标签不同，在內联标签的范围内， Markdown 的语法是可以解析的。\n1 This **word** is bold. This \u0026lt;em\u0026gt;word\u0026lt;/em\u0026gt; is italic. 渲染效果如下:\nThis word is bold. This word is italic.\n区块标签 区块元素──比如 \u0026lt;div\u0026gt;、\u0026lt;table\u0026gt;、\u0026lt;pre\u0026gt;、\u0026lt;p\u0026gt; 等标签，必须在前后加上空行，以便于内容区分。而且这些元素的开始与结尾标签，不可以用 tab 或是空白来缩进。Markdown 会自动识别这区块元素，避免在区块标签前后加上没有必要的 \u0026lt;p\u0026gt; 标签。\n例如，在 Markdown 文件里加上一段 HTML 表格：\n1 2 3 4 5 6 7 8 9 This is a regular paragraph. \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Foo\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; This is another regular paragraph. 请注意，Markdown 语法在 HTML 区块标签中将不会被进行处理。例如，你无法在 HTML 区块内使用 Markdown 形式的*强调*。\nHTML 用法最佳实践 出于安全原因，并非所有 Markdown 应用程序都支持在 Markdown 文档中添加 HTML。如有疑问，请查看相应 Markdown 应用程序的手册。某些应用程序只支持 HTML 标签的子集。\n对于 HTML 的块级元素 \u0026lt;div\u0026gt;、\u0026lt;table\u0026gt;、\u0026lt;pre\u0026gt; 和 \u0026lt;p\u0026gt;，请在其前后使用空行（blank lines）与其它内容进行分隔。尽量不要使用制表符（tabs）或空格（spaces）对 HTML 标签做缩进，否则将影响格式。\n在 HTML 块级标签内不能使用 Markdown 语法。例如 \u0026lt;p\u0026gt;italic and **bold**\u0026lt;/p\u0026gt; 将不起作用。\n","date":"2024-05-11T00:00:00Z","image":"https://nova-bryan.github.io/p/markdown_grammar/mark_hu8927113685150964021.png","permalink":"https://nova-bryan.github.io/p/markdown_grammar/","title":"Markdown_Grammar"},{"content":"求整数的因子（也称为 约数）可以使用 从 1 到 √N 迭代的方法，这样可以大幅减少计算次数，从 O(N) 优化到 O(√N)，大幅提升速度。\n1. O(√N) 高效因子枚举 原理：\n如果 x 是 N 的因子，则 N/x 也是 N 的因子，只需要遍历 1 到 √N 即可找到所有因子。 代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import java.util.*; public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); int n = sc.nextInt(); // 读取整数 N sc.close(); List\u0026lt;Integer\u0026gt; factors = new ArrayList\u0026lt;\u0026gt;(); for (int i = 1; i * i \u0026lt;= n; i++) { if (n % i == 0) { factors.add(i); // i 是因子 if (i != n / i) { factors.add(n / i); // N / i 也是因子 } } } // 因子排序（如果需要从小到大排列） Collections.sort(factors); System.out.println(factors); } } 示例：\n1 2 输入: 36 输出: [1, 2, 3, 4, 6, 9, 12, 18, 36] 时间复杂度：O(√N)，相比 O(N) 的暴力方法，速度快很多！\n2. 只判断因子个数（不存储） 如果你只想知道 因子个数，可以用计数器：\n1 2 3 4 5 6 7 8 int count = 0; for (int i = 1; i * i \u0026lt;= n; i++) { if (n % i == 0) { count++; if (i != n / i) count++; // 计数因子 } } System.out.println(count); 示例：\n1 2 输入: 36 输出: 9 // 因子个数 3. 特殊优化：只找素因子 如果你只想找 素数因子（即 N 被哪些素数整除），可以用试除法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public static List\u0026lt;Integer\u0026gt; primeFactors(int n) { List\u0026lt;Integer\u0026gt; primes = new ArrayList\u0026lt;\u0026gt;(); // 先除去 2 while (n % 2 == 0) { primes.add(2); n /= 2; } // 再检查奇数 for (int i = 3; i * i \u0026lt;= n; i += 2) { while (n % i == 0) { primes.add(i); n /= i; } } // 如果剩余的是素数 if (n \u0026gt; 1) primes.add(n); return primes; } 示例：\n1 2 输入: 36 输出: [2, 2, 3, 3] // 36 = 2² × 3² 时间复杂度：O(√N)，比 O(N) 方法快很多。\n总结 方法 适用场景 复杂度 备注 O(√N) 遍历因子 找出所有因子 O(√N) 推荐 O(√N) 计数因子 只求因子个数 O(√N) 无需存储 试除法找素因子 仅找素因子 O(√N) 用于分解质因数 如果只是找因子，推荐 O(√N) 方法，速度快，代码简洁！ 🚀\n例题： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 import java.util.*; public class Main { public static void main(String[] args) { Scanner sc = new Scanner(System.in); long n = sc.nextLong(); // 读取 N，注意这里用 long，防止溢出 sc.close(); int maxLen = 0; // 记录最长长度 int start = 0; // 记录最长序列的起始因子 // 遍历起始因子 i，从 2 开始（1 不算） for (int i = 2; i * i \u0026lt;= n; i++) { long product = 1; int j = i; // 计算连续乘积，直到超出 N while (product * j \u0026lt;= n) { product *= j; // 如果这个连续乘积刚好整除 N if (n % product == 0) { int length = j - i + 1; // 计算当前序列的长度 if (length \u0026gt; maxLen) { maxLen = length; start = i; } } j++; // 继续尝试下一个连续因子 } } // 如果没有找到合适的连续因子，最长序列就是 N 本身 if (maxLen == 0) { System.out.println(1); System.out.println(n); } else { System.out.println(maxLen); for (int i = 0; i \u0026lt; maxLen; i++) { if (i \u0026gt; 0) System.out.print(\u0026#34;*\u0026#34;); System.out.print(start + i); } } } } ","date":"2024-05-11T00:00:00Z","image":"https://nova-bryan.github.io/p/%E6%95%B4%E6%95%B0%E5%9B%A0%E5%AD%90%E7%9A%84%E5%BF%AB%E9%80%9F%E6%B1%82%E6%B3%95/image_hu7343995253115549451.png","permalink":"https://nova-bryan.github.io/p/%E6%95%B4%E6%95%B0%E5%9B%A0%E5%AD%90%E7%9A%84%E5%BF%AB%E9%80%9F%E6%B1%82%E6%B3%95/","title":"整数因子的快速求法"},{"content":"MySQL-DQL-基本查询 介绍\nDQL英文全称是Data Query Language(数据查询语言)，用来查询数据库表中的记录。\n查询关键字：SELECT\n查询操作是所有SQL语句当中最为常见，也是最为重要的操作。在一个正常的业务系统中，查询操作的使用频次是要远高于增删改操作的。当我们打开某个网站或APP所看到的展示信息，都是通过从数据库中查询得到的，而在这个查询过程中，还会涉及到条件、排序、分页等操作。\n语法\nDQL查询语句，语法结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 SELECT 字段列表 FROM 表名列表 WHERE 条件列表 GROUP BY 分组字段列表 HAVING 分组后条件列表 ORDER BY 排序字段列表 LIMIT 分页参数 我们今天会将上面的完整语法拆分为以下几个部分学习：\n基本查询（不带任何条件） 条件查询（where） 分组查询（group by） 排序查询（order by） 分页查询（limit） 准备一些测试数据用于查询操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 create database db02; -- 创建数据库 use db02; -- 切换数据库 -- 员工管理(带约束) create table tb_emp ( id int unsigned primary key auto_increment comment \u0026#39;ID\u0026#39;, username varchar(20) not null unique comment \u0026#39;用户名\u0026#39;, password varchar(32) default \u0026#39;123456\u0026#39; comment \u0026#39;密码\u0026#39;, name varchar(10) not null comment \u0026#39;姓名\u0026#39;, gender tinyint unsigned not null comment \u0026#39;性别, 说明: 1 男, 2 女\u0026#39;, image varchar(300) comment \u0026#39;图像\u0026#39;, job tinyint unsigned comment \u0026#39;职位, 说明: 1 班主任,2 讲师, 3 学工主管, 4 教研主管\u0026#39;, entrydate date comment \u0026#39;入职时间\u0026#39;, create_time datetime not null comment \u0026#39;创建时间\u0026#39;, update_time datetime not null comment \u0026#39;修改时间\u0026#39; ) comment \u0026#39;员工表\u0026#39;; -- 准备测试数据 INSERT INTO tb_emp (id, username, password, name, gender, image, job, entrydate, create_time, update_time) VALUES (1, \u0026#39;jinyong\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;金庸\u0026#39;, 1, \u0026#39;1.jpg\u0026#39;, 4, \u0026#39;2000-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:35\u0026#39;), (2, \u0026#39;zhangwuji\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张无忌\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2015-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:37\u0026#39;), (3, \u0026#39;yangxiao\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;杨逍\u0026#39;, 1, \u0026#39;3.jpg\u0026#39;, 2, \u0026#39;2008-05-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:39\u0026#39;), (4, \u0026#39;weiyixiao\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;韦一笑\u0026#39;, 1, \u0026#39;4.jpg\u0026#39;, 2, \u0026#39;2007-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:41\u0026#39;), (5, \u0026#39;changyuchun\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;常遇春\u0026#39;, 1, \u0026#39;5.jpg\u0026#39;, 2, \u0026#39;2012-12-05\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:43\u0026#39;), (6, \u0026#39;xiaozhao\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;小昭\u0026#39;, 2, \u0026#39;6.jpg\u0026#39;, 3, \u0026#39;2013-09-05\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:45\u0026#39;), (7, \u0026#39;jixiaofu\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;纪晓芙\u0026#39;, 2, \u0026#39;7.jpg\u0026#39;, 1, \u0026#39;2005-08-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:47\u0026#39;), (8, \u0026#39;zhouzhiruo\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;周芷若\u0026#39;, 2, \u0026#39;8.jpg\u0026#39;, 1, \u0026#39;2014-11-09\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:49\u0026#39;), (9, \u0026#39;dingminjun\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;丁敏君\u0026#39;, 2, \u0026#39;9.jpg\u0026#39;, 1, \u0026#39;2011-03-11\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:51\u0026#39;), (10, \u0026#39;zhaomin\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;赵敏\u0026#39;, 2, \u0026#39;10.jpg\u0026#39;, 1, \u0026#39;2013-09-05\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:53\u0026#39;), (11, \u0026#39;luzhangke\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;鹿杖客\u0026#39;, 1, \u0026#39;11.jpg\u0026#39;, 2, \u0026#39;2007-02-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:55\u0026#39;), (12, \u0026#39;hebiweng\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;鹤笔翁\u0026#39;, 1, \u0026#39;12.jpg\u0026#39;, 2, \u0026#39;2008-08-18\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:57\u0026#39;), (13, \u0026#39;fangdongbai\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;方东白\u0026#39;, 1, \u0026#39;13.jpg\u0026#39;, 1, \u0026#39;2012-11-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:35:59\u0026#39;), (14, \u0026#39;zhangsanfeng\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张三丰\u0026#39;, 1, \u0026#39;14.jpg\u0026#39;, 2, \u0026#39;2002-08-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:01\u0026#39;), (15, \u0026#39;yulianzhou\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;俞莲舟\u0026#39;, 1, \u0026#39;15.jpg\u0026#39;, 2, \u0026#39;2011-05-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:03\u0026#39;), (16, \u0026#39;songyuanqiao\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;宋远桥\u0026#39;, 1, \u0026#39;16.jpg\u0026#39;, 2, \u0026#39;2010-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:05\u0026#39;), (17, \u0026#39;chenyouliang\u0026#39;, \u0026#39;12345678\u0026#39;, \u0026#39;陈友谅\u0026#39;, 1, \u0026#39;17.jpg\u0026#39;, null, \u0026#39;2015-03-21\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:07\u0026#39;), (18, \u0026#39;zhang1\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张一\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2015-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:09\u0026#39;), (19, \u0026#39;zhang2\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张二\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2012-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:11\u0026#39;), (20, \u0026#39;zhang3\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张三\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2018-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:13\u0026#39;), (21, \u0026#39;zhang4\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张四\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2015-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:15\u0026#39;), (22, \u0026#39;zhang5\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张五\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2016-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:17\u0026#39;), (23, \u0026#39;zhang6\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张六\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2012-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:19\u0026#39;), (24, \u0026#39;zhang7\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张七\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2006-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:21\u0026#39;), (25, \u0026#39;zhang8\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张八\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2002-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:23\u0026#39;), (26, \u0026#39;zhang9\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张九\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2011-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:25\u0026#39;), (27, \u0026#39;zhang10\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张十\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2004-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:27\u0026#39;), (28, \u0026#39;zhang11\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张十一\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2007-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:29\u0026#39;), (29, \u0026#39;zhang12\u0026#39;, \u0026#39;123456\u0026#39;, \u0026#39;张十二\u0026#39;, 1, \u0026#39;2.jpg\u0026#39;, 2, \u0026#39;2020-01-01\u0026#39;, \u0026#39;2022-10-27 16:35:33\u0026#39;, \u0026#39;2022-10-27 16:36:31\u0026#39;); 基本查询\n在基本查询的DQL语句中，不带任何的查询条件，语法如下：\n查询多个字段 1 select 字段1, 字段2, 字段3 from 表名; 查询所有字段（通配符） 1 select * from 表名; 设置别名 1 select 字段1 [ as 别名1 ] , 字段2 [ as 别名2 ] from 表名; 去除重复记录 1 select distinct 字段列表 from 表名; 案例1：查询指定字段 name，entrydate并返回\n1 select name,entrydate from tb_emp; 案例2：查询返回所有字段\n1 select * from tb_emp; *号代表查询所有字段，在实际开发中尽量少用（不直观、影响效率）\n案例3：查询所有员工的 name,entrydate，并起别名(姓名、入职日期)\n1 2 3 4 5 6 -- 方式1： select name AS 姓名, entrydate AS 入职日期 from tb_emp; -- 方式2： 别名中有特殊字符时，使用\u0026#39;\u0026#39;或\u0026#34;\u0026#34;包含 select name AS \u0026#39;姓 名\u0026#39;, entrydate AS \u0026#39;入职日期\u0026#39; from tb_emp; -- 方式3： select name AS \u0026#34;姓名\u0026#34;, entrydate AS \u0026#34;入职日期\u0026#34; from tb_emp; 案例4：查询已有的员工关联了哪几种职位(不要重复)\n1 select distinct job from tb_emp; MySQL-DQL-条件查询 条件查询\n语法：\n1 select 字段列表 from 表名 where 条件列表 ; -- 条件列表：意味着可以有多个条件 学习条件查询就是学习条件的构建方式，而在SQL语句当中构造条件的运算符分为两类：\n比较运算符 逻辑运算符 常用的比较运算符如下:\n比较运算符 功能 \u0026gt; 大于 \u0026gt;= 大于等于 \u0026lt; 小于 \u0026lt;= 小于等于 = 等于 \u0026lt;\u0026gt; 或 != 不等于 between \u0026hellip; and \u0026hellip; 在某个范围之内(含最小、最大值) in(\u0026hellip;) 在in之后的列表中的值，多选一 like 占位符 模糊匹配(_匹配单个字符, %匹配任意个字符) is null 是null 常用的逻辑运算符如下:\n逻辑运算符 功能 and 或 \u0026amp;\u0026amp; 并且 (多个条件同时成立) or 或 || 或者 (多个条件任意一个成立) not 或 ! 非 , 不是 案例1：查询 姓名 为 杨逍 的员工\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where name = \u0026#39;杨逍\u0026#39;; -- 字符串使用\u0026#39;\u0026#39;或\u0026#34;\u0026#34;包含 案例2：查询 id小于等于5 的员工信息\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where id \u0026lt;=5; 案例3：查询 没有分配职位 的员工信息\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where job is null ; 注意：查询为NULL的数据时，不能使用 = null\n案例4：查询 有职位 的员工信息\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where job is not null ; 案例5：查询 密码不等于 \u0026lsquo;123456\u0026rsquo; 的员工信息\n1 2 3 4 5 6 7 8 -- 方式1： select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where password \u0026lt;\u0026gt; \u0026#39;123456\u0026#39;; -- 方式2： select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where password != \u0026#39;123456\u0026#39;; 案例6：查询 入职日期 在 \u0026lsquo;2000-01-01\u0026rsquo; (包含) 到 \u0026lsquo;2010-01-01\u0026rsquo;(包含) 之间的员工信息\n1 2 3 4 5 6 7 8 -- 方式1： select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where entrydate\u0026gt;=\u0026#39;2000-01-01\u0026#39; and entrydate\u0026lt;=\u0026#39;2010-01-01\u0026#39;; -- 方式2： between...and select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where entrydate between \u0026#39;2000-01-01\u0026#39; and \u0026#39;2010-01-01\u0026#39;; 案例7：查询 入职时间 在 \u0026lsquo;2000-01-01\u0026rsquo; (包含) 到 \u0026lsquo;2010-01-01\u0026rsquo;(包含) 之间 且 性别为女 的员工信息\n1 2 3 4 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where entrydate between \u0026#39;2000-01-01\u0026#39; and \u0026#39;2010-01-01\u0026#39; and gender = 2; 案例8：查询 职位是 2 (讲师), 3 (学工主管), 4 (教研主管) 的员工信息\n1 2 3 4 5 6 7 8 -- 方式1：使用or连接多个条件 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where job=2 or job=3 or job=4; -- 方式2：in关键字 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where job in (2,3,4); 案例9：查询 姓名 为两个字的员工信息\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where name like \u0026#39;__\u0026#39;; # 通配符 \u0026#34;_\u0026#34; 代表任意1个字符 案例10：查询 姓 \u0026lsquo;张\u0026rsquo; 的员工信息\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where name like \u0026#39;张%\u0026#39;; # 通配符 \u0026#34;%\u0026#34; 代表任意个字符（0个 ~ 多个） MySQL-DQL-聚合函数 之前我们做的查询都是横向查询，就是根据条件一行一行的进行判断，而使用聚合函数查询就是纵向查询，它是对一列的值进行计算，然后返回一个结果值。（将一列数据作为一个整体，进行纵向计算）\n语法：\n1 select 聚合函数(字段列表) from 表名 ; 注意 : 聚合函数会忽略空值，对NULL值不作为统计。\n常用聚合函数：\n函数 功能 count 统计数量 max 最大值 min 最小值 avg 平均值 sum 求和 count ：按照列去统计有多少行数据。\n在根据指定的列统计的时候，如果这一列中有null的行，该行不会被统计在其中。 sum ：计算指定列的数值和，如果不是数值类型，那么计算结果为0\nmax ：计算指定列的最大值\nmin ：计算指定列的最小值\navg ：计算指定列的平均值\n案例1：统计该企业员工数量\n1 2 3 4 5 6 7 8 9 10 # count(字段) select count(id) from tb_emp;-- 结果：29 select count(job) from tb_emp;-- 结果：28 （聚合函数对NULL值不做计算） # count(常量) select count(0) from tb_emp; select count(\u0026#39;A\u0026#39;) from tb_emp; # count(*) 推荐此写法（MySQL底层进行了优化） select count(*) from tb_emp; 案例2：统计该企业最早入职的员工\n1 select min(entrydate) from tb_emp; 案例3：统计该企业最迟入职的员工\n1 select max(entrydate) from tb_emp; 案例4：统计该企业员工 ID 的平均值\n1 select avg(id) from tb_emp; 案例5：统计该企业员工的 ID 之和\n1 select sum(id) from tb_emp; MySQL-DQL-分组查询 分组： 按照某一列或者某几列，把相同的数据进行合并输出。\n分组其实就是按列进行分类(指定列下相同的数据归为一类)，然后可以对分类完的数据进行合并计算。\n分组查询通常会使用聚合函数进行计算。\n语法：\n1 select 字段列表 from 表名 [where 条件] group by 分组字段名 [having 分组后过滤条件]; 案例1：根据性别分组 , 统计男性和女性员工的数量\n1 2 3 select gender, count(*) from tb_emp group by gender; -- 按照gender字段进行分组（gender字段下相同的数据归为一组） 案例2：查询入职时间在 \u0026lsquo;2015-01-01\u0026rsquo; (包含) 以前的员工 , 并对结果根据职位分组 , 获取员工数量大于等于2的职位\n1 2 3 4 5 select job, count(*) from tb_emp where entrydate \u0026lt;= \u0026#39;2015-01-01\u0026#39; -- 分组前条件 group by job -- 按照job字段分组 having count(*) \u0026gt;= 2; -- 分组后条件 注意事项:\n• 分组之后，查询的字段一般为聚合函数和分组字段，查询其他字段无任何意义\n• 执行顺序：where \u0026gt; 聚合函数 \u0026gt; having\nwhere与having区别（面试题）\n执行时机不同：where是分组之前进行过滤，不满足where条件，不参与分组；而having是分组之后对结果进行过滤。 判断条件不同：where不能对聚合函数进行判断，而having可以。 MySQL-DQL-排序查询 排序在日常开发中是非常常见的一个操作，有升序排序，也有降序排序。\n语法：\n1 2 3 4 5 select 字段列表 from 表名 [where 条件列表] [group by 分组字段 ] order by 字段1 排序方式1 , 字段2 排序方式2 … ; 排序方式：\nASC ：升序（默认值） DESC：降序 案例1：根据入职时间, 对员工进行升序排序\n1 2 3 4 5 6 7 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp order by entrydate ASC; -- 按照entrydate字段下的数据进行升序排序 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp order by entrydate; -- 默认就是ASC（升序） 注意事项：如果是升序, 可以不指定排序方式ASC\n案例2：根据入职时间，对员工进行降序排序\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp order by entrydate DESC; -- 按照entrydate字段下的数据进行降序排序 案例3：根据入职时间对公司的员工进行升序排序，入职时间相同，再按照更新时间进行降序排序\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp order by entrydate ASC , update_time DESC; 注意事项：如果是多字段排序，当第一个字段值相同时，才会根据第二个字段进行排序\nMySQL-DQL-分页查询 分页操作在业务系统开发时，也是非常常见的一个功能，日常我们在网站中看到的各种各样的分页条，后台也都需要借助于数据库的分页操作。\n分页查询语法：\n1 select 字段列表 from 表名 limit 起始索引, 查询记录数 ; 案例1：从起始索引0开始查询员工数据, 每页展示5条记录\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp limit 0 , 5; -- 从索引0开始，向后取5条记录 案例2：查询 第1页 员工数据, 每页展示5条记录\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp limit 5; -- 如果查询的是第1页数据，起始索引可以省略，直接简写为：limit 条数 案例3：查询 第2页 员工数据, 每页展示5条记录\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp limit 5 , 5; -- 从索引5开始，向后取5条记录 案例4：查询 第3页 员工数据, 每页展示5条记录\n1 2 3 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp limit 10 , 5; -- 从索引10开始，向后取5条记录 注意事项:\n起始索引从0开始。 计算公式 ： 起始索引 = （查询页码 - 1）* 每页显示记录数 分页查询是数据库的方言，不同的数据库有不同的实现，MySQL中是LIMIT 如果查询的是第一页数据，起始索引可以省略，直接简写为 limit 条数 MySQL-DQL-案例 案例一\n案例：根据需求完成员工管理的条件分页查询\n分析：根据输入的条件，查询第1页数据\n在员工管理的列表上方有一些查询条件：员工姓名、员工性别，员工入职时间(开始时间~结束时间) 姓名：张 性别：男 入职时间：2000-01-01 ~ 2015-12-31 除了查询条件外，在列表的下面还有一个分页条，这就涉及到了分页查询 查询第1页数据（每页显示10条数据） 基于查询的结果，按照修改时间进行降序排序 结论：条件查询 + 分页查询 + 排序查询\n1 2 3 4 5 6 7 8 9 10 11 12 -- 根据输入条件查询第1页数据（每页展示10条记录） -- 输入条件： -- 姓名：张 （模糊查询） -- 性别：男 -- 入职时间：2000-01-01 ~ 2015-12-31 -- 分页： 0 , 10 -- 排序： 修改时间 DESC select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where name like \u0026#39;张%\u0026#39; and gender = 1 and entrydate between \u0026#39;2000-01-01\u0026#39; and \u0026#39;2015-12-31\u0026#39; order by update_time desc limit 0 , 10; 案例二\n案例：根据需求完成员工信息的统计\n分析：以上信息统计在开发中也叫图形报表(将统计好的数据以可视化的形式展示出来)\n员工性别统计：以饼状图的形式展示出企业男性员人数和女性员工人数 只要查询出男性员工和女性员工各自有多少人就可以了 员工职位统计：以柱状图的形式展示各职位的在岗人数 只要查询出各个职位有多少人就可以了 员工性别统计：\n1 2 3 4 -- if(条件表达式, true取值 , false取值) select if(gender=1,\u0026#39;男性员工\u0026#39;,\u0026#39;女性员工\u0026#39;) AS 性别, count(*) AS 人数 from tb_emp group by gender; if(表达式, tvalue, fvalue) ：当表达式为true时，取值tvalue；当表达式为false时，取值fvalue\n员工职位统计：\n1 2 3 4 5 6 7 8 9 10 11 -- case 表达式 when 值1 then 结果1 when 值2 then 结果2 ... else result end select (case job when 1 then \u0026#39;班主任\u0026#39; when 2 then \u0026#39;讲师\u0026#39; when 3 then \u0026#39;学工主管\u0026#39; when 4 then \u0026#39;教研主管\u0026#39; else \u0026#39;未分配职位\u0026#39; end) AS 职位 , count(*) AS 人数 from tb_emp group by job; case 表达式 when 值1 then 结果1 [when 值2 then 结果2 \u0026hellip;] [else result] end\nMySQL-多表设计-一对多 项目开发中，在进行数据库表结构设计时，会根据业务需求及业务模块之间的关系，分析并设计表结构，由于业务之间相互关联，所以各个表结构之间也存在着各种联系，基本上分为三种：\n一对多(多对一) 多对多 一对一 一对多\n表设计\n需求：根据页面原型及需求文档 ，完成部门及员工的表结构设计\n员工管理页面原型：（前面已完成tb_emp表结构设计） 部门管理页面原型： 经过上述分析，现已明确的部门表结构：\n业务字段 ： 部门名称 基础字段 ： id(主键)、创建时间、修改时间 部门表 - SQL语句：\n1 2 3 4 5 6 7 8 9 10 11 12 # 建议：创建新的数据库（多表设计存放在新数据库下） create database db03; use db03; -- 部门表 create table tb_dept ( id int unsigned primary key auto_increment comment \u0026#39;主键ID\u0026#39;, name varchar(10) not null unique comment \u0026#39;部门名称\u0026#39;, create_time datetime not null comment \u0026#39;创建时间\u0026#39;, update_time datetime not null comment \u0026#39;修改时间\u0026#39; ) comment \u0026#39;部门表\u0026#39;; 部门表创建好之后，我们还需要再修改下员工表。为什么要修改员工表呢？是因为我们之前设计员工表(单表)的时候，并没有考虑员工的归属部门。\n员工表：添加归属部门字段\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- 员工表 create table tb_emp ( id int unsigned primary key auto_increment comment \u0026#39;ID\u0026#39;, username varchar(20) not null unique comment \u0026#39;用户名\u0026#39;, password varchar(32) default \u0026#39;123456\u0026#39; comment \u0026#39;密码\u0026#39;, name varchar(10) not null comment \u0026#39;姓名\u0026#39;, gender tinyint unsigned not null comment \u0026#39;性别, 说明: 1 男, 2 女\u0026#39;, image varchar(300) comment \u0026#39;图像\u0026#39;, job tinyint unsigned comment \u0026#39;职位, 说明: 1 班主任,2 讲师, 3 学工主管, 4 教研主管\u0026#39;, entrydate date comment \u0026#39;入职时间\u0026#39;, dept_id int unsigned comment \u0026#39;部门ID\u0026#39;, -- 员工的归属部门 create_time datetime not null comment \u0026#39;创建时间\u0026#39;, update_time datetime not null comment \u0026#39;修改时间\u0026#39; ) comment \u0026#39;员工表\u0026#39;; 测试数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 -- 部门表测试数据 insert into tb_dept (id, name, create_time, update_time) values (1,\u0026#39;学工部\u0026#39;,now(),now()), (2,\u0026#39;教研部\u0026#39;,now(),now()), (3,\u0026#39;咨询部\u0026#39;,now(),now()), (4,\u0026#39;就业部\u0026#39;,now(),now()), (5,\u0026#39;人事部\u0026#39;,now(),now()); -- 员工表测试数据 INSERT INTO tb_emp (id, username, password, name, gender, image, job, entrydate,dept_id, create_time, update_time) VALUES (1,\u0026#39;jinyong\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;金庸\u0026#39;,1,\u0026#39;1.jpg\u0026#39;,4,\u0026#39;2000-01-01\u0026#39;,2,now(),now()), (2,\u0026#39;zhangwuji\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;张无忌\u0026#39;,1,\u0026#39;2.jpg\u0026#39;,2,\u0026#39;2015-01-01\u0026#39;,2,now(),now()), (3,\u0026#39;yangxiao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;杨逍\u0026#39;,1,\u0026#39;3.jpg\u0026#39;,2,\u0026#39;2008-05-01\u0026#39;,2,now(),now()), (4,\u0026#39;weiyixiao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;韦一笑\u0026#39;,1,\u0026#39;4.jpg\u0026#39;,2,\u0026#39;2007-01-01\u0026#39;,2,now(),now()), (5,\u0026#39;changyuchun\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;常遇春\u0026#39;,1,\u0026#39;5.jpg\u0026#39;,2,\u0026#39;2012-12-05\u0026#39;,2,now(),now()), (6,\u0026#39;xiaozhao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;小昭\u0026#39;,2,\u0026#39;6.jpg\u0026#39;,3,\u0026#39;2013-09-05\u0026#39;,1,now(),now()), (7,\u0026#39;jixiaofu\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;纪晓芙\u0026#39;,2,\u0026#39;7.jpg\u0026#39;,1,\u0026#39;2005-08-01\u0026#39;,1,now(),now()), (8,\u0026#39;zhouzhiruo\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;周芷若\u0026#39;,2,\u0026#39;8.jpg\u0026#39;,1,\u0026#39;2014-11-09\u0026#39;,1,now(),now()), (9,\u0026#39;dingminjun\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;丁敏君\u0026#39;,2,\u0026#39;9.jpg\u0026#39;,1,\u0026#39;2011-03-11\u0026#39;,1,now(),now()), (10,\u0026#39;zhaomin\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;赵敏\u0026#39;,2,\u0026#39;10.jpg\u0026#39;,1,\u0026#39;2013-09-05\u0026#39;,1,now(),now()), (11,\u0026#39;luzhangke\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;鹿杖客\u0026#39;,1,\u0026#39;11.jpg\u0026#39;,1,\u0026#39;2007-02-01\u0026#39;,1,now(),now()), (12,\u0026#39;hebiweng\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;鹤笔翁\u0026#39;,1,\u0026#39;12.jpg\u0026#39;,1,\u0026#39;2008-08-18\u0026#39;,1,now(),now()), (13,\u0026#39;fangdongbai\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;方东白\u0026#39;,1,\u0026#39;13.jpg\u0026#39;,2,\u0026#39;2012-11-01\u0026#39;,2,now(),now()), (14,\u0026#39;zhangsanfeng\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;张三丰\u0026#39;,1,\u0026#39;14.jpg\u0026#39;,2,\u0026#39;2002-08-01\u0026#39;,2,now(),now()), (15,\u0026#39;yulianzhou\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;俞莲舟\u0026#39;,1,\u0026#39;15.jpg\u0026#39;,2,\u0026#39;2011-05-01\u0026#39;,2,now(),now()), (16,\u0026#39;songyuanqiao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;宋远桥\u0026#39;,1,\u0026#39;16.jpg\u0026#39;,2,\u0026#39;2010-01-01\u0026#39;,2,now(),now()), (17,\u0026#39;chenyouliang\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;陈友谅\u0026#39;,1,\u0026#39;17.jpg\u0026#39;,NULL,\u0026#39;2015-03-21\u0026#39;,NULL,now(),now()); 员工表 - 部门表之间的关系：\n一对多关系实现：在数据库表中多的一方，添加字段，来关联属于一这方的主键。\nMySQL-多表设计-一对多-外键 外键约束\n问题\n表结构创建完毕后，我们看到两张表的数据分别为： 现在员工表中有五个员工都归属于1号部门(学工部)，当删除了1号部门后，数据变为：\n1号部门被删除了，但是依然还有5个员工是属于1号部门的。 此时：就出现数据的不完整、不一致了。\n问题分析\n目前上述的两张表(员工表、部门表)，在数据库层面，并未建立关联，所以是无法保证数据的一致性和完整性的\n问题解决\n想解决上述的问题呢，我们就可以通过数据库中的 外键约束 来解决。\n外键约束：让两张表的数据建立连接，保证数据的一致性和完整性。\n对应的关键字：foreign key\n外键约束的语法：\n1 2 3 4 5 6 7 8 9 10 -- 创建表时指定 create table 表名( 字段名 数据类型, ... [constraint] [外键名称] foreign key (外键字段名) references 主表 (主表列名) ); -- 建完表后，添加外键 alter table 表名 add constraint 外键名称 foreign key(外键字段名) references 主表(主表列名); 那接下来，我们就为员工表的dept_id 建立外键约束，来关联部门表的主键。\n方式1：通过SQL语句操作\n1 2 3 -- 修改表： 添加外键约束 alter table tb_emp add constraint fk_dept_id foreign key (dept_id) references tb_dept(id); 方式2：图形化界面操作\n当我们添加外键约束时，我们得保证当前数据库表中的数据是完整的。 所以，我们需要将之前删除掉的数据再添加回来。\n当我们添加了外键之后，再删除ID为1的部门，就会发现，此时数据库报错了，不允许删除。\n外键约束（foreign key）：保证了数据的完整性和一致性。\n物理外键和逻辑外键\n物理外键 概念：使用foreign key定义外键关联另外一张表。 缺点： 影响增、删、改的效率（需要检查外键关系）。 仅用于单节点数据库，不适用与分布式、集群场景。 容易引发数据库的死锁问题，消耗性能。 逻辑外键 概念：在业务层逻辑中，解决外键关联。 通过逻辑外键，就可以很方便的解决上述问题。 在现在的企业开发中，很少会使用物理外键，都是使用逻辑外键。 甚至在一些数据库开发规范中，会明确指出禁止使用物理外键 foreign key\nMySQL-多表设计-一对一\u0026amp;多对多 一对一\n一对一关系表在实际开发中应用起来比较简单，通常是用来做单表的拆分，也就是将一张大表拆分成两张小表，将大表中的一些基础字段放在一张表当中，将其他的字段放在另外一张表当中，以此来提高数据的操作效率。\n一对一的应用场景： 用户表(基本信息+身份信息)\n基本信息：用户的ID、姓名、性别、手机号、学历 身份信息：民族、生日、身份证号、身份证签发机关，身份证的有效期(开始时间、结束时间) 如果在业务系统当中，对用户的基本信息查询频率特别的高，但是对于用户的身份信息查询频率很低，此时出于提高查询效率的考虑，我就可以将这张大表拆分成两张小表，第一张表存放的是用户的基本信息，而第二张表存放的就是用户的身份信息。他们两者之间一对一的关系，一个用户只能对应一个身份证，而一个身份证也只能关联一个用户。\n那么在数据库层面怎么去体现上述两者之间是一对一的关系呢？\n其实一对一我们可以看成一种特殊的一对多。一对多我们是怎么设计表关系的？是不是在多的一方添加外键。同样我们也可以通过外键来体现一对一之间的关系，我们只需要在任意一方来添加一个外键就可以了。\n一对一 ：在任意一方加入外键，关联另外一方的主键，并且设置外键为唯一的(UNIQUE)\nSQL脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 -- 用户基本信息表 create table tb_user( id int unsigned primary key auto_increment comment \u0026#39;ID\u0026#39;, name varchar(10) not null comment \u0026#39;姓名\u0026#39;, gender tinyint unsigned not null comment \u0026#39;性别, 1 男 2 女\u0026#39;, phone char(11) comment \u0026#39;手机号\u0026#39;, degree varchar(10) comment \u0026#39;学历\u0026#39; ) comment \u0026#39;用户基本信息表\u0026#39;; -- 测试数据 insert into tb_user values (1,\u0026#39;白眉鹰王\u0026#39;,1,\u0026#39;18812340001\u0026#39;,\u0026#39;初中\u0026#39;), (2,\u0026#39;青翼蝠王\u0026#39;,1,\u0026#39;18812340002\u0026#39;,\u0026#39;大专\u0026#39;), (3,\u0026#39;金毛狮王\u0026#39;,1,\u0026#39;18812340003\u0026#39;,\u0026#39;初中\u0026#39;), (4,\u0026#39;紫衫龙王\u0026#39;,2,\u0026#39;18812340004\u0026#39;,\u0026#39;硕士\u0026#39;); -- 用户身份信息表 create table tb_user_card( id int unsigned primary key auto_increment comment \u0026#39;ID\u0026#39;, nationality varchar(10) not null comment \u0026#39;民族\u0026#39;, birthday date not null comment \u0026#39;生日\u0026#39;, idcard char(18) not null comment \u0026#39;身份证号\u0026#39;, issued varchar(20) not null comment \u0026#39;签发机关\u0026#39;, expire_begin date not null comment \u0026#39;有效期限-开始\u0026#39;, expire_end date comment \u0026#39;有效期限-结束\u0026#39;, user_id int unsigned not null unique comment \u0026#39;用户ID\u0026#39;, constraint fk_user_id foreign key (user_id) references tb_user(id) ) comment \u0026#39;用户身份信息表\u0026#39;; -- 测试数据 insert into tb_user_card values (1,\u0026#39;汉\u0026#39;,\u0026#39;1960-11-06\u0026#39;,\u0026#39;100000100000100001\u0026#39;,\u0026#39;朝阳区公安局\u0026#39;,\u0026#39;2000-06-10\u0026#39;,null,1), (2,\u0026#39;汉\u0026#39;,\u0026#39;1971-11-06\u0026#39;,\u0026#39;100000100000100002\u0026#39;,\u0026#39;静安区公安局\u0026#39;,\u0026#39;2005-06-10\u0026#39;,\u0026#39;2025-06-10\u0026#39;,2), (3,\u0026#39;汉\u0026#39;,\u0026#39;1963-11-06\u0026#39;,\u0026#39;100000100000100003\u0026#39;,\u0026#39;昌平区公安局\u0026#39;,\u0026#39;2006-06-10\u0026#39;,null,3), (4,\u0026#39;回\u0026#39;,\u0026#39;1980-11-06\u0026#39;,\u0026#39;100000100000100004\u0026#39;,\u0026#39;海淀区公安局\u0026#39;,\u0026#39;2008-06-10\u0026#39;,\u0026#39;2028-06-10\u0026#39;,4); 多对多\n多对多的关系在开发中属于也比较常见的。比如：学生和老师的关系，一个学生可以有多个授课老师，一个授课老师也可以有多个学生。在比如：学生和课程的关系，一个学生可以选修多门课程，一个课程也可以供多个学生选修。\n案例：学生与课程的关系\n关系：一个学生可以选修多门课程，一门课程也可以供多个学生选择 实现关系：建立第三张中间表，中间表至少包含两个外键，分别关联两方主键 SQL脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 -- 学生表 create table tb_student( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, name varchar(10) comment \u0026#39;姓名\u0026#39;, no varchar(10) comment \u0026#39;学号\u0026#39; ) comment \u0026#39;学生表\u0026#39;; -- 学生表测试数据 insert into tb_student(name, no) values (\u0026#39;黛绮丝\u0026#39;, \u0026#39;2000100101\u0026#39;),(\u0026#39;谢逊\u0026#39;, \u0026#39;2000100102\u0026#39;),(\u0026#39;殷天正\u0026#39;, \u0026#39;2000100103\u0026#39;),(\u0026#39;韦一笑\u0026#39;, \u0026#39;2000100104\u0026#39;); -- 课程表 create table tb_course( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, name varchar(10) comment \u0026#39;课程名称\u0026#39; ) comment \u0026#39;课程表\u0026#39;; -- 课程表测试数据 insert into tb_course (name) values (\u0026#39;Java\u0026#39;), (\u0026#39;PHP\u0026#39;), (\u0026#39;MySQL\u0026#39;) , (\u0026#39;Hadoop\u0026#39;); -- 学生课程表（中间表） create table tb_student_course( id int auto_increment comment \u0026#39;主键\u0026#39; primary key, student_id int not null comment \u0026#39;学生ID\u0026#39;, course_id int not null comment \u0026#39;课程ID\u0026#39;, constraint fk_courseid foreign key (course_id) references tb_course (id), constraint fk_studentid foreign key (student_id) references tb_student (id) )comment \u0026#39;学生课程中间表\u0026#39;; -- 学生课程表测试数据 insert into tb_student_course(student_id, course_id) values (1,1),(1,2),(1,3),(2,2),(2,3),(3,4); MySQL-多表设计-案例-关系分析 案例： 参考页面原型及需求，设计合理的表结构\n步骤\n阅读页面原型及需求文档，分析各个模块涉及到的表结构，及表结构之间的关系。 根据页面原型及需求文档，分析各个表结构中具体的字段及约束。 分析\n页面原型-分类管理 分类的信息：分类名称、分类类型[菜品/套餐]、分类排序、分类状态[禁用/启用]、分类的操作时间(修改时间)。\n页面原型-菜品管理 菜品的信息：菜品名称、菜品图片、菜品分类、菜品售价、菜品售卖状态、菜品的操作时间(修改时间)。\n思考：分类与菜品之间是什么关系？\n思考逻辑：一个分类下可以有多个菜品吗？反过来再想一想，一个菜品会对应多个分类吗？ 答案：一对多关系。一个分类下会有多个菜品，而一个菜品只能归属一个分类。\n设计表原则：在多的一方，添加字段，关联属于一这方的主键。\n页面原型-套餐管理 套餐的信息：套餐名称、套餐图片、套餐分类、套餐价格、套餐售卖状态、套餐的操作时间。\n思考：套餐与菜品之间是什么关系？\n思考逻辑：一个套餐下可以有多个菜品吗？反过来再想一想，一个菜品可以出现在多个套餐中吗？ 答案：多对多关系。一个套餐下会有多个菜品，而一个菜品也可以出现在多个套餐中。\n设计表原则：创建第三张中间表，建立两个字段分别关联菜品表的主键和套餐表的主键。\n分析页面原型及需求文档后，我们获得：\n分类表 业务字段：分类名称、分类类型、分类排序、分类状态 基础字段：id(主键)、分类的创建时间、分类的修改时间 菜品表 业务字段：菜品名称、菜品图片、菜品分类、菜品售价、菜品售卖状态 基础字段：id(主键)、分类的创建时间、分类的修改时间 套餐表 业务字段：套餐名称、套餐图片、套餐分类、套餐价格、套餐售卖状态 基础字段：id(主键)、分类的创建时间、分类的修改时间 表结构之间的关系：\n分类表 - 菜品表 ： 一对多 在菜品表中添加字段(菜品分类)，关联分类表 菜品表 - 套餐表 ： 多对多 创建第三张中间表(套餐菜品关联表)，在中间表上添加两个字段(菜品id、套餐id)，分别关联菜品表和分类表 MySQL-多表设计-案例-表结构 表结构\n分类表：category\n业务字段：分类名称、分类类型、分类排序、分类状态 基础字段：id(主键)、创建时间、修改时间 1 2 3 4 5 6 7 8 9 10 11 -- 分类表 create table category ( id int unsigned primary key auto_increment comment \u0026#39;主键ID\u0026#39;, name varchar(20) not null unique comment \u0026#39;分类名称\u0026#39;, type tinyint unsigned not null comment \u0026#39;类型 1 菜品分类 2 套餐分类\u0026#39;, sort tinyint unsigned not null comment \u0026#39;顺序\u0026#39;, status tinyint unsigned not null default 0 comment \u0026#39;状态 0 禁用，1 启用\u0026#39;, create_time datetime not null comment \u0026#39;创建时间\u0026#39;, update_time datetime not null comment \u0026#39;更新时间\u0026#39; ) comment \u0026#39;菜品及套餐分类\u0026#39;; 菜品表：dish\n业务字段：菜品名称、菜品图片、菜品分类、菜品售价、菜品售卖状态 基础字段：id(主键)、分类的创建时间、分类的修改时间 1 2 3 4 5 6 7 8 9 10 11 12 13 -- 菜品表 create table dish ( id int unsigned primary key auto_increment comment \u0026#39;主键ID\u0026#39;, name varchar(20) not null unique comment \u0026#39;菜品名称\u0026#39;, category_id int unsigned not null comment \u0026#39;菜品分类ID\u0026#39;, -- 逻辑外键 price decimal(8, 2) not null comment \u0026#39;菜品价格\u0026#39;, image varchar(300) not null comment \u0026#39;菜品图片\u0026#39;, description varchar(200) comment \u0026#39;描述信息\u0026#39;, status tinyint unsigned not null default 0 comment \u0026#39;状态, 0 停售 1 起售\u0026#39;, create_time datetime not null comment \u0026#39;创建时间\u0026#39;, update_time datetime not null comment \u0026#39;更新时间\u0026#39; ) comment \u0026#39;菜品\u0026#39;; 套餐表：setmeal\n业务字段：套餐名称、套餐图片、套餐分类、套餐价格、套餐售卖状态 基础字段：id(主键)、分类的创建时间、分类的修改时间 1 2 3 4 5 6 7 8 9 10 11 12 13 -- 套餐表 create table setmeal ( id int unsigned primary key auto_increment comment \u0026#39;主键ID\u0026#39;, name varchar(20) not null unique comment \u0026#39;套餐名称\u0026#39;, category_id int unsigned not null comment \u0026#39;分类id\u0026#39;, -- 逻辑外键 price decimal(8, 2) not null comment \u0026#39;套餐价格\u0026#39;, image varchar(300) not null comment \u0026#39;图片\u0026#39;, description varchar(200) comment \u0026#39;描述信息\u0026#39;, status tinyint unsigned not null default 0 comment \u0026#39;状态 0:停用 1:启用\u0026#39;, create_time datetime not null comment \u0026#39;创建时间\u0026#39;, update_time datetime not null comment \u0026#39;更新时间\u0026#39; ) comment \u0026#39;套餐\u0026#39;; 套餐菜品关联表：setmeal_dish\n1 2 3 4 5 6 7 8 -- 套餐菜品关联表 create table setmeal_dish ( id int unsigned primary key auto_increment comment \u0026#39;主键ID\u0026#39;, setmeal_id int unsigned not null comment \u0026#39;套餐id \u0026#39;, -- 逻辑外键 dish_id int unsigned not null comment \u0026#39;菜品id\u0026#39;, -- 逻辑外键 copies tinyint unsigned not null comment \u0026#39;份数\u0026#39; ) comment \u0026#39;套餐菜品关联表\u0026#39;; 小结\n","date":"2024-04-16T16:01:23+08:00","image":"https://nova-bryan.github.io/p/mysql-dql/image_hu17089168107649188491.png","permalink":"https://nova-bryan.github.io/p/mysql-dql/","title":"Mysql DQL"},{"content":"苍穹外卖学习文档 软件开发整体介绍 软件开发流程 需求分析 需求规格说明书、产品原型\n设计 UI设计、数据库设计、接口设计\n编码 项目代码、单元测试\n测试 测试用例、测试报告\n上线运维 软件环境安装、配置\n角色分工 项目经理\n对整体项目负责，任务分配、把控进度\n产品经理\n进行需求调研。输出需求调研文档、产品原型等\nUI设计师\n根据产品模型输出界面效果图\n架构师\n项目整体架构设计、技术选型等\n开发工程师\n代码实现\n测试工程师\n编写测试用例，输出测试报告\n运维工程师\n软件环境搭建、项目上线\n软件环境 开发环境 开发人员在开发阶段使用的环境，一般外部用户无法访问\n测试环境 专门给测试人员使用的环境，用于测试项目，一般外部用户无法访问\n生产环境 即线上环境，正式提供对外服务的环境\n苍穹外卖项目介绍 项目介绍 定位：专门为餐饮企业定制的一款软件产品\n功能架构：\n产品原型 用于展示项目的业务功能\n技术选型 展示项目中使用到的技术框架和中间件等\n开发环境搭建 前端环境搭建 整体结构 通过Nginx代理\n后端环境搭建 熟悉项目结构 sky-common子模块 constant：常量类 context：项目上下文相关 enumeration：枚举类 exception：自定义异常类 json：处理json转换 properties：springboot配置属性类，把配置文件中的配置项封装成对象 result：后端返回的结果 utils：工具类 sky-pojo子模块 sky-server子模块 存放的是 配置文件、配置类、拦截器、controller、service、mapper、启动类等\n使用Git进行版本控制 创建Git本地仓库 创建Git远程仓库 将本地文件推送到Git远程仓库 数据库环境搭建 前后端联调 Nginx🆕 反向代理，就是让前端发送的动态请求由Nginx转发到后端服务器\nNginx反向代理的好处\n提高访问速度\n进行负载均衡\n就是把大量的请求按照我们指定的方式均衡的分配给集群中的每台服务器\n保证后端服务安全\nNginx反向代理的配置方式 Nginx负载均衡的配置方式 Nginx负载均衡策略 轮询：平均接收到请求\n完善登录功能 修改数据库中的明文密码，改为MD5加密后的密文 修改Java代码，前端提交的密码进行MD5加密后再跟数据库中密码比对 导入接口文档 前后端分离开发流程 操作步骤 这里YApi可换成ApiPost，导入数据选择YApi即可\nSwagger 介绍 使用方式 导入knife4j的maven坐标\n在配置类中加入knife4j相关配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /** * 通过knife4j生成接口文档 * @return */ @Bean public Docket docket() { ApiInfo apiInfo = new ApiInfoBuilder() .title(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .version(\u0026#34;2.0\u0026#34;) .description(\u0026#34;苍穹外卖项目接口文档\u0026#34;) .build(); Docket docket = new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo) .select() //指定生成接口需要扫描的包 .apis(RequestHandlerSelectors.basePackage(\u0026#34;com.sky.controller\u0026#34;)) .paths(PathSelectors.any()) .build(); return docket; } 设置静态资源映射，否则接口文档页面无法访问\n1 2 3 4 5 6 7 8 9 /** * 设置静态资源映射 * @param registry */ protected void addResourceHandlers(ResourceHandlerRegistry registry) { log.info(\u0026#34;开始设置静态资源映射...\u0026#34;); registry.addResourceHandler(\u0026#34;/doc.html\u0026#34;).addResourceLocations(\u0026#34;classpath:/META-INF/resources/\u0026#34;); registry.addResourceHandler(\u0026#34;/webjars/**\u0026#34;).addResourceLocations(\u0026#34;classpath:/META-INF/resources/webjars/\u0026#34;); } 常用注解 通过注解可以控制生成的接口文档，使接口文档拥有更好的可读性，常用注解如下：\n员工管理、分类管理 员工管理界面\n分类管理界面\n新增员工 需求分析和设计 产品原型 接口设计 本项目约定：\n管理端发出的请求，统一使用/admin作为前缀 用户端发出的请求，统一使用/user作为前缀 数据库设计 employee表为员工表，用于存储商家内部的员工信息。具体表结构如下：\n字段名 数据类型 说明 备注 id bigint 主键 自增⭐ name varchar(32) 姓名 username varchar(32) 用户名 唯一⭐ password varchar(64) 密码 phone varchar(11) 手机号 sex varchar(2) 性别 id_number varchar(18) 身份证号 status int 账号状态 1正常 0锁定⭐ create_time datetime 创建时间 update_time datetime 最后修改时间 create_user bigint 创建人id update_user bigint 最后修改人id 代码开发 根据新增员工接口设计对应的DTO\n注意：当前端提交的数据和实体类中对应的属性差别比较大时，建议使用DTO来封装数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /** * 新增员工 * @param employeeDTO */ public void save(EmployeeDTO employeeDTO) { Employee employee = new Employee(); //对象属性拷贝，属性名必须一致 BeanUtils.copyProperties(employeeDTO, employee); //设置账号的状态，默认正常状态，1表示正常，0表示锁定 employee.setStatus(StatusConstant.ENABLE); //设置密码，默认密码为123456 employee.setPassword(DigestUtils.md5DigestAsHex(PasswordConstant.DEFAULT_PASSWORD.getBytes())); //设置当前记录的创建时间和修改时间 employee.setCreateTime(LocalDateTime.now()); employee.setUpdateTime(LocalDateTime.now()); //设置当前记录的创建人id和修改人id // TODO 后期需要改为当前登录的用户id employee.setCreateUser(10L); employee.setUpdateUser(10L); employeeMapper.insert(employee); } 功能测试 通过Swagger接口文档测试 通过前后端联调测试 注意：由于开发阶段前端和后端是并行开发的，后端完成某个功能后，此时前端对应的功能可能还没有开发完成，导致无法进行前后端联调测试。所以在开发阶段，后端测试主要以接口文档测试为主。\n代码完善 程序存在的问题：\n录入的用户名已存在，抛出异常后没有处理 新增员工时，创建人id和修改人id设置为了固定值 解析出登录员工id后，如何传递给Service的save方法？\n员工分页查询 需求分析和设计 产品原型\n业务规则：\n根据每页展示员工信息 每页展示10条数据 分页查询时可以根据需要，输入员工姓名进行查询 接口设计\n代码开发 员工信息分页查询后端返回的对象类型为：Result\u0026lt;PageResult\u0026gt;\nmybatis提供的分页查询框架pagehelper\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${pagehelper}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 功能测试 可以通过接口文档进行测试，也可以进行前后端联调测试。\n代码完善 最后操作时间需要修改成年月日\n解决方式：\n方式一：在属性上加入注解，对日期进行格式化\n1 2 @JsonFormat(pattern = \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;) private LocalDateTime updateTime 方式二：在Webconfiguration中扩展SpringMvc的消息转换器，统一对日期类型进行格式化处理\n启用禁用员工账号 需求分析和设计 产品原型\n业务规则：\n可以对状态为“启用”的员工账号进行“禁用”操作 可以对状态为“禁用”的员工账号进行“启用”操作 状态为“禁用”的员工账号不能登录系统 接口设计\n代码开发 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 /** * 启用/禁用员工账号 * @param status * @param id * @return */ @PostMapping(\u0026#34;status/{status}\u0026#34;) @ApiOperation(\u0026#34;启用/禁用员工账号\u0026#34;) public Result startOrStop(@PathVariable(\u0026#34;status\u0026#34;) Integer status, Long id) { log.info(\u0026#34;启用/禁用员工账号：{}, {}\u0026#34;, status, id); employeeService.startOrStop(status, id); return Result.success(); } /** * 启用/禁用员工账号 * @param status * @param id */ public void startOrStop(Integer status, Long id) { // update employee set status = ? where id = ? /*Employee employee = new Employee(); employee.setStatus(status); employee.setId(id);*/ Employee employee = Employee.builder() .status(status) .id(id) .build(); employeeMapper.update(employee); } \u0026lt;update id=\u0026#34;update\u0026#34; parameterType=\u0026#34;Employee\u0026#34;\u0026gt; update employee \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt;name = #{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;username != null\u0026#34;\u0026gt;username = #{username},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;password != null\u0026#34;\u0026gt;password = #{password},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;phone != null\u0026#34;\u0026gt;phone = #{phone},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;sex != null\u0026#34;\u0026gt;sex = #{sex},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;idNumber != null\u0026#34;\u0026gt;id_Number = #{idNumber},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateTime != null\u0026#34;\u0026gt;update_Time = #{updateTime},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;updateUser != null\u0026#34;\u0026gt;update_User = #{updateUser},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt;status = #{status},\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where id = #{id} \u0026lt;/update\u0026gt; 功能测试 编辑员工 需求分析和设计 产品原型\n编辑员工功能涉及到两个接口：\n根据id查询员工信息 编辑员工信息 代码开发 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /** * 编辑员工信息 * @param employeeDTO * @return */ @PutMapping @ApiOperation(\u0026#34;编辑员工信息\u0026#34;) public Result update(@RequestBody EmployeeDTO employeeDTO) { log.info(\u0026#34;编辑员工信息: {}\u0026#34;, employeeDTO); employeeService.update(employeeDTO); return Result.success(); } /** * 编辑员工信息 * @param employeeDTO */ public void update(EmployeeDTO employeeDTO) { Employee employee = new Employee(); BeanUtils.copyProperties(employeeDTO, employee); employee.setUpdateTime(LocalDateTime.now()); employee.setUpdateUser(BaseContext.getCurrentId()); employeeMapper.update(employee); } 功能测试 导入分类模块功能代码 需求分析和设计 产品原型\n业务规则：\n分类名称必须是唯一的 分类按照类型可以分为菜品分类和套餐分类 新添加的分类状态默认为禁用 接口设计：\n新增分类 分类分页查询 根据id删除分类 修改分类 启用禁用分类 根据类型查询分类 数据库设计（category表）：\ncategory表为分类表，用于存储商品的分类信息。具体表结构如下\n字段名 数据类型 说明 备注 id bigint 主键 自增 name varchar(32) 分类名称 唯一 type int 分类类型 1菜品分类 2套餐分类 sort int 排序字段 用于分类数据的排序 status int 状态 1启用 0禁用 create_time datetime 创建时间 update_time datetime 最后修改时间 create_user bigint 创建人id update_user bigint 最后修改人id 代码导入 功能测试 菜品管理 公共字段自动填充🌟 问题分析 业务表中的公共字段：\n问题：代码冗余、不便于后期维护\n实现思路 自定义注解AutoFill，用于标识需要进行公共字段自动填充的方法 自定义切面类AutoFillAspect，统一拦截加入了AutoFill注解的方法，通过反射为公共字段赋值 在Mapper的方法上加入AutoFill注解 代码开发 功能测试 新增菜品 需求分析和设计 产品原型：\n业务规则：\n菜品名称必须是唯一的 菜品必须属于某个分类下，不能单独存在 新增菜品时可以根据情况选择菜品的口味 每个菜品必须对应一张图片 接口设计：\n根据类型查询分类（已完成）\n文件上传\n新增菜品\n数据库设计（dish菜品表和dish_flavor口味表）：\ndish表为菜品表，用于存储菜品的信息。具体表结构如下\n字段名 数据类型 说明 备注 id bigint 主键 自增 name varchar(32) 菜品名称 唯一 category_id bigint 分类id 逻辑外键 price decimal(10,2) 菜品价格 image varchar(255) 图片路径 description varchar(255) 菜品描述 status int 售卖状态 1起售 0停售 create_time datetime 创建时间 update_time datetime 最后修改时间 create_user bigint 创建人id update_user bigint 最后修改人id dish_flavor表为菜品口味表，用于存储菜品的口味信息。具体表结构如下\n字段名 数据类型 说明 备注 id bigint 主键 自增 dish_id bigint 菜品id 逻辑外键 name varchar(32) 口味名称 value varchar(255) 口味值 代码开发 开发文件上传接口：\n功能测试 菜品分页查询 需求分析和设计 产品原型\n业务规则\n根据页码展示菜品信息 每页展示10条数据 分页查询时可以根据需要输入菜品名称、菜品分类、菜品状态进行查询 接口设计\n代码开发 根据菜品分页查询接口定义设计对应的DTO：\n根据菜品分页查询接口定义设计对应的VO：\n功能测试 删除菜品 需求分析和设计 产品原型\n业务规则：\n可以一次删除一个菜品，也可以批量删除菜品 起售中的菜品不能删除 被套餐关联的菜品不能删除 删除菜品后，关联的口味数据也需要删除掉 接口设计：\n数据库设计：\n代码开发 功能测试 修改菜品 需求分析和设计 产品原型\n接口设计：\n根据id查询商品\n根据类型查询分类（已实现）\n文件上传（已实现）\n修改商品\n代码开发 功能测试 店铺营业状态设置 Redis入门 Redis简介 Redis是一个基于内存的key-value结构数据库。\n基于内存存储，读写性能高 适合存储热点数据（热点商品、资讯、新闻） 企业应用广泛 官网：https://redis.io/\n中文网：https://www.redis.net.cn/\nRedis下载与安装 Redis服务启动与停止 Redis数据类型 5种常用数据类型介绍 Redis存储的是key-value结构的数据，其中key是字符串类型，value有5种常用的数据类型：\n字符串 string\n普通字符串，Redis中最简单的数据类型\n哈希 hash\n也叫散列，类似于Java中的HashMap结构\n列表 list\n按照插入顺序排序，可以有重复元素，类似于Java中的LinkedList\n集合 set\n无序集合，没有重复元素，类似于Java中的HashSet\n有序集合 sorted set/zset\n集合中每个元素关联一个分数（score），Redis根据分数升序排序，没有重复元素\n各种数据类型的特点 Redis常用命令 字符串操作命令 SET key value 设置指定key的值 GET key 获取指定key的值 SETEX key seconds value 设置指定key的值，并将key的过期时间设为seconds秒 \u0026mdash;\u0026gt; 短信验证码 SETNX key value 只有在key不存在时设置key的值 哈希操作命令 Redis hash 是一个String类型的 field 和 value 的映射表，hash特别适合用于存储对象，常用命令：\nHSET key field value 将哈希表 key 中的字段 field 的值为 value HGET key field 获取存储在哈希表中指定字段的值 HDEL key field 删除存储在哈希表中的指定字段 HKEYS key 获取哈希表中所有字段 HVALS key 获取哈希表中所有值 列表操作命令 Redis列表是简单的字符串列表，按照插入顺序排序，常用命令：\nLPUSH key value1 [value2] 将一个或多个值插入到列表头部 LRANGE key start stop 获取列表指定范围内的元素 RPOP key 移除并获取列表最后一个元素 LLEN key 获取列表长度 集合操作命令 Redis set 是 String 类型的无序集合。集合成员是唯一的，集合中不能出现重复的数据，常用命令：\nSADD key member1 [member2] 向集合添加一个或多个成员 SMEMBERS key 返回集合中所有的成员 SCARD key 获取集合的成员数 SINTER key1 [key2] 返回给定的所有集合的交集 SUNION key1 [key2] 返回所有给定集合的并集 SREM key member1 [member2] 删除集合中一个或多个成员 有序集合操作命令 Redis的有序集合是String类型元素的集合，且不允许有重复成员。每个元素都会关联一个double类型的分数。常用命令：\nZADD key score1 member1 [score2 member2] 向有序集合添加一个或多个成员 ZRANGE key start stop [WITHSCORES] 通过索引区间返回有序集合中指定区间内的成员 ZINCRBY key increment member 有序集合中对指定成员的分数加上增量increment ZREM key member [member\u0026hellip; ] 移除有序集合中的一个或多个成员 通用命令 Redis的通用命令是不分数据类型的，都可以使用的命令：\nKEYS pattern 查找所有符合给定模式（pattern）的key EXISTS key 检查给定key是否存在 TYPE key 返回key所存储的值的类型 DEL key 该命令用于在key存在时删除key 在Java中操作Redis Redis的Java客户端 Redis的Java客户端很多，常用的几种：\nJedis\nLettuce\nSpring Data Redis\n是Spring的一部分，对Redis底层开发包进行了高度封装。在Spring项目中，可以使用Spring Data Redis来简化操作。\nSpring Data Redis使用方式 操作步骤：\n导入Spring Data Redis 的Maven坐标\n配置Redis数据源\n编写配置类，创建RedisTemplate对象\n通过RedisTemplate对象操作Redis\n店铺营业状态 需求分析和设计 产品原型\n接口设计：\n设置营业状态 管理端查询营业状态 用户端查询营业状态 本项目约定：\n管理端发出的请求，统一使用/admin作为前缀 用户端发出的请求，统一使用/user作为前缀 营业状态数据存储方式：基于Redis的字符串来进行存储\n代码开发 功能测试 微信登录、商品浏览 HttpClient🆕 介绍 HttpClient 是Apache Jakarta Common下的子项目，可以用来提供高效的、最新的、功能丰富的支持 HTTP 协议的客户端编程工具包，并且它支持 HTTP 协议最新的版本和建议。\n核心API：\nHttpClient HttpClients CloseableHttpClient HttpGet HttpPost 发送请求步骤：\n创建HttpClient对象 创建Http请求对象 \u0026mdash;\u0026gt; HttpGet/HttpPost 调用HttpClient的execute方法发送请求 入门案例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 /** * 测试通过HttpClient发送GET方式请求 */ @Test public void testGET() throws Exception{ //创建Httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建请求对象 HttpGet httpGet = new HttpGet(\u0026#34;http://localhost:8080/user/shop/status\u0026#34;); //发送请求，并接受响应结果 CloseableHttpResponse response = httpClient.execute(httpGet); //获取服务端返回的状态码 int statusCode = response.getStatusLine().getStatusCode(); System.out.println(\u0026#34;服务端返回的状态码为：\u0026#34; + statusCode); HttpEntity entity = response.getEntity(); String body = EntityUtils.toString(entity); System.out.println(\u0026#34;服务端返回的数据为：\u0026#34; + body); //关闭资源 response.close(); httpClient.close(); } /** * 测试通过HttpClient发送POST请求 */ @Test public void testPost() throws Exception { //创建Httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建请求对象 HttpPost httpPost = new HttpPost(\u0026#34;http://localhost:8080/admin/employee/login\u0026#34;); JSONObject jsonObject = new JSONObject(); jsonObject.put(\u0026#34;username\u0026#34;, \u0026#34;admin\u0026#34;); jsonObject.put(\u0026#34;password\u0026#34;, \u0026#34;123456\u0026#34;); StringEntity entity = new StringEntity(jsonObject.toString()); //指定请求的编码方式 entity.setContentEncoding(\u0026#34;utf-8\u0026#34;); //数据格式 entity.setContentType(\u0026#34;application/json\u0026#34;); httpPost.setEntity(entity); //发送请求 CloseableHttpResponse response = httpClient.execute(httpPost); //解析返回结果 int statusCode = response.getStatusLine().getStatusCode(); System.out.println(\u0026#34;响应码为：\u0026#34; + statusCode); HttpEntity entity1 = response.getEntity(); String body = EntityUtils.toString(entity1); System.out.println(\u0026#34;响应数据为：\u0026#34; + body); //关闭资源 response.close(); httpClient.close(); } 微信小程序开发 介绍 准备工作 入门案例 操作步骤：\n了解微信小程序目录结构\n小程序包含一个描述整体程序的 app 和多个描述各自页面的 page。一个小程序主体部分由三个文件组成，必须放在项目的根目录，如下：\n一个小程序页面由四个文件组成：\n编写小程序代码\n编译小程序\n微信登录 导入小程序代码 微信登录流程 官网：https://developers.weixin.qq.com/miniprogram/dev/framework/open-ability/login.html\n需求分析和设计 产品原型：\n业务规则：\n基于微信登录实现小程序的登录功能 如果是新用户需要自动完成注册 接口设计：\n数据库设计（user表）：\n代码开发 配置微信登录所需配置项：\n配置为微信用户生成jwt令牌时使用的配置项：\n功能测试 导入商品浏览功能代码 需求分析和设计 产品原型：\n接口设计：\n查询分类\n根据分类id查询菜品\n根据分类id查询套餐\n根据套餐id查询包含的菜品\n代码导入 功能测试 缓存商品、购物车 缓存菜品 问题说明 用户端小程序展示的菜品数据都是通过查询数据库获得，如果用户端访问量比较大，数据库访问压力随之增大。\n实现思路 通过Redis来缓存菜品数据，减少数据库查询操作。\n缓存逻辑分析：\n每个分类下的菜品保存一份缓存数据\n数据库中菜品数据有变更时清理缓存数据\n代码开发 修改管理端接口 DishController 的相关方法，加入清理缓存的逻辑，需要改造的方法:\n新增菜品 修改菜品 批量删除菜品 起售、停售菜品 功能测试 缓存套餐 Spring Cache⭐ Spring Cache 是一个框架，实现了基于注解的缓存功能，只需要简单地加一个注解，就能实现缓存功能。\nSpring Cache 提供了一层抽象，底层可以切换不同的缓存实现，例如:\nEHCache Caffeine Redis 常用注解：\n在启动类上添加@EnableCaching注解\n1 2 3 4 5 6 7 8 9 @Slf4j @SpringBootApplication @EnableCaching //开启缓存注解功能 public class CacheDemoApplication { public static void main(String[] args) { SpringApplication.run(CacheDemoApplication.class,args); log.info(\u0026#34;项目启动成功...\u0026#34;); } } 在controller上使用@Cacheable、@Cacheput、@CacheEvict注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @RestController @RequestMapping(\u0026#34;/user\u0026#34;) @Slf4j public class UserController { @Autowired private UserMapper userMapper; @PostMapping @CachePut(cacheNames = \u0026#34;userCache\u0026#34;, key = \u0026#34;#user.id\u0026#34;) //如果使用SpringCache缓存数据，key的生成：userCache::2 public User save(@RequestBody User user){ userMapper.insert(user); return user; } @DeleteMapping @CacheEvict(cacheNames = \u0026#34;userCache\u0026#34;, key = \u0026#34;#id\u0026#34;) public void deleteById(Long id){ userMapper.deleteById(id); } @DeleteMapping(\u0026#34;/delAll\u0026#34;) @CacheEvict(cacheNames = \u0026#34;userCache\u0026#34;, allEntries = true) //删除userCache下的所有缓存 public void deleteAll(){ userMapper.deleteAll(); } @GetMapping @Cacheable(cacheNames = \u0026#34;userCache\u0026#34;, key = \u0026#34;#id\u0026#34;) //key的生成：userCache::10 public User getById(Long id){ User user = userMapper.getById(id); return user; } } 实现思路 具体的实现思路如下：\n导入SpringCache和Redis相关Maven坐标 在启动类上加入@EnableCache注解，开启缓存注解功能 在用户端接口SetmealController的list方法上加入@Cacheable注解 在管理端接口SetmealController的save、delete、update、startOrStop等方法上加入@CacheEvict注解 代码开发 功能测试 添加购物车 需求分析和设计 产品原型：\n接口设计：\n请求方式：POST 请求路径：/user/shoppingCart/add 请求参数：套餐id、菜品id、口味 返回结果：code、data、msg 数据库设计：\n作用：暂时存放所选商品的地方 选的什么商品 每个商品买了几个 不同用户的购物车需要区分开 代码开发 功能测试 查看购物车 需求分析和设计 产品原型：\n接口设计：\n代码开发 功能测试 清空购物车 需求分析和设计 产品原型：\n接口设计：\n功能测试 代码开发 用户下单、订单支付 导入地址簿功能代码 需求分析和设计 产品原型：\n业务功能：\n查询地址列表 新增地址 修改地址 删除地址 设置默认地址 查询默认地址 接口设计：\n新增地址 查询当前登录用户的所有地址信息 查询默认地址 根据id删除地址 根据id修改地址 根据id查询地址 设置默认地址 数据库设计（address_book表）：\naddress_book表为地址表，用于存储C端用户的收货地址信息。具体表结构如下：\n字段名 数据类型 说明 备注 id bigint 主键 自增 user_id bigint 用户id 逻辑外键 consignee varchar(50) 收货人 sex varchar(2) 性别 phone varchar(11) 手机号 province_code varchar(12) 省份编码 province_name varchar(32) 省份名称 city_code varchar(12) 城市编码 city_name varchar(32) 城市名称 district_code varchar(12) 区县编码 district_name varchar(32) 区县名称 detail varchar(200) 详细地址信息 具体到门牌号 label varchar(100) 标签 公司、家、学校 is_default tinyint(1) 是否默认地址 1是 0否 代码导入 功能测试 用户下单 需求分析和设计 用户下单业务说明：\n在电商系统中，用户是通过下单的方式通知商家，用户已经购买了商品，需要商家进行备货和发货。\n用户下单后会产生订单相关数据，订单数据需要能够体现如下信息：\n用户点餐业务流程：\n接口设计（分析）：\n接口设计：\n数据库（orders表、order_deatail表）设计：\norders表为订单表，用于存储C端用户的订单数据。具体表结构如下：\n字段名 数据类型 说明 备注 id bigint 主键 自增 number varchar(50) 订单号 status int 订单状态 1待付款 2待接单 3已接单 4派送中 5已完成 6已取消 user_id bigint 用户id 逻辑外键 address_book_id bigint 地址id 逻辑外键 order_time datetime 下单时间 checkout_time datetime 付款时间 pay_method int 支付方式 1微信支付 2支付宝支付 pay_status tinyint 支付状态 0未支付 1已支付 2退款 amount decimal(10,2) 订单金额 remark varchar(100) 备注信息 phone varchar(11) 手机号 address varchar(255) 详细地址信息 user_name varchar(32) 用户姓名 consignee varchar(32) 收货人 cancel_reason varchar(255) 订单取消原因 rejection_reason varchar(255) 拒单原因 cancel_time datetime 订单取消时间 estimated_delivery_time datetime 预计送达时间 delivery_status tinyint 配送状态 1立即送出 0选择具体时间 delivery_time datetime 送达时间 pack_amount int 打包费 tableware_number int 餐具数量 tableware_status tinyint 餐具数量状态 1按餐量提供 0选择具体数量 order_detail表为订单明细表，用于存储C端用户的订单明细数据。具体表结构如下：\n字段名 数据类型 说明 备注 id bigint 主键 自增 name varchar(32) 商品名称 image varchar(255) 商品图片路径 order_id bigint 订单id 逻辑外键 dish_id bigint 菜品id 逻辑外键 setmeal_id bigint 套餐id 逻辑外键 dish_flavor varchar(50) 菜品口味 number int 商品数量 amount decimal(10,2) 商品单价 代码开发 根据用户下单接口的参数设计DTO：\n根据用户下单接口的返回结果设计VO：\n功能测试 订单支付 微信支付介绍 微信支付产品：\n参考：https://pay.weixin.qq.com/static/product/product_index.shtm\n微信支付接入流程：\n微信小程序支付时序图：\nJSAPI下单：商户系统调用该接口在微信支付服务后台生成预支付交易单\n微信小程序调起支付：通过JSAPI下单接口获取到发起支付的必要参数prepay_id，然后使用微信支付提供的小程序方法调起小程序支付\n微信支付准备工作 微信小程序支付时序图：\n获取微信支付平台证书、商户私钥文件\n获取临时域名：支付成功后微信服务通过该域名回调我们的程序\n代码导入 微信支付相关配置：\n功能测试 用户端历史订单模块 1. 查询历史订单 1.1 需求分析和设计 产品原型：\n业务规则\n分页查询历史订单 可以根据订单状态查询 展示订单数据时，需要展示的数据包括：下单时间、订单状态、订单金额、订单明细（商品名称、图片） 接口设计：参见接口文档\n1.2 代码实现 1.2.1 user/OrderController 1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * 历史订单查询 * * @param page * @param pageSize * @param status 订单状态 1待付款 2待接单 3已接单 4派送中 5已完成 6已取消 * @return */ @GetMapping(\u0026#34;/historyOrders\u0026#34;) @ApiOperation(\u0026#34;历史订单查询\u0026#34;) public Result\u0026lt;PageResult\u0026gt; page(int page, int pageSize, Integer status) { PageResult pageResult = orderService.pageQuery4User(page, pageSize, status); return Result.success(pageResult); } 1.2.2 OrderService 1 2 3 4 5 6 7 8 /** * 用户端订单分页查询 * @param page * @param pageSize * @param status * @return */ PageResult pageQuery4User(int page, int pageSize, Integer status); 1.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 /** * 用户端订单分页查询 * * @param pageNum * @param pageSize * @param status * @return */ public PageResult pageQuery4User(int pageNum, int pageSize, Integer status) { // 设置分页 PageHelper.startPage(pageNum, pageSize); OrdersPageQueryDTO ordersPageQueryDTO = new OrdersPageQueryDTO(); ordersPageQueryDTO.setUserId(BaseContext.getCurrentId()); ordersPageQueryDTO.setStatus(status); // 分页条件查询 Page\u0026lt;Orders\u0026gt; page = orderMapper.pageQuery(ordersPageQueryDTO); List\u0026lt;OrderVO\u0026gt; list = new ArrayList(); // 查询出订单明细，并封装入OrderVO进行响应 if (page != null \u0026amp;\u0026amp; page.getTotal() \u0026gt; 0) { for (Orders orders : page) { Long orderId = orders.getId();// 订单id // 查询订单明细 List\u0026lt;OrderDetail\u0026gt; orderDetails = orderDetailMapper.getByOrderId(orderId); OrderVO orderVO = new OrderVO(); BeanUtils.copyProperties(orders, orderVO); orderVO.setOrderDetailList(orderDetails); list.add(orderVO); } } return new PageResult(page.getTotal(), list); } 1.2.4 OrderMapper 1 2 3 4 5 /** * 分页条件查询并按下单时间排序 * @param ordersPageQueryDTO */ Page\u0026lt;Orders\u0026gt; pageQuery(OrdersPageQueryDTO ordersPageQueryDTO); 1.2.5 OrderMapper.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;select id=\u0026#34;pageQuery\u0026#34; resultType=\u0026#34;Orders\u0026#34;\u0026gt; select * from orders \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;number != null and number!=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and number like concat(\u0026#39;%\u0026#39;,#{number},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;phone != null and phone!=\u0026#39;\u0026#39;\u0026#34;\u0026gt; and phone like concat(\u0026#39;%\u0026#39;,#{phone},\u0026#39;%\u0026#39;) \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;userId != null\u0026#34;\u0026gt; and user_id = #{userId} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;status != null\u0026#34;\u0026gt; and status = #{status} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;beginTime != null\u0026#34;\u0026gt; and order_time \u0026amp;gt;= #{beginTime} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;endTime != null\u0026#34;\u0026gt; and order_time \u0026amp;lt;= #{endTime} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; order by order_time desc \u0026lt;/select\u0026gt; 1.2.6 OrderDetailMapper 1 2 3 4 5 6 7 /** * 根据订单id查询订单明细 * @param orderId * @return */ @Select(\u0026#34;select * from order_detail where order_id = #{orderId}\u0026#34;) List\u0026lt;OrderDetail\u0026gt; getByOrderId(Long orderId); 1.3 功能测试 略\n2. 查询订单详情 2.1 需求分析和设计 产品原型：\n接口设计：参见接口文档\n2.2 代码实现 2.2.1 user/OrderController 1 2 3 4 5 6 7 8 9 10 11 12 /** * 查询订单详情 * * @param id * @return */ @GetMapping(\u0026#34;/orderDetail/{id}\u0026#34;) @ApiOperation(\u0026#34;查询订单详情\u0026#34;) public Result\u0026lt;OrderVO\u0026gt; details(@PathVariable(\u0026#34;id\u0026#34;) Long id) { OrderVO orderVO = orderService.details(id); return Result.success(orderVO); } 2.2.2 OrderService 1 2 3 4 5 6 /** * 查询订单详情 * @param id * @return */ OrderVO details(Long id); 2.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /** * 查询订单详情 * * @param id * @return */ public OrderVO details(Long id) { // 根据id查询订单 Orders orders = orderMapper.getById(id); // 查询该订单对应的菜品/套餐明细 List\u0026lt;OrderDetail\u0026gt; orderDetailList = orderDetailMapper.getByOrderId(orders.getId()); // 将该订单及其详情封装到OrderVO并返回 OrderVO orderVO = new OrderVO(); BeanUtils.copyProperties(orders, orderVO); orderVO.setOrderDetailList(orderDetailList); return orderVO; } 2.2.4 OrderMapper 1 2 3 4 5 6 /** * 根据id查询订单 * @param id */ @Select(\u0026#34;select * from orders where id=#{id}\u0026#34;) Orders getById(Long id); 2.3 功能测试 略\n3. 取消订单 3.1 需求分析和设计 产品原型：\n业务规则：\n待支付和待接单状态下，用户可直接取消订单 商家已接单状态下，用户取消订单需电话沟通商家 派送中状态下，用户取消订单需电话沟通商家 如果在待接单状态下取消订单，需要给用户退款 取消订单后需要将订单状态修改为“已取消” 接口设计：参见接口文档\n3.2 代码实现 3.2.1 user/OrderController 1 2 3 4 5 6 7 8 9 10 11 /** * 用户取消订单 * * @return */ @PutMapping(\u0026#34;/cancel/{id}\u0026#34;) @ApiOperation(\u0026#34;取消订单\u0026#34;) public Result cancel(@PathVariable(\u0026#34;id\u0026#34;) Long id) throws Exception { orderService.userCancelById(id); return Result.success(); } 3.2.2 OrderService 1 2 3 4 5 /** * 用户取消订单 * @param id */ void userCancelById(Long id) throws Exception; 3.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 /** * 用户取消订单 * * @param id */ public void userCancelById(Long id) throws Exception { // 根据id查询订单 Orders ordersDB = orderMapper.getById(id); // 校验订单是否存在 if (ordersDB == null) { throw new OrderBusinessException(MessageConstant.ORDER_NOT_FOUND); } //订单状态 1待付款 2待接单 3已接单 4派送中 5已完成 6已取消 if (ordersDB.getStatus() \u0026gt; 2) { throw new OrderBusinessException(MessageConstant.ORDER_STATUS_ERROR); } Orders orders = new Orders(); orders.setId(ordersDB.getId()); // 订单处于待接单状态下取消，需要进行退款 if (ordersDB.getStatus().equals(Orders.TO_BE_CONFIRMED)) { //调用微信支付退款接口 weChatPayUtil.refund( ordersDB.getNumber(), //商户订单号 ordersDB.getNumber(), //商户退款单号 new BigDecimal(0.01),//退款金额，单位 元 new BigDecimal(0.01));//原订单金额 //支付状态修改为 退款 orders.setPayStatus(Orders.REFUND); } // 更新订单状态、取消原因、取消时间 orders.setStatus(Orders.CANCELLED); orders.setCancelReason(\u0026#34;用户取消\u0026#34;); orders.setCancelTime(LocalDateTime.now()); orderMapper.update(orders); } 3.3 功能测试 略\n4. 再来一单 4.1 需求分析和设计 产品原型：\n接口设计：参见接口文档\n业务规则：\n再来一单就是将原订单中的商品重新加入到购物车中 4.2 代码实现 4.2.1 user/OrderController 1 2 3 4 5 6 7 8 9 10 11 12 /** * 再来一单 * * @param id * @return */ @PostMapping(\u0026#34;/repetition/{id}\u0026#34;) @ApiOperation(\u0026#34;再来一单\u0026#34;) public Result repetition(@PathVariable Long id) { orderService.repetition(id); return Result.success(); } 4.2.2 OrderService 1 2 3 4 5 6 /** * 再来一单 * * @param id */ void repetition(Long id); 4.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /** * 再来一单 * * @param id */ public void repetition(Long id) { // 查询当前用户id Long userId = BaseContext.getCurrentId(); // 根据订单id查询当前订单详情 List\u0026lt;OrderDetail\u0026gt; orderDetailList = orderDetailMapper.getByOrderId(id); // 将订单详情对象转换为购物车对象 List\u0026lt;ShoppingCart\u0026gt; shoppingCartList = orderDetailList.stream().map(x -\u0026gt; { ShoppingCart shoppingCart = new ShoppingCart(); // 将原订单详情里面的菜品信息重新复制到购物车对象中 BeanUtils.copyProperties(x, shoppingCart, \u0026#34;id\u0026#34;); shoppingCart.setUserId(userId); shoppingCart.setCreateTime(LocalDateTime.now()); return shoppingCart; }).collect(Collectors.toList()); // 将购物车对象批量添加到数据库 shoppingCartMapper.insertBatch(shoppingCartList); } 4.2.4 ShoppingCartMapper 1 2 3 4 5 6 /** * 批量插入购物车数据 * * @param shoppingCartList */ void insertBatch(List\u0026lt;ShoppingCart\u0026gt; shoppingCartList); 4.2.5 ShoppingCartMapper.xml 1 2 3 4 5 6 7 8 \u0026lt;insert id=\u0026#34;insertBatch\u0026#34; parameterType=\u0026#34;list\u0026#34;\u0026gt; insert into shopping_cart (name, image, user_id, dish_id, setmeal_id, dish_flavor, number, amount, create_time) values \u0026lt;foreach collection=\u0026#34;shoppingCartList\u0026#34; item=\u0026#34;sc\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; (#{sc.name},#{sc.image},#{sc.userId},#{sc.dishId},#{sc.setmealId},#{sc.dishFlavor},#{sc.number},#{sc.amount},#{sc.createTime}) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; 4.3 功能测试 略\n商家端订单管理模块 1. 订单搜索 1.1 需求分析和设计 产品原型：\n业务规则：\n输入订单号/手机号进行搜索，支持模糊搜索 根据订单状态进行筛选 下单时间进行时间筛选 搜索内容为空，提示未找到相关订单 搜索结果页，展示包含搜索关键词的内容 分页展示搜索到的订单数据 接口设计：参见接口文档\n1.2 代码实现 1.2.1 admin/OrderController 在admin包下创建OrderController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /** * 订单管理 */ @RestController(\u0026#34;adminOrderController\u0026#34;) @RequestMapping(\u0026#34;/admin/order\u0026#34;) @Slf4j @Api(tags = \u0026#34;订单管理接口\u0026#34;) public class OrderController { @Autowired private OrderService orderService; /** * 订单搜索 * * @param ordersPageQueryDTO * @return */ @GetMapping(\u0026#34;/conditionSearch\u0026#34;) @ApiOperation(\u0026#34;订单搜索\u0026#34;) public Result\u0026lt;PageResult\u0026gt; conditionSearch(OrdersPageQueryDTO ordersPageQueryDTO) { PageResult pageResult = orderService.conditionSearch(ordersPageQueryDTO); return Result.success(pageResult); } } 1.2.2 OrderService 1 2 3 4 5 6 /** * 条件搜索订单 * @param ordersPageQueryDTO * @return */ PageResult conditionSearch(OrdersPageQueryDTO ordersPageQueryDTO); 1.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 /** * 订单搜索 * * @param ordersPageQueryDTO * @return */ public PageResult conditionSearch(OrdersPageQueryDTO ordersPageQueryDTO) { PageHelper.startPage(ordersPageQueryDTO.getPage(), ordersPageQueryDTO.getPageSize()); Page\u0026lt;Orders\u0026gt; page = orderMapper.pageQuery(ordersPageQueryDTO); // 部分订单状态，需要额外返回订单菜品信息，将Orders转化为OrderVO List\u0026lt;OrderVO\u0026gt; orderVOList = getOrderVOList(page); return new PageResult(page.getTotal(), orderVOList); } private List\u0026lt;OrderVO\u0026gt; getOrderVOList(Page\u0026lt;Orders\u0026gt; page) { // 需要返回订单菜品信息，自定义OrderVO响应结果 List\u0026lt;OrderVO\u0026gt; orderVOList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Orders\u0026gt; ordersList = page.getResult(); if (!CollectionUtils.isEmpty(ordersList)) { for (Orders orders : ordersList) { // 将共同字段复制到OrderVO OrderVO orderVO = new OrderVO(); BeanUtils.copyProperties(orders, orderVO); String orderDishes = getOrderDishesStr(orders); // 将订单菜品信息封装到orderVO中，并添加到orderVOList orderVO.setOrderDishes(orderDishes); orderVOList.add(orderVO); } } return orderVOList; } /** * 根据订单id获取菜品信息字符串 * * @param orders * @return */ private String getOrderDishesStr(Orders orders) { // 查询订单菜品详情信息（订单中的菜品和数量） List\u0026lt;OrderDetail\u0026gt; orderDetailList = orderDetailMapper.getByOrderId(orders.getId()); // 将每一条订单菜品信息拼接为字符串（格式：宫保鸡丁*3；） List\u0026lt;String\u0026gt; orderDishList = orderDetailList.stream().map(x -\u0026gt; { String orderDish = x.getName() + \u0026#34;*\u0026#34; + x.getNumber() + \u0026#34;;\u0026#34;; return orderDish; }).collect(Collectors.toList()); // 将该订单对应的所有菜品信息拼接在一起 return String.join(\u0026#34;\u0026#34;, orderDishList); } 1.3 功能测试 略\n2. 各个状态的订单数量统计 2.1 需求分析和设计 产品原型：\n接口设计：参见接口文档\n2.2 代码实现 2.2.1 admin/OrderController 1 2 3 4 5 6 7 8 9 10 11 /** * 各个状态的订单数量统计 * * @return */ @GetMapping(\u0026#34;/statistics\u0026#34;) @ApiOperation(\u0026#34;各个状态的订单数量统计\u0026#34;) public Result\u0026lt;OrderStatisticsVO\u0026gt; statistics() { OrderStatisticsVO orderStatisticsVO = orderService.statistics(); return Result.success(orderStatisticsVO); } 2.2.2 OrderService 1 2 3 4 5 /** * 各个状态的订单数量统计 * @return */ OrderStatisticsVO statistics(); 2.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 各个状态的订单数量统计 * * @return */ public OrderStatisticsVO statistics() { // 根据状态，分别查询出待接单、待派送、派送中的订单数量 Integer toBeConfirmed = orderMapper.countStatus(Orders.TO_BE_CONFIRMED); Integer confirmed = orderMapper.countStatus(Orders.CONFIRMED); Integer deliveryInProgress = orderMapper.countStatus(Orders.DELIVERY_IN_PROGRESS); // 将查询出的数据封装到orderStatisticsVO中响应 OrderStatisticsVO orderStatisticsVO = new OrderStatisticsVO(); orderStatisticsVO.setToBeConfirmed(toBeConfirmed); orderStatisticsVO.setConfirmed(confirmed); orderStatisticsVO.setDeliveryInProgress(deliveryInProgress); return orderStatisticsVO; } 2.2.4 OrderMapper 1 2 3 4 5 6 /** * 根据状态统计订单数量 * @param status */ @Select(\u0026#34;select count(id) from orders where status = #{status}\u0026#34;) Integer countStatus(Integer status); 2.3 功能测试 略\n3. 查询订单详情 3.1 需求分析和设计 产品原型：\n业务规则：\n订单详情页面需要展示订单基本信息（状态、订单号、下单时间、收货人、电话、收货地址、金额等） 订单详情页面需要展示订单明细数据（商品名称、数量、单价） 接口设计：参见接口文档\n3.2 代码实现 3.2.1 admin/OrderController 1 2 3 4 5 6 7 8 9 10 11 12 /** * 订单详情 * * @param id * @return */ @GetMapping(\u0026#34;/details/{id}\u0026#34;) @ApiOperation(\u0026#34;查询订单详情\u0026#34;) public Result\u0026lt;OrderVO\u0026gt; details(@PathVariable(\u0026#34;id\u0026#34;) Long id) { OrderVO orderVO = orderService.details(id); return Result.success(orderVO); } 3.3 功能测试 略\n4. 接单 4.1 需求分析和设计 产品原型：\n业务规则：\n商家接单其实就是将订单的状态修改为“已接单” 接口设计：参见接口文档\n4.2 代码实现 4.2.1 admin/OrderController 1 2 3 4 5 6 7 8 9 10 11 /** * 接单 * * @return */ @PutMapping(\u0026#34;/confirm\u0026#34;) @ApiOperation(\u0026#34;接单\u0026#34;) public Result confirm(@RequestBody OrdersConfirmDTO ordersConfirmDTO) { orderService.confirm(ordersConfirmDTO); return Result.success(); } 4.2.2 OrderService 1 2 3 4 5 6 /** * 接单 * * @param ordersConfirmDTO */ void confirm(OrdersConfirmDTO ordersConfirmDTO); 4.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 /** * 接单 * * @param ordersConfirmDTO */ public void confirm(OrdersConfirmDTO ordersConfirmDTO) { Orders orders = Orders.builder() .id(ordersConfirmDTO.getId()) .status(Orders.CONFIRMED) .build(); orderMapper.update(orders); } 4.3 功能测试 略\n5. 拒单 5.1 需求分析和设计 产品原型：\n业务规则：\n商家拒单其实就是将订单状态修改为“已取消” 只有订单处于“待接单”状态时可以执行拒单操作 商家拒单时需要指定拒单原因 商家拒单时，如果用户已经完成了支付，需要为用户退款 接口设计：参见接口文档\n5.2 代码实现 5.2.1 admin/OrderController 1 2 3 4 5 6 7 8 9 10 11 /** * 拒单 * * @return */ @PutMapping(\u0026#34;/rejection\u0026#34;) @ApiOperation(\u0026#34;拒单\u0026#34;) public Result rejection(@RequestBody OrdersRejectionDTO ordersRejectionDTO) throws Exception { orderService.rejection(ordersRejectionDTO); return Result.success(); } 5.2.2 OrderService 1 2 3 4 5 6 /** * 拒单 * * @param ordersRejectionDTO */ void rejection(OrdersRejectionDTO ordersRejectionDTO) throws Exception; 5.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /** * 拒单 * * @param ordersRejectionDTO */ public void rejection(OrdersRejectionDTO ordersRejectionDTO) throws Exception { // 根据id查询订单 Orders ordersDB = orderMapper.getById(ordersRejectionDTO.getId()); // 订单只有存在且状态为2（待接单）才可以拒单 if (ordersDB == null || !ordersDB.getStatus().equals(Orders.TO_BE_CONFIRMED)) { throw new OrderBusinessException(MessageConstant.ORDER_STATUS_ERROR); } //支付状态 Integer payStatus = ordersDB.getPayStatus(); if (payStatus == Orders.PAID) { //用户已支付，需要退款 String refund = weChatPayUtil.refund( ordersDB.getNumber(), ordersDB.getNumber(), new BigDecimal(0.01), new BigDecimal(0.01)); log.info(\u0026#34;申请退款：{}\u0026#34;, refund); } // 拒单需要退款，根据订单id更新订单状态、拒单原因、取消时间 Orders orders = new Orders(); orders.setId(ordersDB.getId()); orders.setStatus(Orders.CANCELLED); orders.setRejectionReason(ordersRejectionDTO.getRejectionReason()); orders.setCancelTime(LocalDateTime.now()); orderMapper.update(orders); } 5.3 功能测试 略\n6. 取消订单 6.1 需求分析和设计 产品原型：\n业务规则：\n取消订单其实就是将订单状态修改为“已取消” 商家取消订单时需要指定取消原因 商家取消订单时，如果用户已经完成了支付，需要为用户退款 接口设计：参见接口文档\n6.2 代码实现 6.2.1 admin/OrderController 1 2 3 4 5 6 7 8 9 10 11 /** * 取消订单 * * @return */ @PutMapping(\u0026#34;/cancel\u0026#34;) @ApiOperation(\u0026#34;取消订单\u0026#34;) public Result cancel(@RequestBody OrdersCancelDTO ordersCancelDTO) throws Exception { orderService.cancel(ordersCancelDTO); return Result.success(); } 6.2.2 OrderService 1 2 3 4 5 6 /** * 商家取消订单 * * @param ordersCancelDTO */ void cancel(OrdersCancelDTO ordersCancelDTO) throws Exception; 6.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /** * 取消订单 * * @param ordersCancelDTO */ public void cancel(OrdersCancelDTO ordersCancelDTO) throws Exception { // 根据id查询订单 Orders ordersDB = orderMapper.getById(ordersCancelDTO.getId()); //支付状态 Integer payStatus = ordersDB.getPayStatus(); if (payStatus == 1) { //用户已支付，需要退款 String refund = weChatPayUtil.refund( ordersDB.getNumber(), ordersDB.getNumber(), new BigDecimal(0.01), new BigDecimal(0.01)); log.info(\u0026#34;申请退款：{}\u0026#34;, refund); } // 管理端取消订单需要退款，根据订单id更新订单状态、取消原因、取消时间 Orders orders = new Orders(); orders.setId(ordersCancelDTO.getId()); orders.setStatus(Orders.CANCELLED); orders.setCancelReason(ordersCancelDTO.getCancelReason()); orders.setCancelTime(LocalDateTime.now()); orderMapper.update(orders); } 6.3 功能测试 略\n7. 派送订单 7.1 需求分析和设计 产品原型：\n业务规则：\n派送订单其实就是将订单状态修改为“派送中” 只有状态为“待派送”的订单可以执行派送订单操作 接口设计：参见接口文档\n7.2 代码实现 7.2.1 admin/OrderController 1 2 3 4 5 6 7 8 9 10 11 /** * 派送订单 * * @return */ @PutMapping(\u0026#34;/delivery/{id}\u0026#34;) @ApiOperation(\u0026#34;派送订单\u0026#34;) public Result delivery(@PathVariable(\u0026#34;id\u0026#34;) Long id) { orderService.delivery(id); return Result.success(); } 7.2.2 OrderService 1 2 3 4 5 6 /** * 派送订单 * * @param id */ void delivery(Long id); 7.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /** * 派送订单 * * @param id */ public void delivery(Long id) { // 根据id查询订单 Orders ordersDB = orderMapper.getById(id); // 校验订单是否存在，并且状态为3 if (ordersDB == null || !ordersDB.getStatus().equals(Orders.CONFIRMED)) { throw new OrderBusinessException(MessageConstant.ORDER_STATUS_ERROR); } Orders orders = new Orders(); orders.setId(ordersDB.getId()); // 更新订单状态,状态转为派送中 orders.setStatus(Orders.DELIVERY_IN_PROGRESS); orderMapper.update(orders); } 7.3 功能测试 略\n8. 完成订单 8.1 需求分析和设计 产品原型：\n业务规则：\n完成订单其实就是将订单状态修改为“已完成” 只有状态为“派送中”的订单可以执行订单完成操作 接口设计：参见接口文档\n8.2 代码实现 8.2.1 admin/OrderController 1 2 3 4 5 6 7 8 9 10 11 /** * 完成订单 * * @return */ @PutMapping(\u0026#34;/complete/{id}\u0026#34;) @ApiOperation(\u0026#34;完成订单\u0026#34;) public Result complete(@PathVariable(\u0026#34;id\u0026#34;) Long id) { orderService.complete(id); return Result.success(); } 8.2.2 OrderService 1 2 3 4 5 6 /** * 完成订单 * * @param id */ void complete(Long id); 8.2.3 OrderServiceImpl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * 完成订单 * * @param id */ public void complete(Long id) { // 根据id查询订单 Orders ordersDB = orderMapper.getById(id); // 校验订单是否存在，并且状态为4 if (ordersDB == null || !ordersDB.getStatus().equals(Orders.DELIVERY_IN_PROGRESS)) { throw new OrderBusinessException(MessageConstant.ORDER_STATUS_ERROR); } Orders orders = new Orders(); orders.setId(ordersDB.getId()); // 更新订单状态,状态转为完成 orders.setStatus(Orders.COMPLETED); orders.setDeliveryTime(LocalDateTime.now()); orderMapper.update(orders); } 8.3 功能测试 略\n校验收货地址是否超出配送范围 1. 环境准备 注册账号：https://passport.baidu.com/v2/?reg\u0026amp;tt=1671699340600\u0026amp;overseas=\u0026amp;gid=CF954C2-A3D2-417F-9FE6-B0F249ED7E33\u0026amp;tpl=pp\u0026amp;u=https%3A%2F%2Flbsyun.baidu.com%2Findex.php%3Ftitle%3D首页\n登录百度地图开放平台：https://lbsyun.baidu.com/\n进入控制台，创建应用，获取AK：\n相关接口:\nhttps://lbsyun.baidu.com/index.php?title=webapi/guide/webservice-geocoding\nhttps://lbsyun.baidu.com/index.php?title=webapi/directionlite-v1\n2. 代码开发 2.1 application.yml 配置外卖商家店铺地址和百度地图的AK：\n2.2 OrderServiceImpl 改造OrderServiceImpl，注入上面的配置项：\n1 2 3 4 5 @Value(\u0026#34;${sky.shop.address}\u0026#34;) private String shopAddress; @Value(\u0026#34;${sky.baidu.ak}\u0026#34;) private String ak; 在OrderServiceImpl中提供校验方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 /** * 检查客户的收货地址是否超出配送范围 * @param address */ private void checkOutOfRange(String address) { Map map = new HashMap(); map.put(\u0026#34;address\u0026#34;,shopAddress); map.put(\u0026#34;output\u0026#34;,\u0026#34;json\u0026#34;); map.put(\u0026#34;ak\u0026#34;,ak); //获取店铺的经纬度坐标 String shopCoordinate = HttpClientUtil.doGet(\u0026#34;https://api.map.baidu.com/geocoding/v3\u0026#34;, map); JSONObject jsonObject = JSON.parseObject(shopCoordinate); if(!jsonObject.getString(\u0026#34;status\u0026#34;).equals(\u0026#34;0\u0026#34;)){ throw new OrderBusinessException(\u0026#34;店铺地址解析失败\u0026#34;); } //数据解析 JSONObject location = jsonObject.getJSONObject(\u0026#34;result\u0026#34;).getJSONObject(\u0026#34;location\u0026#34;); String lat = location.getString(\u0026#34;lat\u0026#34;); String lng = location.getString(\u0026#34;lng\u0026#34;); //店铺经纬度坐标 String shopLngLat = lat + \u0026#34;,\u0026#34; + lng; map.put(\u0026#34;address\u0026#34;,address); //获取用户收货地址的经纬度坐标 String userCoordinate = HttpClientUtil.doGet(\u0026#34;https://api.map.baidu.com/geocoding/v3\u0026#34;, map); jsonObject = JSON.parseObject(userCoordinate); if(!jsonObject.getString(\u0026#34;status\u0026#34;).equals(\u0026#34;0\u0026#34;)){ throw new OrderBusinessException(\u0026#34;收货地址解析失败\u0026#34;); } //数据解析 location = jsonObject.getJSONObject(\u0026#34;result\u0026#34;).getJSONObject(\u0026#34;location\u0026#34;); lat = location.getString(\u0026#34;lat\u0026#34;); lng = location.getString(\u0026#34;lng\u0026#34;); //用户收货地址经纬度坐标 String userLngLat = lat + \u0026#34;,\u0026#34; + lng; map.put(\u0026#34;origin\u0026#34;,shopLngLat); map.put(\u0026#34;destination\u0026#34;,userLngLat); map.put(\u0026#34;steps_info\u0026#34;,\u0026#34;0\u0026#34;); //路线规划 String json = HttpClientUtil.doGet(\u0026#34;https://api.map.baidu.com/directionlite/v1/driving\u0026#34;, map); jsonObject = JSON.parseObject(json); if(!jsonObject.getString(\u0026#34;status\u0026#34;).equals(\u0026#34;0\u0026#34;)){ throw new OrderBusinessException(\u0026#34;配送路线规划失败\u0026#34;); } //数据解析 JSONObject result = jsonObject.getJSONObject(\u0026#34;result\u0026#34;); JSONArray jsonArray = (JSONArray) result.get(\u0026#34;routes\u0026#34;); Integer distance = (Integer) ((JSONObject) jsonArray.get(0)).get(\u0026#34;distance\u0026#34;); if(distance \u0026gt; 5000){ //配送距离超过5000米 throw new OrderBusinessException(\u0026#34;超出配送范围\u0026#34;); } } 在OrderServiceImpl的submitOrder方法中调用上面的校验方法：\n订单状态定时处理、来单提醒和客户催单 Spring Task Spring Task 是Spring框架提供的任务调度工具，可以按照约定的时间自动执行某个代码逻辑。\n定位：定时任务框架\n作用：定时自动执行某段Java代码\n介绍 应用场景：\n信用卡每月还卡提醒 银行贷款每月还款提醒 火车票售票系统处理未支付订单 入职纪念日为用户发送通知 cron表达式 cron表达式其实就是一个字符串，通过cron表达式可以定义任务触发的时间\n构成规则：分为6或7个域，由空格分隔开，每个域代表一个含义\n每个域的含义分别为：秒、分钟、小时、日、月、周、年(可选) 周 和 日互斥，只能选择其一，另外一个选择？\n2022年10月12日上午9点整 对应的cron表达式： 0 0 9 12 10 ？2022\n入门案例 Spring Task使用步骤：\n导入Maven坐标 spring-context 启动类添加注解@EnableScheduling开启任务调度 自定义定时任务类 订单状态定时处理 需求分析和设计 用户下单后可能存在的情况：\n下单未支付，订单一直处于“未支付”状态 用户收货后管理端未点击完成按钮，订单一直处于“派送中”状态 对于上面两种情况需要通过定时任务来修改订单状态，具体逻辑为：\n通过定时任务每分钟检查一次是否存在支付超时订单（下单后超过15分钟仍未支付则判定为支付超时订单），如果存在则修改订单状态为“已取消” 通过定时任务每天凌晨1点检查一次是否存在“派送中”的订单，如果存在则修改订单状态为“已完成” 代码开发 功能测试 WebSocket 介绍 WebSocket 是基于 TCP 的一种新的网络协议。它实现了浏览器与服务器全双工通信——浏览器和服务器只需要完成一次握手，两者之间就可以创建持久性的连接，并进行双向数据传输。\nHTTP协议和WebSocket协议对比：\nHTTP是短连接 WebSocket是长连接 HTTP通信是单向的，基于请求响应模式 WebSocket支持双向通信 HTTP和WebSocket底层都是TCP连接 应用场景\n视频弹幕 网页聊天 体育实况更新 股票基金报价实时更新 效果展示：\n入门案例 实现步骤：\n直接使用websocket.html页面作为WebSocket客户端 导入WebSocket的maven坐标 导入WebSocket服务端组建WebSocketServer，用于和客户端通信 导入配置类WebSocketConfiguration，注册WebSocket的服务端组件 导入定时任务类WebSocketTask，定时向客户端推送数据 来单提醒 需求分析和设计 用户下单并且支付成功后需要第一时间通知外卖商家。通知的形式有如下两种：\n语音播报 弹出提示框 设计：\n通过WebSocket实现管理端页面和服务端页面保持长连接状态 当客户支付后，调用WebSocket的相关API实现服务端向管理端推送消息 管理端浏览器解析服务端推送的消息，判断是来单提醒还是客户催单，进行相应的消息提示和语音播报 约定服务端发送给客户端浏览器的数据格式为JSON，字段包括：type、orderid、content type 为消息类型，1为来单提醒，2为客户催单 orderid 为订单id content 为消息内容 代码开发 功能测试 客户催单 需求分析和设计 用户在小程序中点击催单按钮后，需要第一时间通知外卖商家。通知的形式有如下两种：\n语音播报 弹出提示框 设计：\n通过WebSocket实现管理端页面和服务端页面保持长连接状态 当用户点击催单按钮后，调用WebSocket的相关API实现服务端向管理端推送消息 管理端浏览器解析服务端推送的消息，判断是来单提醒还是客户催单，进行相应的消息提示和语音播报 约定服务端发送给客户端浏览器的数据格式为JSON，字段包括：type、orderid、content type 为消息类型，1为来单提醒，2为客户催单 orderid 为订单id content 为消息内容 接口设计：\n代码开发 功能测试 数据统计-图形报表 Apache Echarts 介绍 Apache Echarts是一款基于Javascript 的数据可视化图表库，提供直观，生动，可交互，可个性化定制的数据可视化图表。\n官网地址：https://echarts.apache.org/zh/index.html\n效果展示：\n入门案例 总结:使用Echarts，重点在于研究当前图表所需的数据格式。通常是需要后端提供符合格式要求的动态数据，然后响应给前端来展示图表。\n营业额统计 需求分析和设计 产品原型：\n业务规则：\n营业额指订单状态为已完成的订单金额合计 基于可视化报表的折线图展示营业额数据，X轴为日期，Y轴为营业额 根据时间选择区间，展示每天的营业额数据 接口设计：\n代码开发 根据接口定义设计对应的VO：\n功能测试 用户统计 需求分析和设计 产品原型：\n业务规则：\n基于可视化报表的折线图展示用户数据，x轴为日期，y轴为用户数 根据时间选择区间，展示每天的用户总量和新增用户量数据 接口设计：\n代码开发 根据用户统计接口的返回结果设计VO：\n功能测试 订单统计 需求分析和设计 产品原型：\n业务规则：\n有效订单指状态为“已完成”的订单 基于可视化报表的折线图展示订单数据，X轴为日期，Y轴为订单数量 根据时间选择区间，展示每天的订单总数和有效订单数 展示所选时间区间内的有效订单数、总订单数、订单完成率，订单完成率=有效订单数/总订单数 * 100% 接口设计：\n代码开发 根据订单统计接口的返回结果设计VO：\n功能测试 销量排行Top10 需求分析和设计 产品原型：\n业务规则：\n根据时间选择区间，展示销量前10的商品（包括菜品和套餐） 基于可视化报表的柱状图降序展示商品销量 此处的销量为商品销售的份数 接口设计：\n代码开发 根据销量排名接口的返回结果设计VO：\n功能测试 数据统计-Excel报表 工作台 需求分析和设计 工作台是系统运营的数据看板，并提供快捷操作入口，可以有效提高商家的工作效率。\n工作台展示的数据：\n今日数据 订单管理 菜品总览 套餐总览 订单信息 名词解释：\n营业额：已完成订单的总金额 有效订单：已完成订单的数量 订单完成率：有效订单数、总订单数 * 100 平均客单价：营业额 / 有效订单数 新增用户：新增用户的数量 接口设计：\n今日数据接口 订单管理接口 菜品总览接口 套餐总览接口 订单搜索（已完成） 各个状态的订单数量统计（已完成） 代码导入 功能测试 Apache POI 介绍 Apache POl是一个处理Miscrosoft Office各种文件格式的开源项目。简单来说就是，我们可以使用 POl 在 Java 程序中对Miscrosoft Office各种文件进行读写操作。\n一般情况下，POI都是用于操作Excel文件。\nApache POI 的应用场景：\n银行网银系统导出交易明细 各种业务系统导出Excel报表 批量导入业务数据 入门案例 Apache POI的maven坐标：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class POITest { /** * 通过POI创建Excel文件并且写入文件内容 */ public static void write() throws Exception{ //在内存中创建一个Excel文件 XSSFWorkbook excel = new XSSFWorkbook(); //在Excel文件中创建一个sheet页 XSSFSheet sheet = excel.createSheet(\u0026#34;info\u0026#34;); //在sheet页中创建行对象，rownum编号从0开始 XSSFRow row = sheet.createRow(1); //创建单元格，并且写入文件内容 row.createCell(1).setCellValue(\u0026#34;姓名\u0026#34;); row.createCell(2).setCellValue(\u0026#34;城市\u0026#34;); //创建一个新行 row = sheet.createRow(2); row.createCell(1).setCellValue(\u0026#34;张三\u0026#34;); row.createCell(2).setCellValue(\u0026#34;北京\u0026#34;); row = sheet.createRow(3); row.createCell(1).setCellValue(\u0026#34;李四\u0026#34;); row.createCell(2).setCellValue(\u0026#34;南京\u0026#34;); //通过输出流将内存中的Excel文件写入磁盘 FileOutputStream out = new FileOutputStream(new File(\u0026#34;D:\\\\Projects\\\\info.xlsx\u0026#34;)); excel.write(out); //关闭资源 out.close(); excel.close(); } public static void main(String[] args) throws Exception { write(); } } 导出运营数据Excel报表 需求分析和设计 产品原型：\n导出的Excel报表格式：\n业务规则：\n导出Excel形式的报表文件 导出最近30天的运营数据 接口设计：\n注意：当前接口没有返回数据，因为报表导出功能本质上是文件下载，服务端会通过输出流将Excel文件下载到客户端浏览器\n代码开发 实现步骤：\n设计Excel模板文件\n查询近30天的运营数据\n将查询到的运营数据写入模板文件\n通过输出流将Excel文件下载到客户端浏览器\n","date":"2024-04-13T18:46:11+08:00","image":"https://nova-bryan.github.io/p/%E8%8B%8D%E7%A9%B9%E5%A4%96%E5%8D%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image_hu17089168107649188491.png","permalink":"https://nova-bryan.github.io/p/%E8%8B%8D%E7%A9%B9%E5%A4%96%E5%8D%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"苍穹外卖学习笔记"},{"content":"SpringBoot-配置优先级 在我们前面的课程当中，我们已经讲解了SpringBoot项目当中支持的三类配置文件：\napplication.properties application.yml application.yaml 在SpringBoot项目当中，我们要想配置一个属性，可以通过这三种方式当中的任意一种来配置都可以，那么如果项目中同时存在这三种配置文件，且都配置了同一个属性，如：Tomcat端口号，到底哪一份配置文件生效呢？\napplication.properties 1 server.port=8081 application.yml 1 2 server: port: 8082 application.yaml 1 2 server: port: 8082 我们启动SpringBoot程序，测试下三个配置文件中哪个Tomcat端口号生效：\nproperties、yaml、yml三种配置文件同时存在 properties、yaml、yml三种配置文件，优先级最高的是properties\nyaml、yml两种配置文件同时存在 配置文件优先级排名（从高到低）：\nproperties配置文件 yml配置文件 yaml配置文件 注意事项：虽然springboot支持多种格式配置文件，但是在项目开发时，推荐统一使用一种格式的配置。（yml是主流）\n在SpringBoot项目当中除了以上3种配置文件外，SpringBoot为了增强程序的扩展性，除了支持配置文件的配置方式以外，还支持另外两种常见的配置方式：\nJava系统属性配置 （格式： -Dkey=value）\n1 -Dserver.port=9000 命令行参数 （格式：\u0026ndash;key=value）\n1 --server.port=10010 那在idea当中运行程序时，如何来指定Java系统属性和命令行参数呢？\n编辑启动程序的配置信息 重启服务，同时配置Tomcat端口(三种配置文件、系统属性、命令行参数)，测试哪个Tomcat端口号生效：\n删除命令行参数配置，重启SpringBoot服务：\n优先级： 命令行参数 \u0026gt; 系统属性参数 \u0026gt; properties参数 \u0026gt; yml参数 \u0026gt; yaml参数\n思考：如果项目已经打包上线了，这个时候我们又如何来设置Java系统属性和命令行参数呢？\n1 java -Dserver.port=9000 -jar XXXXX.jar --server.port=10010 下面我们来演示下打包程序运行时指定Java系统属性和命令行参数：\n执行maven打包指令package，把项目打成jar文件 使用命令：java -jar 方式运行jar文件程序 项目打包：\n运行jar程序：\n同时设置Java系统属性和命令行参数 仅设置Java系统属性 注意事项：\nSpringboot项目进行打包时，需要引入插件 spring-boot-maven-plugin (基于官网骨架创建项目，会自动添加该插件) 在SpringBoot项目当中，常见的属性配置方式有5种， 3种配置文件，加上2种外部属性的配置(Java系统属性、命令行参数)。通过以上的测试，我们也得出了优先级(从低到高)：\napplication.yaml（忽略） application.yml application.properties java系统属性（-Dxxx=xxx） 命令行参数（\u0026ndash;xxx=xxx） bean的管理-bean的获取 在前面的课程当中，我们已经讲过了我们可以通过Spring当中提供的注解@Component以及它的三个衍生注解（@Controller、@Service、@Repository）来声明IOC容器中的bean对象，同时我们也学习了如何为应用程序注入运行时所需要依赖的bean对象，也就是依赖注入DI。\n我们今天主要学习IOC容器中Bean的其他使用细节，主要学习以下三方面：\n如何从IOC容器中手动的获取到bean对象 bean的作用域配置 管理第三方的bean对象 默认情况下，SpringBoot项目在启动的时候会自动的创建IOC容器(也称为Spring容器)，并且在启动的过程当中会自动的将bean对象都创建好，存放在IOC容器当中。应用程序在运行时需要依赖什么bean对象，就直接进行依赖注入就可以了。\n而在Spring容器中提供了一些方法，可以主动从IOC容器中获取到bean对象，下面介绍3种常用方式：\n根据name获取bean\n1 Object getBean(String name) 根据类型获取bean\n1 \u0026lt;T\u0026gt; T getBean(Class\u0026lt;T\u0026gt; requiredType) 根据name获取bean（带类型转换）\n1 \u0026lt;T\u0026gt; T getBean(String name, Class\u0026lt;T\u0026gt; requiredType) 思考：要从IOC容器当中来获取到bean对象，需要先拿到IOC容器对象，怎么样才能拿到IOC容器呢？\n想获取到IOC容器，直接将IOC容器对象注入进来就可以了 控制器：DeptController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @RestController @RequestMapping(\u0026#34;/depts\u0026#34;) public class DeptController { @Autowired private DeptService deptService; public DeptController(){ System.out.println(\u0026#34;DeptController constructor ....\u0026#34;); } @GetMapping public Result list(){ List\u0026lt;Dept\u0026gt; deptList = deptService.list(); return Result.success(deptList); } @DeleteMapping(\u0026#34;/{id}\u0026#34;) public Result delete(@PathVariable Integer id) { deptService.delete(id); return Result.success(); } @PostMapping public Result save(@RequestBody Dept dept){ deptService.save(dept); return Result.success(); } } 业务实现类：DeptServiceImpl\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Slf4j @Service public class DeptServiceImpl implements DeptService { @Autowired private DeptMapper deptMapper; @Override public List\u0026lt;Dept\u0026gt; list() { List\u0026lt;Dept\u0026gt; deptList = deptMapper.list(); return deptList; } @Override public void delete(Integer id) { deptMapper.delete(id); } @Override public void save(Dept dept) { dept.setCreateTime(LocalDateTime.now()); dept.setUpdateTime(LocalDateTime.now()); deptMapper.save(dept); } } Mapper接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Mapper public interface DeptMapper { //查询全部部门数据 @Select(\u0026#34;select * from dept\u0026#34;) List\u0026lt;Dept\u0026gt; list(); //删除部门 @Delete(\u0026#34;delete from dept where id = #{id}\u0026#34;) void delete(Integer id); //新增部门 @Insert(\u0026#34;insert into dept(name, create_time, update_time) values (#{name},#{createTime},#{updateTime})\u0026#34;) void save(Dept dept); } 测试类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @SpringBootTest class SpringbootWebConfig2ApplicationTests { @Autowired private ApplicationContext applicationContext; //IOC容器对象 //获取bean对象 @Test public void testGetBean(){ //根据bean的名称获取 DeptController bean1 = (DeptController) applicationContext.getBean(\u0026#34;deptController\u0026#34;); System.out.println(bean1); //根据bean的类型获取 DeptController bean2 = applicationContext.getBean(DeptController.class); System.out.println(bean2); //根据bean的名称 及 类型获取 DeptController bean3 = applicationContext.getBean(\u0026#34;deptController\u0026#34;, DeptController.class); System.out.println(bean3); } } 程序运行后控制台日志：\n问题：输出的bean对象地址值是一样的，说明IOC容器当中的bean对象有几个？\n答案：只有一个。 （默认情况下，IOC中的bean对象是单例）\n那么能不能将bean对象设置为非单例的(每次获取的bean都是一个新对象)？\n可以，在下一个知识点(bean作用域)中讲解。\n注意事项：\n上述所说的 【Spring项目启动时，会把其中的bean都创建好】还会受到作用域及延迟初始化影响，这里主要针对于默认的单例非延迟加载的bean而言。 bean的管理-bean的作用域 在前面我们提到的IOC容器当中，默认bean对象是单例模式(只有一个实例对象)。那么如何设置bean对象为非单例呢？需要设置bean的作用域。\n在Spring中支持五种作用域，后三种在web环境才生效：\n作用域 说明 singleton 容器内同名称的bean只有一个实例（单例）（默认） prototype 每次使用该bean时会创建新的实例（非单例） request 每个请求范围内会创建新的实例（web环境中，了解） session 每个会话范围内会创建新的实例（web环境中，了解） application 每个应用范围内会创建新的实例（web环境中，了解） 知道了bean的5种作用域了，我们要怎么去设置一个bean的作用域呢？\n可以借助Spring中的@Scope注解来进行配置作用域 1). 测试一\n控制器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //默认bean的作用域为：singleton (单例) @Lazy //延迟加载（第一次使用bean对象时，才会创建bean对象并交给ioc容器管理） @RestController @RequestMapping(\u0026#34;/depts\u0026#34;) public class DeptController { @Autowired private DeptService deptService; public DeptController(){ System.out.println(\u0026#34;DeptController constructor ....\u0026#34;); } //省略其他代码... } 测试类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @SpringBootTest class SpringbootWebConfig2ApplicationTests { @Autowired private ApplicationContext applicationContext; //IOC容器对象 //bean的作用域 @Test public void testScope(){ for (int i = 0; i \u0026lt; 10; i++) { DeptController deptController = applicationContext.getBean(DeptController.class); System.out.println(deptController); } } } 重启SpringBoot服务，运行测试方法，查看控制台打印的日志：\n注意事项：\nIOC容器中的bean默认使用的作用域：singleton (单例) 默认singleton的bean，在容器启动时被创建，可以使用@Lazy注解来延迟初始化(延迟到第一次使用时) 2). 测试二\n修改控制器DeptController代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Scope(\u0026#34;prototype\u0026#34;) //bean作用域为非单例 @Lazy //延迟加载 @RestController @RequestMapping(\u0026#34;/depts\u0026#34;) public class DeptController { @Autowired private DeptService deptService; public DeptController(){ System.out.println(\u0026#34;DeptController constructor ....\u0026#34;); } //省略其他代码... } 重启SpringBoot服务，再次执行测试方法，查看控制吧打印的日志：\n注意事项：\nprototype的bean，每一次使用该bean的时候都会创建一个新的实例 实际开发当中，绝大部分的Bean是单例的，也就是说绝大部分Bean不需要配置scope属性 bean的管理-第三方bean 学习完bean的获取、bean的作用域之后，接下来我们再来学习第三方bean的配置。\n之前我们所配置的bean，像controller、service，dao三层体系下编写的类，这些类都是我们在项目当中自己定义的类(自定义类)。当我们要声明这些bean，也非常简单，我们只需要在类上加上@Component以及它的这三个衍生注解（@Controller、@Service、@Repository），就可以来声明这个bean对象了。 但是在我们项目开发当中，还有一种情况就是这个类它不是我们自己编写的，而是我们引入的第三方依赖当中提供的。\n在pom.xml文件中，引入dom4j：\n1 2 3 4 5 6 \u0026lt;!--Dom4j--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.dom4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dom4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; dom4j就是第三方组织提供的。 dom4j中的SAXReader类就是第三方编写的。\n当我们需要使用到SAXReader对象时，直接进行依赖注入是不是就可以了呢？\n按照我们之前的做法，需要在SAXReader类上添加一个注解@Component（将当前类交给IOC容器管理） 结论：第三方提供的类是只读的。无法在第三方类上添加@Component注解或衍生注解。\n那么我们应该怎样使用并定义第三方的bean呢？\n如果要管理的bean对象来自于第三方（不是自定义的），是无法用@Component 及衍生注解声明bean的，就需要用到**@Bean**注解。 解决方案1：在启动类上添加@Bean标识的方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 @SpringBootApplication public class SpringbootWebConfig2Application { public static void main(String[] args) { SpringApplication.run(SpringbootWebConfig2Application.class, args); } //声明第三方bean @Bean //将当前方法的返回值对象交给IOC容器管理, 成为IOC容器bean public SAXReader saxReader(){ return new SAXReader(); } } xml文件：\n1 2 3 4 5 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;emp\u0026gt; \u0026lt;name\u0026gt;Tom\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;18\u0026lt;/age\u0026gt; \u0026lt;/emp\u0026gt; 测试类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @SpringBootTest class SpringbootWebConfig2ApplicationTests { @Autowired private SAXReader saxReader; //第三方bean的管理 @Test public void testThirdBean() throws Exception { Document document = saxReader.read(this.getClass().getClassLoader().getResource(\u0026#34;1.xml\u0026#34;)); Element rootElement = document.getRootElement(); String name = rootElement.element(\u0026#34;name\u0026#34;).getText(); String age = rootElement.element(\u0026#34;age\u0026#34;).getText(); System.out.println(name + \u0026#34; : \u0026#34; + age); } //省略其他代码... } 重启SpringBoot服务，执行测试方法后，控制台输出日志：\n1 Tom : 18 说明：以上在启动类中声明第三方Bean的作法，不建议使用（项目中要保证启动类的纯粹性）\n解决方案2：在配置类中定义@Bean标识的方法\n如果需要定义第三方Bean时， 通常会单独定义一个配置类 1 2 3 4 5 6 7 8 9 10 11 12 @Configuration //配置类 (在配置类当中对第三方bean进行集中的配置管理) public class CommonConfig { //声明第三方bean @Bean //将当前方法的返回值对象交给IOC容器管理, 成为IOC容器bean //通过@Bean注解的name/value属性指定bean名称, 如果未指定, 默认是方法名 public SAXReader reader(DeptService deptService){ System.out.println(deptService); return new SAXReader(); } } 注释掉SpringBoot启动类中创建第三方bean对象的代码，重启服务，执行测试方法，查看控制台日志：\n1 Tom : 18 在方法上加上一个@Bean注解，Spring 容器在启动的时候，它会自动的调用这个方法，并将方法的返回值声明为Spring容器当中的Bean对象。\n注意事项 ：\n通过@Bean注解的name或value属性可以声明bean的名称，如果不指定，默认bean的名称就是方法名。 如果第三方bean需要依赖其它bean对象，直接在bean定义方法中设置形参即可，容器会根据类型自动装配。 关于Bean大家只需要保持一个原则：\n如果是在项目当中我们自己定义的类，想将这些类交给IOC容器管理，我们直接使用@Component以及它的衍生注解来声明就可以。 如果这个类它不是我们自己定义的，而是引入的第三方依赖当中提供的类，而且我们还想将这个类交给IOC容器管理。此时我们就需要在配置类中定义一个方法，在方法上加上一个@Bean注解，通过这种方式来声明第三方的bean对象。 SpringBoot原理-起步依赖 经过前面10多天课程的学习，大家也会发现基于SpringBoot进行web程序的开发是非常简单、非常高效的。\nSpringBoot使我们能够集中精力地去关注业务功能的开发，而不用过多地关注框架本身的配置使用。而我们前面所讲解的都是面向应用层面的技术，接下来我们开始学习SpringBoot的原理，这部分内容偏向于底层的原理分析。\n在剖析SpringBoot的原理之前，我们先来快速回顾一下我们前面所讲解的Spring家族的框架。\nSpring是目前世界上最流行的Java框架，它可以帮助我们更加快速、更加容易的来构建Java项目。而在Spring家族当中提供了很多优秀的框架，而所有的框架都是基于一个基础框架的SpringFramework(也就是Spring框架)。而前面我们也提到，如果我们直接基于Spring框架进行项目的开发，会比较繁琐。\n这个繁琐主要体现在两个地方：\n在pom.xml中依赖配置比较繁琐，在项目开发时，需要自己去找到对应的依赖，还需要找到依赖它所配套的依赖以及对应版本，否则就会出现版本冲突问题。 在使用Spring框架进行项目开发时，需要在Spring的配置文件中做大量的配置，这就造成Spring框架入门难度较大，学习成本较高。 基于Spring存在的问题，官方在Spring框架4.0版本之后，又推出了一个全新的框架：SpringBoot。\n通过 SpringBoot来简化Spring框架的开发(是简化不是替代)。我们直接基于SpringBoot来构建Java项目，会让我们的项目开发更加简单，更加快捷。\nSpringBoot框架之所以使用起来更简单更快捷，是因为SpringBoot框架底层提供了两个非常重要的功能：一个是起步依赖，一个是自动配置。\n通过SpringBoot所提供的起步依赖，就可以大大的简化pom文件当中依赖的配置，从而解决了Spring框架当中依赖配置繁琐的问题。\n通过自动配置的功能就可以大大的简化框架在使用时bean的声明以及bean的配置。我们只需要引入程序开发时所需要的起步依赖，项目开发时所用到常见的配置都已经有了，我们直接使用就可以了。\n简单回顾之后，接下来我们来学习下SpringBoot的原理。其实学习SpringBoot的原理就是来解析SpringBoot当中的起步依赖与自动配置的原理。我们首先来学习SpringBoot当中起步依赖的原理。\n起步依赖\n假如我们没有使用SpringBoot，用的是Spring框架进行web程序的开发，此时我们就需要引入web程序开发所需要的一些依赖。\nspring-webmvc依赖：这是Spring框架进行web程序开发所需要的依赖\nservlet-api依赖：Servlet基础依赖\njackson-databind依赖：JSON处理工具包\n如果要使用AOP，还需要引入aop依赖、aspect依赖\n项目中所引入的这些依赖，还需要保证版本匹配，否则就可能会出现版本冲突问题。\n如果我们使用了SpringBoot，就不需要像上面这么繁琐的引入依赖了。我们只需要引入一个依赖就可以了，那就是web开发的起步依赖：springboot-starter-web。\n为什么我们只需要引入一个web开发的起步依赖，web开发所需要的所有的依赖都有了呢？\n因为Maven的依赖传递。 在SpringBoot给我们提供的这些起步依赖当中，已提供了当前程序开发所需要的所有的常见依赖(官网地址：https://docs.spring.io/spring-boot/docs/2.7.7/reference/htmlsingle/#using.build-systems.starters)。 比如：springboot-starter-web，这是web开发的起步依赖，在web开发的起步依赖当中，就集成了web开发中常见的依赖：json、web、webmvc、tomcat等。我们只需要引入这一个起步依赖，其他的依赖都会自动的通过Maven的依赖传递进来。 结论：起步依赖的原理就是Maven的依赖传递。\nSpringBoot原理-自动配置-概述 自动配置\n我们讲解了SpringBoot当中起步依赖的原理，就是Maven的依赖传递。接下来我们解析下自动配置的原理，我们要分析自动配置的原理，首先要知道什么是自动配置。\nSpringBoot的自动配置就是当Spring容器启动后，一些配置类、bean对象就自动存入到了IOC容器中，不需要我们手动去声明，从而简化了开发，省去了繁琐的配置操作。\n比如：我们要进行事务管理、要进行AOP程序的开发，此时就不需要我们再去手动的声明这些bean对象了，我们直接使用就可以从而大大的简化程序的开发，省去了繁琐的配置操作。\n下面我们打开idea，一起来看下自动配置的效果：\n运行SpringBoot启动类 大家会看到有两个CommonConfig，在第一个CommonConfig类中定义了一个bean对象，bean对象的名字叫reader。\n在第二个CommonConfig中它的bean名字叫commonConfig，为什么还会有这样一个bean对象呢？原因是在CommonConfig配置类上添加了一个注解@Configuration，而@Configuration底层就是@Component\n所以配置类最终也是SpringIOC容器当中的一个bean对象\n在IOC容器中除了我们自己定义的bean以外，还有很多配置类，这些配置类都是SpringBoot在启动的时候加载进来的配置类。这些配置类加载进来之后，它也会生成很多的bean对象。\n比如：配置类GsonAutoConfiguration里面有一个bean，bean的名字叫gson，它的类型是Gson。\ncom.google.gson.Gson是谷歌包中提供的用来处理JSON格式数据的。\n当我们想要使用这些配置类中生成的bean对象时，可以使用@Autowired就自动注入了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import com.google.gson.Gson; import com.itheima.pojo.Result; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest public class AutoConfigurationTests { @Autowired private Gson gson; @Test public void testJson(){ String json = gson.toJson(Result.success()); System.out.println(json); } } 添加断点，使用debug模式运行测试类程序：\n问题：在当前项目中我们并没有声明谷歌提供的Gson这么一个bean对象，然后我们却可以通过@Autowired从Spring容器中注入bean对象，那么这个bean对象怎么来的？\n答案：SpringBoot项目在启动时通过自动配置完成了bean对象的创建。\n体验了SpringBoot的自动配置了，下面我们就来分析自动配置的原理。其实分析自动配置原理就是来解析在SpringBoot项目中，在引入依赖之后是如何将依赖jar包当中所定义的配置类以及bean加载到SpringIOC容器中的。\nSpringBoot原理-自动配置-方案 我们知道了什么是自动配置之后，接下来我们就要来剖析自动配置的原理。解析自动配置的原理就是分析在 SpringBoot项目当中，我们引入对应的依赖之后，是如何将依赖jar包当中所提供的bean以及配置类直接加载到当前项目的SpringIOC容器当中的。\n接下来，我们就直接通过代码来分析自动配置原理。\n准备工作：在Idea中导入\u0026quot;资料\\03. 自动配置原理\u0026quot;下的itheima-utils工程\n1、在SpringBoot项目 spring-boot-web-config2 工程中，通过坐标引入itheima-utils依赖\n1 2 3 4 5 6 @Component public class TokenParser { public void parse(){ System.out.println(\u0026#34;TokenParser ... parse ...\u0026#34;); } } 2、在测试类中，添加测试方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @SpringBootTest public class AutoConfigurationTests { @Autowired private ApplicationContext applicationContext; @Test public void testTokenParse(){ System.out.println(applicationContext.getBean(TokenParser.class)); } //省略其他代码... } 3、执行测试方法\n异常信息描述： 没有com.example.TokenParse类型的bean\n说明：在Spring容器中没有找到com.example.TokenParse类型的bean对象\n思考：引入进来的第三方依赖当中的bean以及配置类为什么没有生效？\n原因在我们之前讲解IOC的时候有提到过，在类上添加@Component注解来声明bean对象时，还需要保证@Component注解能被Spring的组件扫描到。 SpringBoot项目中的@SpringBootApplication注解，具有包扫描的作用，但是它只会扫描启动类所在的当前包以及子包。 当前包：com.itheima， 第三方依赖中提供的包：com.example（扫描不到） 那么如何解决以上问题的呢？\n方案1：@ComponentScan 组件扫描 方案2：@Import 导入（使用@Import导入的类会被Spring加载到IOC容器中） 方案一\n@ComponentScan组件扫描\n1 2 3 4 5 6 7 @SpringBootApplication @ComponentScan({\u0026#34;com.itheima\u0026#34;,\u0026#34;com.example\u0026#34;}) //指定要扫描的包 public class SpringbootWebConfig2Application { public static void main(String[] args) { SpringApplication.run(SpringbootWebConfig2Application.class, args); } } 重新执行测试方法，控制台日志输出：\n大家可以想象一下，如果采用以上这种方式来完成自动配置，那我们进行项目开发时，当需要引入大量的第三方的依赖，就需要在启动类上配置N多要扫描的包，这种方式会很繁琐。而且这种大面积的扫描性能也比较低。\n缺点：\n使用繁琐 性能低 结论：SpringBoot中并没有采用以上这种方案。\n方案二\n@Import导入\n导入形式主要有以下几种： 导入普通类 导入配置类 导入ImportSelector接口实现类 1). 使用@Import导入普通类：\n1 2 3 4 5 6 7 @Import(TokenParser.class) //导入的类会被Spring加载到IOC容器中 @SpringBootApplication public class SpringbootWebConfig2Application { public static void main(String[] args) { SpringApplication.run(SpringbootWebConfig2Application.class, args); } } 重新执行测试方法，控制台日志输出：\n2). 使用@Import导入配置类：\n配置类 1 2 3 4 5 6 7 8 9 10 11 12 @Configuration public class HeaderConfig { @Bean public HeaderParser headerParser(){ return new HeaderParser(); } @Bean public HeaderGenerator headerGenerator(){ return new HeaderGenerator(); } } 启动类 1 2 3 4 5 6 7 @Import(HeaderConfig.class) //导入配置类 @SpringBootApplication public class SpringbootWebConfig2Application { public static void main(String[] args) { SpringApplication.run(SpringbootWebConfig2Application.class, args); } } 测试类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @SpringBootTest public class AutoConfigurationTests { @Autowired private ApplicationContext applicationContext; @Test public void testHeaderParser(){ System.out.println(applicationContext.getBean(HeaderParser.class)); } @Test public void testHeaderGenerator(){ System.out.println(applicationContext.getBean(HeaderGenerator.class)); } //省略其他代码... } 执行测试方法：\n3). 使用@Import导入ImportSelector接口实现类：\nImportSelector接口实现类 1 2 3 4 5 6 public class MyImportSelector implements ImportSelector { public String[] selectImports(AnnotationMetadata importingClassMetadata) { //返回值字符串数组（数组中封装了全限定名称的类） return new String[]{\u0026#34;com.example.HeaderConfig\u0026#34;}; } } 启动类 1 2 3 4 5 6 7 8 @Import(MyImportSelector.class) //导入ImportSelector接口实现类 @SpringBootApplication public class SpringbootWebConfig2Application { public static void main(String[] args) { SpringApplication.run(SpringbootWebConfig2Application.class, args); } } 执行测试方法：\n我们使用@Import注解通过这三种方式都可以导入第三方依赖中所提供的bean或者是配置类。\n思考：如果基于以上方式完成自动配置，当要引入一个第三方依赖时，是不是还要知道第三方依赖中有哪些配置类和哪些Bean对象？\n答案：是的。 （对程序员来讲，很不友好，而且比较繁琐） 思考：当我们要使用第三方依赖，依赖中到底有哪些bean和配置类，谁最清楚？\n答案：第三方依赖自身最清楚。 结论：我们不用自己指定要导入哪些bean对象和配置类了，让第三方依赖它自己来指定。\n怎么让第三方依赖自己指定bean对象和配置类？\n比较常见的方案就是第三方依赖给我们提供一个注解，这个注解一般都以@EnableXxxx开头的注解，注解中封装的就是@Import注解 4). 使用第三方依赖提供的 @EnableXxxxx注解\n第三方依赖中提供的注解 1 2 3 4 5 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Import(MyImportSelector.class)//指定要导入哪些bean对象或配置类 public @interface EnableHeaderConfig { } 在使用时只需在启动类上加上@EnableXxxxx注解即可 1 2 3 4 5 6 7 @EnableHeaderConfig //使用第三方依赖提供的Enable开头的注解 @SpringBootApplication public class SpringbootWebConfig2Application { public static void main(String[] args) { SpringApplication.run(SpringbootWebConfig2Application.class, args); } } 执行测试方法：\n以上四种方式都可以完成导入操作，但是第4种方式会更方便更优雅，而这种方式也是SpringBoot当中所采用的方式。\nSpringBoot原理-自动配置-原理分析-源码跟踪 前面我们讲解了在项目当中引入第三方依赖之后，如何加载第三方依赖中定义好的bean对象以及配置类，从而完成自动配置操作。那下面我们通过源码跟踪的形式来剖析下SpringBoot底层到底是如何完成自动配置的。\n源码跟踪技巧：\n在跟踪框架源码的时候，一定要抓住关键点，找到核心流程。一定不要从头到尾一行代码去看，一个方法的去研究，一定要找到关键流程，抓住关键点，先在宏观上对整个流程或者整个原理有一个认识，有精力再去研究其中的细节。\n要搞清楚SpringBoot的自动配置原理，要从SpringBoot启动类上使用的核心注解@SpringBootApplication开始分析：\n在@SpringBootApplication注解中包含了：\n元注解（不再解释） @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan 我们先来看第一个注解：@SpringBootConfiguration\n@SpringBootConfiguration注解上使用了@Configuration，表明SpringBoot启动类就是一个配置类。\n@Indexed注解，是用来加速应用启动的（不用关心）。\n接下来再先看@ComponentScan注解：\n@ComponentScan注解是用来进行组件扫描的，扫描启动类所在的包及其子包下所有被@Component及其衍生注解声明的类。\nSpringBoot启动类，之所以具备扫描包功能，就是因为包含了@ComponentScan注解。\n最后我们来看看@EnableAutoConfiguration注解（自动配置核心注解）：\n使用@Import注解，导入了实现ImportSelector接口的实现类。\nAutoConfigurationImportSelector类是ImportSelector接口的实现类。\nAutoConfigurationImportSelector类中重写了ImportSelector接口的selectImports()方法：\nselectImports()方法底层调用getAutoConfigurationEntry()方法，获取可自动配置的配置类信息集合\ngetAutoConfigurationEntry()方法通过调用getCandidateConfigurations(annotationMetadata, attributes)方法获取在配置文件中配置的所有自动配置类的集合\ngetCandidateConfigurations方法的功能：\n获取所有基于META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports文件、META-INF/spring.factories文件中配置类的集合\nMETA-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports文件和META-INF/spring.factories文件这两个文件在哪里呢？\n通常在引入的起步依赖中，都有包含以上两个文件 在前面在给大家演示自动配置的时候，我们直接在测试类当中注入了一个叫gson的bean对象，进行JSON格式转换。虽然我们没有配置bean对象，但是我们是可以直接注入使用的。原因就是因为在自动配置类当中做了自动配置。到底是在哪个自动配置类当中做的自动配置呢？我们通过搜索来查询一下。\n在META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports配置文件中指定了第三方依赖Gson的配置类：GsonAutoConfiguration\n第三方依赖中提供的GsonAutoConfiguration类：\n在GsonAutoConfiguration类上，添加了注解@AutoConfiguration，通过查看源码，可以明确：GsonAutoConfiguration类是一个配置。\n看到这里，大家就应该明白为什么可以完成自动配置了，原理就是在配置类中定义一个@Bean标识的方法，而Spring会自动调用配置类中使用@Bean标识的方法，并把方法的返回值注册到IOC容器中。\n自动配置源码小结\n自动配置原理源码入口就是@SpringBootApplication注解，在这个注解中封装了3个注解，分别是：\n@SpringBootConfiguration 声明当前类是一个配置类 @ComponentScan 进行组件扫描（SpringBoot中默认扫描的是启动类所在的当前包及其子包） @EnableAutoConfiguration 封装了@Import注解（Import注解中指定了一个ImportSelector接口的实现类） 在实现类重写的selectImports()方法，读取当前项目下所有依赖jar包中META-INF/spring.factories、META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports两个文件里面定义的配置类（配置类中定义了@Bean注解标识的方法）。 当SpringBoot程序启动时，就会加载配置文件当中所定义的配置类，并将这些配置类信息(类的全限定名)封装到String类型的数组中，最终通过@Import注解将这些配置类全部加载到Spring的IOC容器中，交给IOC容器管理。\n最后呢给大家抛出一个问题：在META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports文件中定义的配置类非常多，而且每个配置类中又可以定义很多的bean，那这些bean都会注册到Spring的IOC容器中吗？\n答案：并不是。 在声明bean对象时，上面有加一个以@Conditional开头的注解，这种注解的作用就是按照条件进行装配，只有满足条件之后，才会将bean注册到Spring的IOC容器中（下面会详细来讲解）\nSpringBoot原理-自动配置-原理分析-@Conditional 我们在跟踪SpringBoot自动配置的源码的时候，在自动配置类声明bean的时候，除了在方法上加了一个@Bean注解以外，还会经常用到一个注解，就是以Conditional开头的这一类的注解。以Conditional开头的这些注解都是条件装配的注解。下面我们就来介绍下条件装配注解。\n@Conditional注解：\n作用：按照一定的条件进行判断，在满足给定条件后才会注册对应的bean对象到Spring的IOC容器中。 位置：方法、类 @Conditional本身是一个父注解，派生出大量的子注解： @ConditionalOnClass：判断环境中有对应字节码文件，才注册bean到IOC容器。 @ConditionalOnMissingBean：判断环境中没有对应的bean(类型或名称)，才注册bean到IOC容器。 @ConditionalOnProperty：判断配置文件中有对应属性和值，才注册bean到IOC容器。 下面我们通过代码来演示下Conditional注解的使用：\n@ConditionalOnClass注解 1 2 3 4 5 6 7 8 9 10 11 @Configuration public class HeaderConfig { @Bean @ConditionalOnClass(name=\u0026#34;io.jsonwebtoken.Jwts\u0026#34;)//环境中存在指定的这个类，才会将该bean加入IOC容器 public HeaderParser headerParser(){ return new HeaderParser(); } //省略其他代码... } pom.xml 1 2 3 4 5 6 \u0026lt;!--JWT令牌--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 测试类 1 2 3 4 5 6 7 8 9 10 11 12 @SpringBootTest public class AutoConfigurationTests { @Autowired private ApplicationContext applicationContext; @Test public void testHeaderParser(){ System.out.println(applicationContext.getBean(HeaderParser.class)); } //省略其他代码... } 执行testHeaderParser()测试方法：\n因为io.jsonwebtoken.Jwts字节码文件在启动SpringBoot程序时已存在，所以创建HeaderParser对象并注册到IOC容器中。\n@ConditionalOnMissingBean注解 1 2 3 4 5 6 7 8 9 10 11 @Configuration public class HeaderConfig { @Bean @ConditionalOnMissingBean //不存在该类型的bean，才会将该bean加入IOC容器 public HeaderParser headerParser(){ return new HeaderParser(); } //省略其他代码... } 执行testHeaderParser()测试方法：\nSpringBoot在调用@Bean标识的headerParser()前，IOC容器中是没有HeaderParser类型的bean，所以HeaderParser对象正常创建，并注册到IOC容器中。\n再次修改@ConditionalOnMissingBean注解：\n1 2 3 4 5 6 7 8 9 10 11 @Configuration public class HeaderConfig { @Bean @ConditionalOnMissingBean(name=\u0026#34;deptController2\u0026#34;)//不存在指定名称的bean，才会将该bean加入IOC容器 public HeaderParser headerParser(){ return new HeaderParser(); } //省略其他代码... } 执行testHeaderParser()测试方法：\n因为在SpringBoot环境中不存在名字叫deptController2的bean对象，所以创建HeaderParser对象并注册到IOC容器中。\n再次修改@ConditionalOnMissingBean注解：\n1 2 3 4 5 6 7 8 9 10 11 @Configuration public class HeaderConfig { @Bean @ConditionalOnMissingBean(HeaderConfig.class)//不存在指定类型的bean，才会将bean加入IOC容器 public HeaderParser headerParser(){ return new HeaderParser(); } //省略其他代码... } 1 2 3 4 5 6 7 8 9 10 11 12 @SpringBootTest public class AutoConfigurationTests { @Autowired private ApplicationContext applicationContext; @Test public void testHeaderParser(){ System.out.println(applicationContext.getBean(HeaderParser.class)); } //省略其他代码... } 执行testHeaderParser()测试方法：\n因为HeaderConfig类中添加@Configuration注解，而@Configuration注解中包含了@Component，所以SpringBoot启动时会创建HeaderConfig类对象，并注册到IOC容器中。\n当IOC容器中有HeaderConfig类型的bean存在时，不会把创建HeaderParser对象注册到IOC容器中。而IOC容器中没有HeaderParser类型的对象时，通过getBean(HeaderParser.class)方法获取bean对象时，引发异常：NoSuchBeanDefinitionException\n@ConditionalOnProperty注解（这个注解和配置文件当中配置的属性有关系） 先在application.yml配置文件中添加如下的键值对：\n1 name: itheima 在声明bean的时候就可以指定一个条件@ConditionalOnProperty\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Configuration public class HeaderConfig { @Bean @ConditionalOnProperty(name =\u0026#34;name\u0026#34;,havingValue = \u0026#34;itheima\u0026#34;)//配置文件中存在指定属性名与值，才会将bean加入IOC容器 public HeaderParser headerParser(){ return new HeaderParser(); } @Bean public HeaderGenerator headerGenerator(){ return new HeaderGenerator(); } } 执行testHeaderParser()测试方法：\n修改@ConditionalOnProperty注解： havingValue的值修改为\u0026quot;itheima2\u0026quot;\n1 2 3 4 5 @Bean @ConditionalOnProperty(name =\u0026#34;name\u0026#34;,havingValue = \u0026#34;itheima2\u0026#34;)//配置文件中存在指定属性名与值，才会将bean加入IOC容器 public HeaderParser headerParser(){ return new HeaderParser(); } 再次执行testHeaderParser()测试方法：\n因为application.yml配置文件中，不存在： name: itheima2，所以HeaderParser对象在IOC容器中不存在\n我们再回头看看之前讲解SpringBoot源码时提到的一个配置类：GsonAutoConfiguration\n最后再给大家梳理一下自动配置原理：\n自动配置的核心就在@SpringBootApplication注解上，SpringBootApplication这个注解底层包含了3个注解，分别是：\n@SpringBootConfiguration\n@ComponentScan\n@EnableAutoConfiguration\n@EnableAutoConfiguration这个注解才是自动配置的核心。\n它封装了一个@Import注解，Import注解里面指定了一个ImportSelector接口的实现类。 在这个实现类中，重写了ImportSelector接口中的selectImports()方法。 而selectImports()方法中会去读取两份配置文件，并将配置文件中定义的配置类做为selectImports()方法的返回值返回，返回值代表的就是需要将哪些类交给Spring的IOC容器进行管理。 那么所有自动配置类的中声明的bean都会加载到Spring的IOC容器中吗? 其实并不会，因为这些配置类中在声明bean时，通常都会添加@Conditional开头的注解，这个注解就是进行条件装配。而Spring会根据Conditional注解有选择性的进行bean的创建。 @Enable 开头的注解底层，它就封装了一个注解 import 注解，它里面指定了一个类，是 ImportSelector 接口的实现类。在实现类当中，我们需要去实现 ImportSelector 接口当中的一个方法 selectImports 这个方法。这个方法的返回值代表的就是我需要将哪些类交给 spring 的 IOC容器进行管理。 此时它会去读取两份配置文件，一份儿是 spring.factories，另外一份儿是 autoConfiguration.imports。而在 autoConfiguration.imports 这份儿文件当中，它就会去配置大量的自动配置的类。 而前面我们也提到过这些所有的自动配置类当中，所有的 bean都会加载到 spring 的 IOC 容器当中吗？其实并不会，因为这些配置类当中，在声明 bean 的时候，通常会加上这么一类@Conditional 开头的注解。这个注解就是进行条件装配。所以SpringBoot非常的智能，它会根据 @Conditional 注解来进行条件装配。只有条件成立，它才会声明这个bean，才会将这个 bean 交给 IOC 容器管理。 SpringBoot原理-自动配置-案例(自定义starter分析) 前面我们解析了SpringBoot中自动配置的原理，下面我们就通过一个自定义starter案例来加深大家对于自动配置原理的理解。首先介绍一下自定义starter的业务场景，再来分析一下具体的操作步骤。\n所谓starter指的就是SpringBoot当中的起步依赖。在SpringBoot当中已经给我们提供了很多的起步依赖了，我们为什么还需要自定义 starter 起步依赖？这是因为在实际的项目开发当中，我们可能会用到很多第三方的技术，并不是所有的第三方的技术官方都给我们提供了与SpringBoot整合的starter起步依赖，但是这些技术又非常的通用，在很多项目组当中都在使用。\n业务场景：\n我们前面案例当中所使用的阿里云OSS对象存储服务，现在阿里云的官方是没有给我们提供对应的起步依赖的，这个时候使用起来就会比较繁琐，我们需要引入对应的依赖。我们还需要在配置文件当中进行配置，还需要基于官方SDK示例来改造对应的工具类，我们在项目当中才可以进行使用。 大家想在我们当前项目当中使用了阿里云OSS，我们需要进行这么多步的操作。在别的项目组当中要想使用阿里云OSS，是不是也需要进行这么多步的操作，所以这个时候我们就可以自定义一些公共组件，在这些公共组件当中，我就可以提前把需要配置的bean都提前配置好。将来在项目当中，我要想使用这个技术，我直接将组件对应的坐标直接引入进来，就已经自动配置好了，就可以直接使用了。我们也可以把公共组件提供给别的项目组进行使用，这样就可以大大的简化我们的开发。 在SpringBoot项目中，一般都会将这些公共组件封装为SpringBoot当中的starter，也就是我们所说的起步依赖。\nSpringBoot官方starter命名： spring-boot-starter-xxxx\n第三组织提供的starter命名： xxxx-spring-boot-starter\nMybatis提供了配置类，并且也提供了springboot会自动读取的配置文件。当SpringBoot项目启动时，会读取到spring.factories配置文件中的配置类并加载配置类，生成相关bean对象注册到IOC容器中。\n结果：我们可以直接在SpringBoot程序中使用Mybatis自动配置的bean对象。\n在自定义一个起步依赖starter的时候，按照规范需要定义两个模块：\nstarter模块（进行依赖管理[把程序开发所需要的依赖都定义在starter起步依赖中]） autoconfigure模块（自动配置） 将来在项目当中进行相关功能开发时，只需要引入一个起步依赖就可以了，因为它会将autoconfigure自动配置的依赖给传递下来。\n上面我们简单介绍了自定义starter的场景，以及自定义starter时涉及到的模块之后，接下来我们就来完成一个自定义starter的案例。\n需求：自定义aliyun-oss-spring-boot-starter，完成阿里云OSS操作工具类AliyunOSSUtils的自动配置。\n目标：引入起步依赖引入之后，要想使用阿里云OSS，注入AliyunOSSUtils直接使用即可。\n之前阿里云OSS的使用：\n配置文件 1 2 3 4 5 6 7 #配置阿里云OSS参数 aliyun: oss: endpoint: https://oss-cn-shanghai.aliyuncs.com accessKeyId: accessKeySecret: bucketName: web-framework01 AliOSSProperties类 1 2 3 4 5 6 7 8 9 10 11 12 13 @Data @Component @ConfigurationProperties(prefix = \u0026#34;aliyun.oss\u0026#34;) public class AliOSSProperties { //区域 private String endpoint; //身份ID private String accessKeyId ; //身份密钥 private String accessKeySecret ; //存储空间 private String bucketName; } AliOSSUtils工具类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @Component //当前类对象由Spring创建和管理 public class AliOSSUtils { @Autowired private AliOSSProperties aliOSSProperties; /** * 实现上传图片到OSS */ public String upload(MultipartFile multipartFile) throws IOException { // 获取上传的文件的输入流 InputStream inputStream = multipartFile.getInputStream(); // 避免文件覆盖 String originalFilename = multipartFile.getOriginalFilename(); String fileName = UUID.randomUUID().toString() + originalFilename.substring(originalFilename.lastIndexOf(\u0026#34;.\u0026#34;)); //上传文件到 OSS OSS ossClient = new OSSClientBuilder().build(aliOSSProperties.getEndpoint(), aliOSSProperties.getAccessKeyId(), aliOSSProperties.getAccessKeySecret()); ossClient.putObject(aliOSSProperties.getBucketName(), fileName, inputStream); //文件访问路径 String url =aliOSSProperties.getEndpoint().split(\u0026#34;//\u0026#34;)[0] + \u0026#34;//\u0026#34; + aliOSSProperties.getBucketName() + \u0026#34;.\u0026#34; + aliOSSProperties.getEndpoint().split(\u0026#34;//\u0026#34;)[1] + \u0026#34;/\u0026#34; + fileName; // 关闭ossClient ossClient.shutdown(); return url;// 把上传到oss的路径返回 } } 当我们在项目当中要使用阿里云OSS，就可以注入AliOSSUtils工具类来进行文件上传。但这种方式其实是比较繁琐的。\n大家再思考，现在我们使用阿里云OSS，需要做这么几步，将来大家在开发其他的项目的时候，你使用阿里云OSS，这几步你要不要做？当团队中其他小伙伴也在使用阿里云OSS的时候，步骤 不也是一样的。\n所以这个时候我们就可以制作一个公共组件(自定义starter)。starter定义好之后，将来要使用阿里云OSS进行文件上传，只需要将起步依赖引入进来之后，就可以直接注入AliOSSUtils使用了。\n需求明确了，接下来我们再来分析一下具体的实现步骤：\n第1步：创建自定义starter模块（进行依赖管理） 把阿里云OSS所有的依赖统一管理起来 第2步：创建autoconfigure模块 在starter中引入autoconfigure （我们使用时只需要引入starter起步依赖即可） 第3步：在autoconfigure中完成自动配置 定义一个自动配置类，在自动配置类中将所要配置的bean都提前配置好 定义配置文件，把自动配置类的全类名定义在配置文件中 我们分析完自定义阿里云OSS自动配置的操作步骤了，下面我们就按照分析的步骤来实现自定义starter。\nSpringBoot原理-自动配置-案例(自定义starter实现) 自定义starter的步骤我们刚才已经分析了，接下来我们就按照分析的步骤来完成自定义starter的开发。\n首先我们先来创建两个Maven模块：\n1). aliyun-oss-spring-boot-starter模块\n创建完starter模块后，删除多余的文件，最终保留内容如下：\n删除pom.xml文件中多余的内容后：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.5\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.oss\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-oss-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;11\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 2). aliyun-oss-spring-boot-autoconfigure模块\n创建完starter模块后，删除多余的文件，最终保留内容如下：\n删除pom.xml文件中多余的内容后：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.5\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.oss\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-oss-spring-boot-autoconfigure\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;11\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 按照我们之前的分析，是需要在starter模块中来引入autoconfigure这个模块的。打开starter模块中的pom文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.5\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.oss\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-oss-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;11\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--引入autoconfigure模块--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.oss\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-oss-spring-boot-autoconfigure\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 前两步已经完成了，接下来是最关键的就是第三步：\n在autoconfigure模块当中来完成自动配置操作。\n我们将之前案例中所使用的阿里云OSS部分的代码直接拷贝到autoconfigure模块下，然后进行改造就行了。\n拷贝过来后，还缺失一些相关的依赖，需要把相关依赖也拷贝过来：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.5\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.oss\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-oss-spring-boot-autoconfigure\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;11\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--引入web起步依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--Lombok--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--阿里云OSS--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.oss\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-sdk-oss\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.15.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.xml.bind\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jaxb-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.activation\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;activation\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- no more than 2.3.3--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.glassfish.jaxb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jaxb-runtime\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 现在大家思考下，在类上添加的@Component注解还有用吗？\n答案：没用了。 在SpringBoot项目中，并不会去扫描com.aliyun.oss这个包，不扫描这个包那类上的注解也就失去了作用。\n@Component注解不需要使用了，可以从类上删除了。\n删除后报红色错误，暂时不理会，后面再来处理。\n删除AliOSSUtils类中的@Component注解、@Autowired注解\n下面我们就要定义一个自动配置类了，在自动配置类当中来声明AliOSSUtils的bean对象。\nAliOSSAutoConfiguration类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 @Configuration//当前类为Spring配置类 @EnableConfigurationProperties(AliOSSProperties.class)//导入AliOSSProperties类，并交给SpringIOC管理 public class AliOSSAutoConfiguration { //创建AliOSSUtils对象，并交给SpringIOC容器 @Bean public AliOSSUtils aliOSSUtils(AliOSSProperties aliOSSProperties){ AliOSSUtils aliOSSUtils = new AliOSSUtils(); aliOSSUtils.setAliOSSProperties(aliOSSProperties); return aliOSSUtils; } } AliOSSProperties类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 /*阿里云OSS相关配置*/ @Data @ConfigurationProperties(prefix = \u0026#34;aliyun.oss\u0026#34;) public class AliOSSProperties { //区域 private String endpoint; //身份ID private String accessKeyId ; //身份密钥 private String accessKeySecret ; //存储空间 private String bucketName; } AliOSSUtils类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Data public class AliOSSUtils { private AliOSSProperties aliOSSProperties; /** * 实现上传图片到OSS */ public String upload(MultipartFile multipartFile) throws IOException { // 获取上传的文件的输入流 InputStream inputStream = multipartFile.getInputStream(); // 避免文件覆盖 String originalFilename = multipartFile.getOriginalFilename(); String fileName = UUID.randomUUID().toString() + originalFilename.substring(originalFilename.lastIndexOf(\u0026#34;.\u0026#34;)); //上传文件到 OSS OSS ossClient = new OSSClientBuilder().build(aliOSSProperties.getEndpoint(), aliOSSProperties.getAccessKeyId(), aliOSSProperties.getAccessKeySecret()); ossClient.putObject(aliOSSProperties.getBucketName(), fileName, inputStream); //文件访问路径 String url =aliOSSProperties.getEndpoint().split(\u0026#34;//\u0026#34;)[0] + \u0026#34;//\u0026#34; + aliOSSProperties.getBucketName() + \u0026#34;.\u0026#34; + aliOSSProperties.getEndpoint().split(\u0026#34;//\u0026#34;)[1] + \u0026#34;/\u0026#34; + fileName; // 关闭ossClient ossClient.shutdown(); return url;// 把上传到oss的路径返回 } } 在aliyun-oss-spring-boot-autoconfigure模块中的resources下，新建自动配置文件：\nMETA-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports 1 com.aliyun.oss.AliOSSAutoConfiguration 自定义starter测试\n阿里云OSS的starter我们刚才已经定义好了，接下来我们就来做一个测试。\n今天的课程资料当中，提供了一个自定义starter的测试工程。我们直接打开文件夹，里面有一个测试工程。测试工程就是springboot-autoconfiguration-test，我们只需要将测试工程直接导入到Idea当中即可。\n测试前准备：\n在test工程中引入阿里云starter依赖 通过依赖传递，会把autoconfigure依赖也引入了 1 2 3 4 5 6 \u0026lt;!--引入阿里云OSS起步依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.oss\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-oss-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 在test工程中的application.yml文件中，配置阿里云OSS配置参数信息（从以前的工程中拷贝即可）\n1 2 3 4 5 6 7 #配置阿里云OSS参数 aliyun: oss: endpoint: https://oss-cn-shanghai.aliyuncs.com accessKeyId: accessKeySecret: bucketName: web-framework01 3. 在test工程中的UploadController类编写代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @RestController public class UploadController { @Autowired private AliOSSUtils aliOSSUtils; @PostMapping(\u0026#34;/upload\u0026#34;) public String upload(MultipartFile image) throws Exception { //上传文件到阿里云 OSS String url = aliOSSUtils.upload(image); return url; } } 编写完代码后，我们启动当前的SpringBoot测试工程：\n随着SpringBoot项目启动，自动配置会把AliOSSUtils的bean对象装配到IOC容器中 用postman工具进行文件上传：\n通过断点可以看到自动注入AliOSSUtils的bean对象：\nWeb后端开发-总结 到此基于SpringBoot进行web后端开发的相关知识我们已经学习完毕了。下面我们一起针对这段web课程做一个总结。\n我们来回顾一下关于web后端开发，我们都学习了哪些内容，以及每一块知识，具体是属于哪个框架的。\nweb后端开发现在基本上都是基于标准的三层架构进行开发的，在三层架构当中，Controller控制器层负责接收请求响应数据，Service业务层负责具体的业务逻辑处理，而Dao数据访问层也叫持久层，就是用来处理数据访问操作的，来完成数据库当中数据的增删改查操作。\n在三层架构当中，前端发起请求首先会到达Controller(不进行逻辑处理)，然后Controller会直接调用Service 进行逻辑处理， Service再调用Dao完成数据访问操作。\n如果我们在执行具体的业务处理之前，需要去做一些通用的业务处理，比如：我们要进行统一的登录校验，我们要进行统一的字符编码等这些操作时，我们就可以借助于Javaweb当中三大组件之一的过滤器Filter或者是Spring当中提供的拦截器Interceptor来实现。\n而为了实现三层架构层与层之间的解耦，我们学习了Spring框架当中的第一大核心：IOC控制反转与DI依赖注入。\n所谓控制反转，指的是将对象创建的控制权由应用程序自身交给外部容器，这个容器就是我们常说的IOC容器或Spring容器。\n而DI依赖注入指的是容器为程序提供运行时所需要的资源。\n除了IOC与DI我们还讲到了AOP面向切面编程，还有Spring中的事务管理、全局异常处理器，以及传递会话技术Cookie、Session以及新的会话跟踪解决方案JWT令牌，阿里云OSS对象存储服务，以及通过Mybatis持久层架构操作数据库等技术。\n我们在学习这些web后端开发技术的时候，我们都是基于主流的SpringBoot进行整合使用的。而SpringBoot又是用来简化开发，提高开发效率的。像过滤器、拦截器、IOC、DI、AOP、事务管理等这些技术到底是哪个框架提供的核心功能？\nFilter过滤器、Cookie、 Session这些都是传统的JavaWeb提供的技术。\nJWT令牌、阿里云OSS对象存储服务，是现在企业项目中常见的一些解决方案。\nIOC控制反转、DI依赖注入、AOP面向切面编程、事务管理、全局异常处理、拦截器等，这些技术都是 Spring Framework框架当中提供的核心功能。\nMybatis就是一个持久层的框架，是用来操作数据库的。\n在Spring框架的生态中，对web程序开发提供了很好的支持，如：全局异常处理器、拦截器这些都是Spring框架中web开发模块所提供的功能，而Spring框架的web开发模块，我们也称为：SpringMVC\nSpringMVC不是一个单独的框架，它是Spring框架的一部分，是Spring框架中的web开发模块，是用来简化原始的Servlet程序开发的。\n外界俗称的SSM，就是由：SpringMVC、Spring Framework、Mybatis三块组成。\n基于传统的SSM框架进行整合开发项目会比较繁琐，而且效率也比较低，所以在现在的企业项目开发当中，基本上都是直接基于SpringBoot整合SSM进行项目开发的。\n","date":"2024-04-13T16:01:26+08:00","image":"https://nova-bryan.github.io/p/springboot%E5%8E%9F%E7%90%86%E5%92%8Cbean%E7%9A%84%E7%AE%A1%E7%90%86/image_hu17089168107649188491.png","permalink":"https://nova-bryan.github.io/p/springboot%E5%8E%9F%E7%90%86%E5%92%8Cbean%E7%9A%84%E7%AE%A1%E7%90%86/","title":"SpringBoot原理和Bean的管理"},{"content":"登录基础功能 在前面的课程中，我们已经实现了部门管理、员工管理的基本功能，但是大家会发现，我们并没有登录，就直接访问到了Tlias智能学习辅助系统的后台。 这是不安全的，所以我们今天的主题就是登录认证。 最终我们要实现的效果就是用户必须登录之后，才可以访问后台系统中的功能。\n需求 在登录界面中，我们可以输入用户的用户名以及密码，然后点击 \u0026ldquo;登录\u0026rdquo; 按钮就要请求服务器，服务端判断用户输入的用户名或者密码是否正确。如果正确，则返回成功结果，前端跳转至系统首页面。\n接口文档 我们参照接口文档来开发登录功能\n基本信息\n1 2 3 请求路径：/login 请求方式：POST 接口描述：该接口用于员工登录Tlias智能学习辅助系统，登录完毕后，系统下发JWT令牌。 请求参数\n参数格式：application/json\n参数说明：\n名称 类型 是否必须 备注 username string 必须 用户名 password string 必须 密码 请求数据样例：\n1 2 3 4 { \u0026#34;username\u0026#34;: \u0026#34;jinyong\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;123456\u0026#34; } 响应数据 参数格式：application/json\n参数说明：\n名称 类型 是否必须 默认值 备注 其他信息 code number 必须 响应码, 1 成功 ; 0 失败 msg string 非必须 提示信息 data string 必须 返回的数据 , jwt令牌 响应数据样例：\n1 2 3 4 5 { \u0026#34;code\u0026#34;: 1, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiJ9.eyJuYW1lIjoi6YeR5bq4IiwiaWQiOjEsInVzZXJuYW1lIjoiamlueW9uZyIsImV4cCI6MTY2MjIwNzA0OH0.KkUc_CXJZJ8Dd063eImx4H9Ojfrr6XMJ-yVzaWCVZCo\u0026#34; } 思路分析 登录服务端的核心逻辑就是：接收前端请求传递的用户名和密码 ，然后再根据用户名和密码查询用户信息，如果用户信息存在，则说明用户输入的用户名和密码正确。如果查询到的用户不存在，则说明用户输入的用户名和密码错误。\n功能开发 LoginController\n1 2 3 4 5 6 7 8 9 10 11 12 @RestController public class LoginController { @Autowired private EmpService empService; @PostMapping(\u0026#34;/login\u0026#34;) public Result login(@RequestBody Emp emp){ Emp e = empService.login(emp); return e != null ? Result.success():Result.error(\u0026#34;用户名或密码错误\u0026#34;); } } EmpService\n1 2 3 4 5 6 7 8 9 10 11 public interface EmpService { /** * 用户登录 * @param emp * @return */ public Emp login(Emp emp); //省略其他代码... } EmpServiceImpl\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Slf4j @Service public class EmpServiceImpl implements EmpService { @Autowired private EmpMapper empMapper; @Override public Emp login(Emp emp) { //调用dao层功能：登录 Emp loginEmp = empMapper.getByUsernameAndPassword(emp); //返回查询结果给Controller return loginEmp; } //省略其他代码... } EmpMapper\n1 2 3 4 5 6 7 8 9 10 @Mapper public interface EmpMapper { @Select(\u0026#34;select id, username, password, name, gender, image, job, entrydate, dept_id, create_time, update_time \u0026#34; + \u0026#34;from emp \u0026#34; + \u0026#34;where username=#{username} and password =#{password}\u0026#34;) public Emp getByUsernameAndPassword(Emp emp); //省略其他代码... } 测试 功能开发完毕后，我们就可以启动服务，打开postman进行测试了。\n发起POST请求，访问：http://localhost:8080/login\npostman测试通过了，那接下来，我们就可以结合着前端工程进行联调测试。\n先退出系统，进入到登录页面：\n在登录页面输入账户密码：\n登录成功之后进入到后台管理系统页面：\n登录校验-概述 问题分析 我们已经完成了基础登录功能的开发与测试，在我们登录成功后就可以进入到后台管理系统中进行数据的操作。\n但是当我们在浏览器中新的页面上输入地址：http://localhost:9528/#/system/dept，发现没有登录仍然可以进入到后端管理系统页面。\n而真正的登录功能应该是：登陆后才能访问后端系统页面，不登陆则跳转登陆页面进行登陆。\n为什么会出现这个问题？其实原因很简单，就是因为针对于我们当前所开发的部门管理、员工管理以及文件上传等相关接口来说，我们在服务器端并没有做任何的判断，没有去判断用户是否登录了。所以无论用户是否登录，都可以访问部门管理以及员工管理的相关数据。所以我们目前所开发的登录功能，它只是徒有其表。而我们要想解决这个问题，我们就需要完成一步非常重要的操作：登录校验。\n什么是登录校验？\n所谓登录校验，指的是我们在服务器端接收到浏览器发送过来的请求之后，首先我们要对请求进行校验。先要校验一下用户登录了没有，如果用户已经登录了，就直接执行对应的业务操作就可以了；如果用户没有登录，此时就不允许他执行相关的业务操作，直接给前端响应一个错误的结果，最终跳转到登录页面，要求他登录成功之后，再来访问对应的数据。 了解完什么是登录校验之后，接下来我们分析一下登录校验大概的实现思路。\n首先我们在宏观上先有一个认知：\n前面在讲解HTTP协议的时候，我们提到HTTP协议是无状态协议。什么又是无状态的协议？\n所谓无状态，指的是每一次请求都是独立的，下一次请求并不会携带上一次请求的数据。而浏览器与服务器之间进行交互，基于HTTP协议也就意味着现在我们通过浏览器来访问了登陆这个接口，实现了登陆的操作，接下来我们在执行其他业务操作时，服务器也并不知道这个员工到底登陆了没有。因为HTTP协议是无状态的，两次请求之间是独立的，所以是无法判断这个员工到底登陆了没有。\n那应该怎么来实现登录校验的操作呢？具体的实现思路可以分为两部分：\n在员工登录成功后，需要将用户登录成功的信息存起来，记录用户已经登录成功的标记。 在浏览器发起请求时，需要在服务端进行统一拦截，拦截后进行登录校验。 想要判断员工是否已经登录，我们需要在员工登录成功之后，存储一个登录成功的标记，接下来在每一个接口方法执行之前，先做一个条件判断，判断一下这个员工到底登录了没有。如果是登录了，就可以执行正常的业务操作，如果没有登录，会直接给前端返回一个错误的信息，前端拿到这个错误信息之后会自动的跳转到登录页面。\n我们程序中所开发的查询功能、删除功能、添加功能、修改功能，都需要使用以上套路进行登录校验。此时就会出现：相同代码逻辑，每个功能都需要编写，就会造成代码非常繁琐。\n为了简化这块操作，我们可以使用一种技术：统一拦截技术。\n通过统一拦截的技术，我们可以来拦截浏览器发送过来的所有的请求，拦截到这个请求之后，就可以通过请求来获取之前所存入的登录标记，在获取到登录标记且标记为登录成功，就说明员工已经登录了。如果已经登录，我们就直接放行(意思就是可以访问正常的业务接口了)。\n我们要完成以上操作，会涉及到web开发中的两个技术：\n会话技术 统一拦截技术 而统一拦截技术现实方案也有两种：\nServlet规范中的Filter过滤器 Spring提供的interceptor拦截器 下面我们先学习会话技术，然后再学习统一拦截技术。\n登录认证-登录校验-会话技术 会话技术介绍 什么是会话？\n在我们日常生活当中，会话指的就是谈话、交谈。\n在web开发当中，会话指的就是浏览器与服务器之间的一次连接，我们就称为一次会话。\n在用户打开浏览器第一次访问服务器的时候，这个会话就建立了，直到有任何一方断开连接，此时会话就结束了。在一次会话当中，是可以包含多次请求和响应的。\n比如：打开了浏览器来访问web服务器上的资源（浏览器不能关闭、服务器不能断开）\n第1次：访问的是登录的接口，完成登录操作 第2次：访问的是部门管理接口，查询所有部门数据 第3次：访问的是员工管理接口，查询员工数据 只要浏览器和服务器都没有关闭，以上3次请求都属于一次会话当中完成的。\n需要注意的是：会话是和浏览器关联的，当有三个浏览器客户端和服务器建立了连接时，就会有三个会话。同一个浏览器在未关闭之前请求了多次服务器，这多次请求是属于同一个会话。比如：1、2、3这三个请求都是属于同一个会话。当我们关闭浏览器之后，这次会话就结束了。而如果我们是直接把web服务器关了，那么所有的会话就都结束了。\n知道了会话的概念了，接下来我们再来了解下会话跟踪。\n会话跟踪：一种维护浏览器状态的方法，服务器需要识别多次请求是否来自于同一浏览器，以便在同一次会话的多次请求间共享数据。\n服务器会接收很多的请求，但是服务器是需要识别出这些请求是不是同一个浏览器发出来的。比如：1和2这两个请求是不是同一个浏览器发出来的，3和5这两个请求不是同一个浏览器发出来的。如果是同一个浏览器发出来的，就说明是同一个会话。如果是不同的浏览器发出来的，就说明是不同的会话。而识别多次请求是否来自于同一浏览器的过程，我们就称为会话跟踪。\n我们使用会话跟踪技术就是要完成在同一个会话中，多个请求之间进行共享数据。\n为什么要共享数据呢？\n由于HTTP是无状态协议，在后面请求中怎么拿到前一次请求生成的数据呢？此时就需要在一次会话的多次请求之间进行数据共享\n会话跟踪技术有两种：\nCookie（客户端会话跟踪技术） 数据存储在客户端浏览器当中 Session（服务端会话跟踪技术） 数据存储在储在服务端 令牌技术 登录认证-登录校验-会话跟踪方案一 上面我们介绍了什么是会话，什么是会话跟踪，并且也提到了会话跟踪 3 种常见的技术方案。接下来，我们就来对比一下这 3 种会话跟踪的技术方案，来看一下具体的实现思路，以及它们之间的优缺点。\n方案一-Cookie cookie 是客户端会话跟踪技术，它是存储在客户端浏览器的，我们使用 cookie 来跟踪会话，我们就可以在浏览器第一次发起请求来请求服务器的时候，我们在服务器端来设置一个cookie。\n比如第一次请求了登录接口，登录接口执行完成之后，我们就可以设置一个cookie，在 cookie 当中我们就可以来存储用户相关的一些数据信息。比如我可以在 cookie 当中来存储当前登录用户的用户名，用户的ID。\n服务器端在给客户端在响应数据的时候，会自动的将 cookie 响应给浏览器，浏览器接收到响应回来的 cookie 之后，会自动的将 cookie 的值存储在浏览器本地。接下来在后续的每一次请求当中，都会将浏览器本地所存储的 cookie 自动地携带到服务端。\n接下来在服务端我们就可以获取到 cookie 的值。我们可以去判断一下这个 cookie 的值是否存在，如果不存在这个cookie，就说明客户端之前是没有访问登录接口的；如果存在 cookie 的值，就说明客户端之前已经登录完成了。这样我们就可以基于 cookie 在同一次会话的不同请求之间来共享数据。\n我刚才在介绍流程的时候，用了 3 个自动：\n服务器会 自动 的将 cookie 响应给浏览器。 浏览器接收到响应回来的数据之后，会 自动 的将 cookie 存储在浏览器本地。 在后续的请求当中，浏览器会 自动 的将 cookie 携带到服务器端。 为什么这一切都是自动化进行的？\n是因为 cookie 它是 HTP 协议当中所支持的技术，而各大浏览器厂商都支持了这一标准。在 HTTP 协议官方给我们提供了一个响应头和请求头：\n响应头 Set-Cookie ：设置Cookie数据的 请求头 Cookie：携带Cookie数据的 代码测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Slf4j @RestController public class SessionController { //设置Cookie @GetMapping(\u0026#34;/c1\u0026#34;) public Result cookie1(HttpServletResponse response){ response.addCookie(new Cookie(\u0026#34;login_username\u0026#34;,\u0026#34;itheima\u0026#34;)); //设置Cookie/响应Cookie return Result.success(); } //获取Cookie @GetMapping(\u0026#34;/c2\u0026#34;) public Result cookie2(HttpServletRequest request){ Cookie[] cookies = request.getCookies(); for (Cookie cookie : cookies) { if(cookie.getName().equals(\u0026#34;login_username\u0026#34;)){ System.out.println(\u0026#34;login_username: \u0026#34;+cookie.getValue()); //输出name为login_username的cookie } } return Result.success(); } } A. 访问c1接口，设置Cookie，http://localhost:8080/c1\n我们可以看到，设置的cookie，通过响应头Set-Cookie响应给浏览器，并且浏览器会将Cookie，存储在浏览器端。\nB. 访问c2接口 http://localhost:8080/c2，此时浏览器会自动的将Cookie携带到服务端，是通过请求头Cookie，携带的。\n优缺点\n优点：HTTP协议中支持的技术（像Set-Cookie 响应头的解析以及 Cookie 请求头数据的携带，都是浏览器自动进行的，是无需我们手动操作的） 缺点： 移动端APP(Android、IOS)中无法使用Cookie 不安全，用户可以自己禁用Cookie Cookie不能跨域 跨域介绍：\n现在的项目，大部分都是前后端分离的，前后端最终也会分开部署，前端部署在服务器 192.168.150.200 上，端口 80，后端部署在 192.168.150.100上，端口 8080 我们打开浏览器直接访问前端工程，访问url：http://192.168.150.200/login.html 然后在该页面发起请求到服务端，而服务端所在地址不再是localhost，而是服务器的IP地址192.168.150.100，假设访问接口地址为：http://192.168.150.100:8080/login 那此时就存在跨域操作了，因为我们是在 http://192.168.150.200/login.html 这个页面上访问了http://192.168.150.100:8080/login 接口 此时如果服务器设置了一个Cookie，这个Cookie是不能使用的，因为Cookie无法跨域 区分跨域的维度：\n协议 IP/协议 端口 只要上述的三个维度有任何一个维度不同，那就是跨域操作\n举例：\nhttp://192.168.150.200/login.html \u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt; https://192.168.150.200/login [协议不同，跨域]\nhttp://192.168.150.200/login.html \u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt; http://192.168.150.100/login [IP不同，跨域]\nhttp://192.168.150.200/login.html \u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt; http://192.168.150.200:8080/login [端口不同，跨域]\nhttp://192.168.150.200/login.html \u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt; http://192.168.150.200/login [不跨域]\n登录认证-登录校验-会话跟踪方案二、三 方案二-Session 前面介绍的时候，我们提到Session，它是服务器端会话跟踪技术，所以它是存储在服务器端的。而 Session 的底层其实就是基于我们刚才所介绍的 Cookie 来实现的。\n获取Session\n如果我们现在要基于 Session 来进行会话跟踪，浏览器在第一次请求服务器的时候，我们就可以直接在服务器当中来获取到会话对象Session。如果是第一次请求Session ，会话对象是不存在的，这个时候服务器会自动的创建一个会话对象Session 。而每一个会话对象Session ，它都有一个ID（示意图中Session后面括号中的1，就表示ID），我们称之为 Session 的ID。\n响应Cookie (JSESSIONID)\n接下来，服务器端在给浏览器响应数据的时候，它会将 Session 的 ID 通过 Cookie 响应给浏览器。其实在响应头当中增加了一个 Set-Cookie 响应头。这个 Set-Cookie 响应头对应的值是不是cookie？ cookie 的名字是固定的 JSESSIONID 代表的服务器端会话对象 Session 的 ID。浏览器会自动识别这个响应头，然后自动将Cookie存储在浏览器本地。\n查找Session\n接下来，在后续的每一次请求当中，都会将 Cookie 的数据获取出来，并且携带到服务端。接下来服务器拿到JSESSIONID这个 Cookie 的值，也就是 Session 的ID。拿到 ID 之后，就会从众多的 Session 当中来找到当前请求对应的会话对象Session。\n这样我们是不是就可以通过 Session 会话对象在同一次会话的多次请求之间来共享数据了？好，这就是基于 Session 进行会话跟踪的流程。\n代码测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Slf4j @RestController public class SessionController { @GetMapping(\u0026#34;/s1\u0026#34;) public Result session1(HttpSession session){ log.info(\u0026#34;HttpSession-s1: {}\u0026#34;, session.hashCode()); session.setAttribute(\u0026#34;loginUser\u0026#34;, \u0026#34;tom\u0026#34;); //往session中存储数据 return Result.success(); } @GetMapping(\u0026#34;/s2\u0026#34;) public Result session2(HttpServletRequest request){ HttpSession session = request.getSession(); log.info(\u0026#34;HttpSession-s2: {}\u0026#34;, session.hashCode()); Object loginUser = session.getAttribute(\u0026#34;loginUser\u0026#34;); //从session中获取数据 log.info(\u0026#34;loginUser: {}\u0026#34;, loginUser); return Result.success(loginUser); } } A. 访问 s1 接口，http://localhost:8080/s1\n请求完成之后，在响应头中，就会看到有一个Set-Cookie的响应头，里面响应回来了一个Cookie，就是JSESSIONID，这个就是服务端会话对象 Session 的ID。\nB. 访问 s2 接口，http://localhost:8080/s2\n接下来，在后续的每次请求时，都会将Cookie的值，携带到服务端，那服务端呢，接收到Cookie之后，会自动的根据JSESSIONID的值，找到对应的会话对象Session。\n那经过这两步测试，大家也会看到，在控制台中输出如下日志：\n两次请求，获取到的Session会话对象的hashcode是一样的，就说明是同一个会话对象。而且，第一次请求时，往Session会话对象中存储的值，第二次请求时，也获取到了。 那这样，我们就可以通过Session会话对象，在同一个会话的多次请求之间来进行数据共享了。\n优缺点\n优点：Session是存储在服务端的，安全 缺点： 服务器集群环境下无法直接使用Session 移动端APP(Android、IOS)中无法使用Cookie 用户可以自己禁用Cookie Cookie不能跨域 PS：Session 底层是基于Cookie实现的会话跟踪，如果Cookie不可用，则该方案，也就失效了。\n服务器集群环境为何无法使用Session？\n首先第一点，我们现在所开发的项目，一般都不会只部署在一台服务器上，因为一台服务器会存在一个很大的问题，就是单点故障。所谓单点故障，指的就是一旦这台服务器挂了，整个应用都没法访问了。 所以在现在的企业项目开发当中，最终部署的时候都是以集群的形式来进行部署，也就是同一个项目它会部署多份。比如这个项目我们现在就部署了 3 份。\n而用户在访问的时候，到底访问这三台其中的哪一台？其实用户在访问的时候，他会访问一台前置的服务器，我们叫负载均衡服务器，我们在后面项目当中会详细讲解。目前大家先有一个印象负载均衡服务器，它的作用就是将前端发起的请求均匀的分发给后面的这三台服务器。\n此时假如我们通过 session 来进行会话跟踪，可能就会存在这样一个问题。用户打开浏览器要进行登录操作，此时会发起登录请求。登录请求到达负载均衡服务器，将这个请求转给了第一台 Tomcat 服务器。\nTomcat 服务器接收到请求之后，要获取到会话对象session。获取到会话对象 session 之后，要给浏览器响应数据，最终在给浏览器响应数据的时候，就会携带这么一个 cookie 的名字，就是 JSESSIONID ，下一次再请求的时候，是不是又会将 Cookie 携带到服务端？\n好。此时假如又执行了一次查询操作，要查询部门的数据。这次请求到达负载均衡服务器之后，负载均衡服务器将这次请求转给了第二台 Tomcat 服务器，此时他就要到第二台 Tomcat 服务器当中。根据JSESSIONID 也就是对应的 session 的 ID 值，要找对应的 session 会话对象。\n我想请问在第二台服务器当中有没有这个ID的会话对象 Session， 是没有的。此时是不是就出现问题了？我同一个浏览器发起了 2 次请求，结果获取到的不是同一个会话对象，这就是Session这种会话跟踪方案它的缺点，在服务器集群环境下无法直接使用Session。\n大家会看到上面这两种传统的会话技术，在现在的企业开发当中是不是会存在很多的问题。 为了解决这些问题，在现在的企业开发当中，基本上都会采用第三种方案，通过令牌技术来进行会话跟踪。接下来我们就来介绍一下令牌技术，来看一下令牌技术又是如何跟踪会话的。\n登录校验-JWT令牌-介绍 前面我们介绍了基于令牌技术来实现会话追踪。这里所提到的令牌就是用户身份的标识，其本质就是一个字符串。令牌的形式有很多，我们使用的是功能强大的 JWT令牌。\n介绍 JWT全称：JSON Web Token （官网：https://jwt.io/）\n定义了一种简洁的、自包含的格式，用于在通信双方以json数据格式安全的传输信息。由于数字签名的存在，这些信息是可靠的。\n简洁：是指jwt就是一个简单的字符串。可以在请求参数或者是请求头当中直接传递。\n自包含：指的是jwt令牌，看似是一个随机的字符串，但是我们是可以根据自身的需求在jwt令牌中存储自定义的数据内容。如：可以直接在jwt令牌中存储用户的相关信息。\n简单来讲，jwt就是将原始的json数据格式进行了安全的封装，这样就可以直接基于jwt在通信双方安全的进行信息传输了。\nJWT的组成： （JWT令牌由三个部分组成，三个部分之间使用英文的点来分割）\n第一部分：Header(头）， 记录令牌类型、签名算法等。 例如：{\u0026ldquo;alg\u0026rdquo;:\u0026ldquo;HS256\u0026rdquo;,\u0026ldquo;type\u0026rdquo;:\u0026ldquo;JWT\u0026rdquo;}\n第二部分：Payload(有效载荷），携带一些自定义信息、默认信息等。 例如：{\u0026ldquo;id\u0026rdquo;:\u0026ldquo;1\u0026rdquo;,\u0026ldquo;username\u0026rdquo;:\u0026ldquo;Tom\u0026rdquo;}\n第三部分：Signature(签名），防止Token被篡改、确保安全性。将header、payload，并加入指定秘钥，通过指定签名算法计算而来。\n签名的目的就是为了防jwt令牌被篡改，而正是因为jwt令牌最后一个部分数字签名的存在，所以整个jwt 令牌是非常安全可靠的。一旦jwt令牌当中任何一个部分、任何一个字符被篡改了，整个令牌在校验的时候都会失败，所以它是非常安全可靠的。\nJWT是如何将原始的JSON格式数据，转变为字符串的呢？\n其实在生成JWT令牌时，会对JSON格式的数据进行一次编码：进行base64编码\nBase64：是一种基于64个可打印的字符来表示二进制数据的编码方式。既然能编码，那也就意味着也能解码。所使用的64个字符分别是A到Z、a到z、 0- 9，一个加号，一个斜杠，加起来就是64个字符。任何数据经过base64编码之后，最终就会通过这64个字符来表示。当然还有一个符号，那就是等号。等号它是一个补位的符号\n需要注意的是Base64是编码方式，而不是加密方式。\nJWT令牌最典型的应用场景就是登录认证：\n在浏览器发起请求来执行登录操作，此时会访问登录的接口，如果登录成功之后，我们需要生成一个jwt令牌，将生成的 jwt令牌返回给前端。 前端拿到jwt令牌之后，会将jwt令牌存储起来。在后续的每一次请求中都会将jwt令牌携带到服务端。 服务端统一拦截请求之后，先来判断一下这次请求有没有把令牌带过来，如果没有带过来，直接拒绝访问，如果带过来了，还要校验一下令牌是否是有效。如果有效，就直接放行进行请求的处理。 在JWT登录认证的场景中我们发现，整个流程当中涉及到两步操作：\n在登录成功之后，要生成令牌。 每一次请求当中，要接收令牌并对令牌进行校验。 稍后我们再来学习如何来生成jwt令牌，以及如何来校验jwt令牌。\n登录校验-JWT令牌-生成和校验 生成和校验 简单介绍了JWT令牌以及JWT令牌的组成之后，接下来我们就来学习基于Java代码如何生成和校验JWT令牌。\n首先我们先来实现JWT令牌的生成。要想使用JWT令牌，需要先引入JWT的依赖：\n1 2 3 4 5 6 \u0026lt;!-- JWT依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在引入完JWT来赖后，就可以调用工具包中提供的API来完成JWT令牌的生成和校验\n工具类：Jwts\n生成JWT代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Test public void genJwt(){ Map\u0026lt;String,Object\u0026gt; claims = new HashMap\u0026lt;\u0026gt;(); claims.put(\u0026#34;id\u0026#34;,1); claims.put(\u0026#34;username\u0026#34;,\u0026#34;Tom\u0026#34;); String jwt = Jwts.builder() .setClaims(claims) //自定义内容(载荷) .signWith(SignatureAlgorithm.HS256, \u0026#34;itheima\u0026#34;) //签名算法 .setExpiration(new Date(System.currentTimeMillis() + 24*3600*1000)) //有效期 .compact(); System.out.println(jwt); } 运行测试方法：\n1 eyJhbGciOiJIUzI1NiJ9.eyJpZCI6MSwiZXhwIjoxNjcyNzI5NzMwfQ.fHi0Ub8npbyt71UqLXDdLyipptLgxBUg_mSuGJtXtBk 输出的结果就是生成的JWT令牌,，通过英文的点分割对三个部分进行分割，我们可以将生成的令牌复制一下，然后打开JWT的官网，将生成的令牌直接放在Encoded位置，此时就会自动的将令牌解析出来。\n第一部分解析出来，看到JSON格式的原始数据，所使用的签名算法为HS256。\n第二个部分是我们自定义的数据，之前我们自定义的数据就是id，还有一个exp代表的是我们所设置的过期时间。\n由于前两个部分是base64编码，所以是可以直接解码出来。但最后一个部分并不是base64编码，是经过签名算法计算出来的，所以最后一个部分是不会解析的。\n实现了JWT令牌的生成，下面我们接着使用Java代码来校验JWT令牌(解析生成的令牌)：\n1 2 3 4 5 6 7 8 9 @Test public void parseJwt(){ Claims claims = Jwts.parser() .setSigningKey(\u0026#34;itheima\u0026#34;)//指定签名密钥（必须保证和生成令牌时使用相同的签名密钥） .parseClaimsJws(\u0026#34;eyJhbGciOiJIUzI1NiJ9.eyJpZCI6MSwiZXhwIjoxNjcyNzI5NzMwfQ.fHi0Ub8npbyt71UqLXDdLyipptLgxBUg_mSuGJtXtBk\u0026#34;) .getBody(); System.out.println(claims); } 运行测试方法：\n1 {id=1, exp=1672729730} 令牌解析后，我们可以看到id和过期时间，如果在解析的过程当中没有报错，就说明解析成功了。\n下面我们做一个测试：把令牌header中的数字9变为8，运行测试方法后发现报错：\n原header： eyJhbGciOiJIUzI1NiJ9\n修改为： eyJhbGciOiJIUzI1NiJ8\n结论：篡改令牌中的任何一个字符，在对令牌进行解析时都会报错，所以JWT令牌是非常安全可靠的。\n我们继续测试：修改生成令牌的时指定的过期时间，修改为1分钟\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Test public void genJwt(){ Map\u0026lt;String,Object\u0026gt; claims = new HashMap\u0026lt;\u0026gt;(); claims.put(“id”,1); claims.put(“username”,“Tom”); String jwt = Jwts.builder() .setClaims(claims) //自定义内容(载荷) .signWith(SignatureAlgorithm.HS256, “itheima”) //签名算法 .setExpiration(new Date(System.currentTimeMillis() + 60*1000)) //有效期60秒 .compact(); System.out.println(jwt); //输出结果：eyJhbGciOiJIUzI1NiJ9.eyJpZCI6MSwiZXhwIjoxNjczMDA5NzU0fQ.RcVIR65AkGiax-ID6FjW60eLFH3tPTKdoK7UtE4A1ro } @Test public void parseJwt(){ Claims claims = Jwts.parser() .setSigningKey(\u0026#34;itheima\u0026#34;)//指定签名密钥 .parseClaimsJws(\u0026#34;eyJhbGciOiJIUzI1NiJ9.eyJpZCI6MSwiZXhwIjoxNjczMDA5NzU0fQ.RcVIR65AkGiax-ID6FjW60eLFH3tPTKdoK7UtE4A1ro\u0026#34;) .getBody(); System.out.println(claims); } 等待1分钟之后运行测试方法发现也报错了，说明：JWT令牌过期后，令牌就失效了，解析的为非法令牌。\n通过以上测试，我们在使用JWT令牌时需要注意：\nJWT校验时使用的签名秘钥，必须和生成JWT令牌时使用的秘钥是配套的。 如果JWT令牌解析校验时报错，则说明 JWT令牌被篡改 或 失效了，令牌非法。 登录校验-JWT令牌-登录后下发令牌 登录下发令牌 JWT令牌的生成和校验的基本操作我们已经学习完了，接下来我们就需要在案例当中通过JWT令牌技术来跟踪会话。具体的思路我们前面已经分析过了，主要就是两步操作：\n生成令牌 在登录成功之后来生成一个JWT令牌，并且把这个令牌直接返回给前端 校验令牌 拦截前端请求，从请求中获取到令牌，对令牌进行解析校验 那我们首先来完成：登录成功之后生成JWT令牌，并且把令牌返回给前端。\nJWT令牌怎么返回给前端呢？此时我们就需要再来看一下接口文档当中关于登录接口的描述（主要看响应数据）：\n响应数据\n参数格式：application/json\n参数说明：\n名称 类型 是否必须 默认值 备注 其他信息 code number 必须 响应码, 1 成功 ; 0 失败 msg string 非必须 提示信息 data string 必须 返回的数据 , jwt令牌 响应数据样例：\n1 2 3 4 5 { \u0026#34;code\u0026#34;: 1, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiJ9.eyJuYW1lIjoi6YeR5bq4IiwiaWQiOjEsInVzZXJuYW1lIjoiamlueW9uZyIsImV4cCI6MTY2MjIwNzA0OH0.KkUc_CXJZJ8Dd063eImx4H9Ojfrr6XMJ-yVzaWCVZCo\u0026#34; } 备注说明 用户登录成功后，系统会自动下发JWT令牌，然后在后续的每次请求中，都需要在请求头header中携带到服务端，请求头的名称为 token ，值为 登录时下发的JWT令牌。\n如果检测到用户未登录，则会返回如下固定错误信息：\n1 2 3 4 5 { \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;NOT_LOGIN\u0026#34;, \u0026#34;data\u0026#34;: null } 解读完接口文档中的描述了，目前我们先来完成令牌的生成和令牌的下发，我们只需要生成一个令牌返回给前端就可以了。\n实现步骤：\n引入JWT工具类 在项目工程下创建com.itheima.utils包，并把提供JWT工具类复制到该包下 登录完成后，调用工具类生成JWT令牌并返回 JWT工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class JwtUtils { private static String signKey = \u0026#34;itheima\u0026#34;;//签名密钥 private static Long expire = 43200000L; //有效时间 /** * 生成JWT令牌 * @param claims JWT第二部分负载 payload 中存储的内容 * @return */ public static String generateJwt(Map\u0026lt;String, Object\u0026gt; claims){ String jwt = Jwts.builder() .addClaims(claims)//自定义信息（有效载荷） .signWith(SignatureAlgorithm.HS256, signKey)//签名算法（头部） .setExpiration(new Date(System.currentTimeMillis() + expire))//过期时间 .compact(); return jwt; } /** * 解析JWT令牌 * @param jwt JWT令牌 * @return JWT第二部分负载 payload 中存储的内容 */ public static Claims parseJWT(String jwt){ Claims claims = Jwts.parser() .setSigningKey(signKey)//指定签名密钥 .parseClaimsJws(jwt)//指定令牌Token .getBody(); return claims; } } 登录成功，生成JWT令牌并返回\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @RestController @Slf4j public class LoginController { //依赖业务层对象 @Autowired private EmpService empService; @PostMapping(\u0026#34;/login\u0026#34;) public Result login(@RequestBody Emp emp) { //调用业务层：登录功能 Emp loginEmp = empService.login(emp); //判断：登录用户是否存在 if(loginEmp !=null ){ //自定义信息 Map\u0026lt;String , Object\u0026gt; claims = new HashMap\u0026lt;\u0026gt;(); claims.put(\u0026#34;id\u0026#34;, loginEmp.getId()); claims.put(\u0026#34;username\u0026#34;,loginEmp.getUsername()); claims.put(\u0026#34;name\u0026#34;,loginEmp.getName()); //使用JWT工具类，生成身份令牌 String token = JwtUtils.generateJwt(claims); return Result.success(token); } return Result.error(\u0026#34;用户名或密码错误\u0026#34;); } } 重启服务，打开postman测试登录接口：\n打开浏览器完成前后端联调操作：利用开发者工具，抓取一下网络请求\n登录请求完成后，可以看到JWT令牌已经响应给了前端，此时前端就会将JWT令牌存储在浏览器本地。\n服务器响应的JWT令牌存储在本地浏览器哪里了呢？\n在当前案例中，JWT令牌存储在浏览器的本地存储空间local storage中了。 local storage是浏览器的本地存储，在移动端也是支持的。 我们在发起一个查询部门数据的请求，此时我们可以看到在请求头中包含一个token(JWT令牌)，后续的每一次请求当中，都会将这个令牌携带到服务端。\n登录校验-Filter-入门 刚才通过浏览器的开发者工具，我们可以看到在后续的请求当中，都会在请求头中携带JWT令牌到服务端，而服务端需要统一拦截所有的请求，从而判断是否携带的有合法的JWT令牌。 那怎么样来统一拦截到所有的请求校验令牌的有效性呢？这里我们会学习两种解决方案：\nFilter过滤器 Interceptor拦截器 我们首先来学习过滤器Filter。\n快速入门 什么是Filter？\nFilter表示过滤器，是 JavaWeb三大组件(Servlet、Filter、Listener)之一。 过滤器可以把对资源的请求拦截下来，从而实现一些特殊的功能 使用了过滤器之后，要想访问web服务器上的资源，必须先经过滤器，过滤器处理完毕之后，才可以访问对应的资源。 过滤器一般完成一些通用的操作，比如：登录校验、统一编码处理、敏感字符处理等。 下面我们通过Filter快速入门程序掌握过滤器的基本使用操作：\n第1步，定义过滤器 ：1.定义一个类，实现 Filter 接口，并重写其所有方法。 第2步，配置过滤器：Filter类上加 @WebFilter 注解，配置拦截资源的路径。引导类上加 @ServletComponentScan 开启Servlet组件支持。 *定义过滤器*\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 //定义一个类，实现一个标准的Filter过滤器的接口 public class DemoFilter implements Filter { @Override //初始化方法, 只调用一次 public void init(FilterConfig filterConfig) throws ServletException { System.out.println(\u0026#34;init 初始化方法执行了\u0026#34;); } @Override //拦截到请求之后调用, 调用多次 public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { System.out.println(\u0026#34;Demo 拦截到了请求...放行前逻辑\u0026#34;); //放行 chain.doFilter(request,response); } @Override //销毁方法, 只调用一次 public void destroy() { System.out.println(\u0026#34;destroy 销毁方法执行了\u0026#34;); } } init方法：过滤器的初始化方法。在web服务器启动的时候会自动的创建Filter过滤器对象，在创建过滤器对象的时候会自动调用init初始化方法，这个方法只会被调用一次。 doFilter方法：这个方法是在每一次拦截到请求之后都会被调用，所以这个方法是会被调用多次的，每拦截到一次请求就会调用一次doFilter()方法。 destroy方法： 是销毁的方法。当我们关闭服务器的时候，它会自动的调用销毁方法destroy，而这个销毁方法也只会被调用一次。 在定义完Filter之后，Filter其实并不会生效，还需要完成Filter的配置，Filter的配置非常简单，只需要在Filter类上添加一个注解：@WebFilter，并指定属性urlPatterns，通过这个属性指定过滤器要拦截哪些请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @WebFilter(urlPatterns = \u0026#34;/*\u0026#34;) //配置过滤器要拦截的请求路径（ /* 表示拦截浏览器的所有请求 ） public class DemoFilter implements Filter { @Override //初始化方法, 只调用一次 public void init(FilterConfig filterConfig) throws ServletException { System.out.println(\u0026#34;init 初始化方法执行了\u0026#34;); } @Override //拦截到请求之后调用, 调用多次 public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { System.out.println(\u0026#34;Demo 拦截到了请求...放行前逻辑\u0026#34;); //放行 chain.doFilter(request,response); } @Override //销毁方法, 只调用一次 public void destroy() { System.out.println(\u0026#34;destroy 销毁方法执行了\u0026#34;); } } 当我们在Filter类上面加了@WebFilter注解之后，接下来我们还需要在启动类上面加上一个注解@ServletComponentScan，通过这个@ServletComponentScan注解来开启SpringBoot项目对于Servlet组件的支持。\n1 2 3 4 5 6 7 8 9 @ServletComponentScan @SpringBootApplication public class TliasWebManagementApplication { public static void main(String[] args) { SpringApplication.run(TliasWebManagementApplication.class, args); } } 重新启动服务，打开浏览器，执行部门管理的请求，可以看到控制台输出了过滤器中的内容：\n注意事项：\n在过滤器Filter中，如果不执行放行操作，将无法访问后面的资源。 放行操作：chain.doFilter(request, response);\n现在我们已完成了Filter过滤器的基本使用，下面我们将学习Filter过滤器在使用过程中的一些细节。\n登录校验-Filter-详解（执行流程-拦截路径） Filter过滤器的快速入门程序我们已经完成了，接下来我们就要详细的介绍一下过滤器Filter在使用中的一些细节。主要介绍以下3个方面的细节：\n过滤器的执行流程 过滤器的拦截路径配置 过滤器链 执行流程 首先我们先来看下过滤器的执行流程：\n过滤器当中我们拦截到了请求之后，如果希望继续访问后面的web资源，就要执行放行操作，放行就是调用 FilterChain对象当中的doFilter()方法，在调用doFilter()这个方法之前所编写的代码属于放行之前的逻辑。\n在放行后访问完 web 资源之后还会回到过滤器当中，回到过滤器之后如有需求还可以执行放行之后的逻辑，放行之后的逻辑我们写在doFilter()这行代码之后。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @WebFilter(urlPatterns = \u0026#34;/*\u0026#34;) public class DemoFilter implements Filter { @Override //初始化方法, 只调用一次 public void init(FilterConfig filterConfig) throws ServletException { System.out.println(\u0026#34;init 初始化方法执行了\u0026#34;); } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { System.out.println(\u0026#34;DemoFilter 放行前逻辑.....\u0026#34;); //放行请求 filterChain.doFilter(servletRequest,servletResponse); System.out.println(\u0026#34;DemoFilter 放行后逻辑.....\u0026#34;); } @Override //销毁方法, 只调用一次 public void destroy() { System.out.println(\u0026#34;destroy 销毁方法执行了\u0026#34;); } } 拦截路径 执行流程我们搞清楚之后，接下来再来介绍一下过滤器的拦截路径，Filter可以根据需求，配置不同的拦截资源路径：\n拦截路径 urlPatterns值 含义 拦截具体路径 /login 只有访问 /login 路径时，才会被拦截 目录拦截 /emps/* 访问/emps下的所有资源，都会被拦截 拦截所有 /* 访问所有资源，都会被拦截 下面我们来测试\u0026quot;拦截具体路径\u0026quot;：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @WebFilter(urlPatterns = \u0026#34;/login\u0026#34;) //拦截/login具体路径 public class DemoFilter implements Filter { @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { System.out.println(\u0026#34;DemoFilter 放行前逻辑.....\u0026#34;); //放行请求 filterChain.doFilter(servletRequest,servletResponse); System.out.println(\u0026#34;DemoFilter 放行后逻辑.....\u0026#34;); } @Override public void init(FilterConfig filterConfig) throws ServletException { Filter.super.init(filterConfig); } @Override public void destroy() { Filter.super.destroy(); } } 测试1：访问部门管理请求，发现过滤器没有拦截请求\n测试2：访问登录请求/login，发现过滤器拦截请求\n下面我们来测试\u0026quot;目录拦截\u0026quot;：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @WebFilter(urlPatterns = \u0026#34;/depts/*\u0026#34;) //拦截所有以/depts开头，后面是什么无所谓 public class DemoFilter implements Filter { @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { System.out.println(\u0026#34;DemoFilter 放行前逻辑.....\u0026#34;); //放行请求 filterChain.doFilter(servletRequest,servletResponse); System.out.println(\u0026#34;DemoFilter 放行后逻辑.....\u0026#34;); } @Override public void init(FilterConfig filterConfig) throws ServletException { Filter.super.init(filterConfig); } @Override public void destroy() { Filter.super.destroy(); } } 测试1：访问部门管理请求，发现过滤器拦截了请求\n测试2：访问登录请求/login，发现过滤器没有拦截请求\n登录校验-Filter-详解（过滤器链） 过滤器链 最后我们在来介绍下过滤器链，什么是过滤器链呢？所谓过滤器链指的是在一个web应用程序当中，可以配置多个过滤器，多个过滤器就形成了一个过滤器链。\n比如：在我们web服务器当中，定义了两个过滤器，这两个过滤器就形成了一个过滤器链。\n而这个链上的过滤器在执行的时候会一个一个的执行，会先执行第一个Filter，放行之后再来执行第二个Filter，如果执行到了最后一个过滤器放行之后，才会访问对应的web资源。\n访问完web资源之后，按照我们刚才所介绍的过滤器的执行流程，还会回到过滤器当中来执行过滤器放行后的逻辑，而在执行放行后的逻辑的时候，顺序是反着的。\n先要执行过滤器2放行之后的逻辑，再来执行过滤器1放行之后的逻辑，最后在给浏览器响应数据。\n以上就是当我们在web应用当中配置了多个过滤器，形成了这样一个过滤器链以及过滤器链的执行顺序。下面我们通过idea来验证下过滤器链。\n验证步骤：\n在filter包下再来新建一个Filter过滤器类：AbcFilter 在AbcFilter过滤器中编写放行前和放行后逻辑 配置AbcFilter过滤器拦截请求路径为：/* 重启SpringBoot服务，查看DemoFilter、AbcFilter的执行日志 AbcFilter过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 @WebFilter(urlPatterns = \u0026#34;/*\u0026#34;) public class AbcFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { System.out.println(\u0026#34;Abc 拦截到了请求... 放行前逻辑\u0026#34;); //放行 chain.doFilter(request,response); System.out.println(\u0026#34;Abc 拦截到了请求... 放行后逻辑\u0026#34;); } } DemoFilter过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 @WebFilter(urlPatterns = \u0026#34;/*\u0026#34;) public class DemoFilter implements Filter { @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { System.out.println(\u0026#34;DemoFilter 放行前逻辑.....\u0026#34;); //放行请求 filterChain.doFilter(servletRequest,servletResponse); System.out.println(\u0026#34;DemoFilter 放行后逻辑.....\u0026#34;); } } 打开浏览器访问登录接口：\n通过控制台日志的输出，大家发现AbcFilter先执行DemoFilter后执行，这是为什么呢？\n其实是和过滤器的类名有关系。以注解方式配置的Filter过滤器，它的执行优先级是按时过滤器类名的自动排序确定的，类名排名越靠前，优先级越高。\n假如我们想让DemoFilter先执行，怎么办呢？答案就是修改类名。\n测试：修改AbcFilter类名为XbcFilter，运行程序查看控制台日志\n1 2 3 4 5 6 7 8 9 10 11 12 @WebFilter(urlPatterns = \u0026#34;/*\u0026#34;) public class XbcFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { System.out.println(\u0026#34;Xbc 拦截到了请求...放行前逻辑\u0026#34;); //放行 chain.doFilter(request,response); System.out.println(\u0026#34;Xbc 拦截到了请求...放行后逻辑\u0026#34;); } } 到此，关于过滤器的使用细节，我们已经全部介绍完毕了。\n登录校验-Filter-登录校验过滤器 12.1 分析 过滤器Filter的快速入门以及使用细节我们已经介绍完了，接下来最后一步，我们需要使用过滤器Filter来完成案例当中的登录校验功能。\n我们先来回顾下前面分析过的登录校验的基本流程：\n要进入到后台管理系统，我们必须先完成登录操作，此时就需要访问登录接口login。 登录成功之后，我们会在服务端生成一个JWT令牌，并且把JWT令牌返回给前端，前端会将JWT令牌存储下来。 在后续的每一次请求当中，都会将JWT令牌携带到服务端，请求到达服务端之后，要想去访问对应的业务功能，此时我们必须先要校验令牌的有效性。 对于校验令牌的这一块操作，我们使用登录校验的过滤器，在过滤器当中来校验令牌的有效性。如果令牌是无效的，就响应一个错误的信息，也不会再去放行访问对应的资源了。如果令牌存在，并且它是有效的，此时就会放行去访问对应的web资源，执行相应的业务操作。 大概清楚了在Filter过滤器的实现步骤了，那在正式开发登录校验过滤器之前，我们思考两个问题：\n所有的请求，拦截到了之后，都需要校验令牌吗？ 答案：登录请求例外 拦截到请求后，什么情况下才可以放行，执行业务操作？ 答案：有令牌，且令牌校验通过(合法)；否则都返回未登录错误结果 具体流程 我们要完成登录校验，主要是利用Filter过滤器实现，而Filter过滤器的流程步骤：\n基于上面的业务流程，我们分析出具体的操作步骤：\n获取请求url 判断请求url中是否包含login，如果包含，说明是登录操作，放行 获取请求头中的令牌（token） 判断令牌是否存在，如果不存在，返回错误结果（未登录） 解析token，如果解析失败，返回错误结果（未登录） 放行 代码实现 分析清楚了以上的问题后，我们就参照接口文档来开发登录功能了，登录接口描述如下：\n基本信息\n1 2 3 4 5 请求路径：/login 请求方式：POST 接口描述：该接口用于员工登录Tlias智能学习辅助系统，登录完毕后，系统下发JWT令牌。 请求参数\n参数格式：application/json\n参数说明：\n名称 类型 是否必须 备注 username string 必须 用户名 password string 必须 密码 请求数据样例：\n1 2 3 4 { \u0026#34;username\u0026#34;: \u0026#34;jinyong\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;123456\u0026#34; } 响应数据 参数格式：application/json\n参数说明：\n名称 类型 是否必须 默认值 备注 其他信息 code number 必须 响应码, 1 成功 ; 0 失败 msg string 非必须 提示信息 data string 必须 返回的数据 , jwt令牌 响应数据样例：\n1 2 3 4 5 { \u0026#34;code\u0026#34;: 1, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiJ9.eyJuYW1lIjoi6YeR5bq4IiwiaWQiOjEsInVzZXJuYW1lIjoiamlueW9uZyIsImV4cCI6MTY2MjIwNzA0OH0.KkUc_CXJZJ8Dd063eImx4H9Ojfrr6XMJ-yVzaWCVZCo\u0026#34; } 备注说明 用户登录成功后，系统会自动下发JWT令牌，然后在后续的每次请求中，都需要在请求头header中携带到服务端，请求头的名称为 token ，值为 登录时下发的JWT令牌。\n如果检测到用户未登录，则会返回如下固定错误信息：\n1 2 3 4 5 { \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;NOT_LOGIN\u0026#34;, \u0026#34;data\u0026#34;: null } 登录校验过滤器：LoginCheckFilter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @Slf4j @WebFilter(urlPatterns = \u0026#34;/*\u0026#34;) //拦截所有请求 public class LoginCheckFilter implements Filter { @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain chain) throws IOException, ServletException { //前置：强制转换为http协议的请求对象、响应对象 （转换原因：要使用子类中特有方法） HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; //1.获取请求url String url = request.getRequestURL().toString(); log.info(\u0026#34;请求路径：{}\u0026#34;, url); //请求路径：http://localhost:8080/login //2.判断请求url中是否包含login，如果包含，说明是登录操作，放行 if(url.contains(\u0026#34;/login\u0026#34;)){ chain.doFilter(request, response);//放行请求 return;//结束当前方法的执行 } //3.获取请求头中的令牌（token） String token = request.getHeader(\u0026#34;token\u0026#34;); log.info(\u0026#34;从请求头中获取的令牌：{}\u0026#34;,token); //4.判断令牌是否存在，如果不存在，返回错误结果（未登录） if(!StringUtils.hasLength(token)){ log.info(\u0026#34;Token不存在\u0026#34;); Result responseResult = Result.error(\u0026#34;NOT_LOGIN\u0026#34;); //把Result对象转换为JSON格式字符串 (fastjson是阿里巴巴提供的用于实现对象和json的转换工具类) String json = JSONObject.toJSONString(responseResult); response.setContentType(\u0026#34;application/json;charset=utf-8\u0026#34;); //响应 response.getWriter().write(json); return; } //5.解析token，如果解析失败，返回错误结果（未登录） try { JwtUtils.parseJWT(token); }catch (Exception e){ log.info(\u0026#34;令牌解析失败!\u0026#34;); Result responseResult = Result.error(\u0026#34;NOT_LOGIN\u0026#34;); //把Result对象转换为JSON格式字符串 (fastjson是阿里巴巴提供的用于实现对象和json的转换工具类) String json = JSONObject.toJSONString(responseResult); response.setContentType(\u0026#34;application/json;charset=utf-8\u0026#34;); //响应 response.getWriter().write(json); return; } //6.放行 chain.doFilter(request, response); } } 在上述过滤器的功能实现中，我们使用到了一个第三方json处理的工具包fastjson。我们要想使用，需要引入如下依赖：\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.76\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 登录校验的过滤器我们编写完成了，接下来我们就可以重新启动服务来做一个测试：\n测试前先把之前所编写的测试使用的过滤器，暂时注释掉。直接将@WebFilter注解给注释掉即可。\n测试1：未登录是否可以访问部门管理页面\n首先关闭浏览器，重新打开浏览器，在地址栏中输入：http://localhost:9528/#/system/dept\n由于用户没有登录，登录校验过滤器返回错误信息，前端页面根据返回的错误信息结果，自动跳转到登录页面了\n测试2：先进行登录操作，再访问部门管理页面 登录校验成功之后，可以正常访问相关业务操作页面\n登录校验-Interceptor-入门 学习完了过滤器Filter之后，接下来我们继续学习拦截器Interseptor。\n拦截器我们主要分为三个方面进行讲解：\n介绍下什么是拦截器，并通过快速入门程序上手拦截器 拦截器的使用细节 通过拦截器Interceptor完成登录校验功能 我们先学习第一块内容：拦截器快速入门\n快速入门 什么是拦截器？\n是一种动态拦截方法调用的机制，类似于过滤器。 拦截器是Spring框架中提供的，用来动态拦截控制器方法的执行。 拦截器的作用：\n拦截请求，在指定方法调用前后，根据业务需要执行预先设定的代码。 在拦截器当中，我们通常也是做一些通用性的操作，比如：我们可以通过拦截器来拦截前端发起的请求，将登录校验的逻辑全部编写在拦截器当中。在校验的过程当中，如发现用户登录了(携带JWT令牌且是合法令牌)，就可以直接放行，去访问spring当中的资源。如果校验时发现并没有登录或是非法令牌，就可以直接给前端响应未登录的错误信息。\n下面我们通过快速入门程序，来学习下拦截器的基本使用。拦截器的使用步骤和过滤器类似，也分为两步：\n定义拦截器 注册配置拦截器 **自定义拦截器：**实现HandlerInterceptor接口，并重写其所有方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 //自定义拦截器 @Component public class LoginCheckInterceptor implements HandlerInterceptor { //目标资源方法执行前执行。 返回true：放行 返回false：不放行 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\u0026#34;preHandle .... \u0026#34;); return true; //true表示放行 } //目标资源方法执行后执行 @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\u0026#34;postHandle ... \u0026#34;); } //视图渲染完毕后执行，最后执行 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\u0026#34;afterCompletion .... \u0026#34;); } } 注意：\npreHandle方法：目标资源方法执行前执行。 返回true：放行 返回false：不放行\npostHandle方法：目标资源方法执行后执行\nafterCompletion方法：视图渲染完毕后执行，最后执行\n注册配置拦截器：实现WebMvcConfigurer接口，并重写addInterceptors方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Configuration public class WebConfig implements WebMvcConfigurer { //自定义的拦截器对象 @Autowired private LoginCheckInterceptor loginCheckInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { //注册自定义拦截器对象 registry.addInterceptor(loginCheckInterceptor).addPathPatterns(\u0026#34;/**\u0026#34;);//设置拦截器拦截的请求路径（ /** 表示拦截所有请求） } } 重新启动SpringBoot服务，打开postman测试：\n接下来我们再来做一个测试：将拦截器中返回值改为false\n使用postman，再次点击send发送请求后，没有响应数据，说明请求被拦截了没有放行\n登录校验-Interceptor-详解 拦截器的入门程序完成之后，接下来我们来介绍拦截器的使用细节。拦截器的使用细节我们主要介绍两个部分：\n拦截器的拦截路径配置 拦截器的执行流程 拦截路径 首先我们先来看拦截器的拦截路径的配置，在注册配置拦截器的时候，我们要指定拦截器的拦截路径，通过addPathPatterns(\u0026quot;要拦截路径\u0026quot;)方法，就可以指定要拦截哪些资源。\n在入门程序中我们配置的是/**，表示拦截所有资源，而在配置拦截器时，不仅可以指定要拦截哪些资源，还可以指定不拦截哪些资源，只需要调用excludePathPatterns(\u0026quot;不拦截路径\u0026quot;)方法，指定哪些资源不需要拦截。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Configuration public class WebConfig implements WebMvcConfigurer { //拦截器对象 @Autowired private LoginCheckInterceptor loginCheckInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { //注册自定义拦截器对象 registry.addInterceptor(loginCheckInterceptor) .addPathPatterns(\u0026#34;/**\u0026#34;)//设置拦截器拦截的请求路径（ /** 表示拦截所有请求） .excludePathPatterns(\u0026#34;/login\u0026#34;);//设置不拦截的请求路径 } } 在拦截器中除了可以设置/**拦截所有资源外，还有一些常见拦截路径设置：\n拦截路径 含义 举例 /* 一级路径 能匹配/depts，/emps，/login，不能匹配 /depts/1 /** 任意级路径 能匹配/depts，/depts/1，/depts/1/2 /depts/* /depts下的一级路径 能匹配/depts/1，不能匹配/depts/1/2，/depts /depts/** /depts下的任意级路径 能匹配/depts，/depts/1，/depts/1/2，不能匹配/emps/1 下面主要来演示下/**与/*的区别：\n修改拦截器配置，把拦截路径设置为/* 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Configuration public class WebConfig implements WebMvcConfigurer { //拦截器对象 @Autowired private LoginCheckInterceptor loginCheckInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { //注册自定义拦截器对象 registry.addInterceptor(loginCheckInterceptor) .addPathPatterns(\u0026#34;/*\u0026#34;) .excludePathPatterns(\u0026#34;/login\u0026#34;);//设置不拦截的请求路径 } } 使用postman测试：http://localhost:8080/emps/1\n控制台没有输出拦截器中的日志信息，说明/*没有匹配到拦截路径/emp/1 。\n执行流程 介绍完拦截路径的配置之后，接下来我们再来介绍拦截器的执行流程。通过执行流程，大家就能够清晰的知道过滤器与拦截器的执行时机。\n当我们打开浏览器来访问部署在web服务器当中的web应用时，此时我们所定义的过滤器会拦截到这次请求。拦截到这次请求之后，它会先执行放行前的逻辑，然后再执行放行操作。而由于我们当前是基于springboot开发的，所以放行之后是进入到了spring的环境当中，也就是要来访问我们所定义的controller当中的接口方法。 Tomcat并不识别所编写的Controller程序，但是它识别Servlet程序，所以在Spring的Web环境中提供了一个非常核心的Servlet：DispatcherServlet（前端控制器），所有请求都会先进行到DispatcherServlet，再将请求转给Controller。 当我们定义了拦截器后，会在执行Controller的方法之前，请求被拦截器拦截住。执行preHandle()方法，这个方法执行完成后需要返回一个布尔类型的值，如果返回true，就表示放行本次操作，才会继续访问controller中的方法；如果返回false，则不会放行（controller中的方法也不会执行）。 在controller当中的方法执行完毕之后，再回过来执行postHandle()这个方法以及afterCompletion() 方法，然后再返回给DispatcherServlet，最终再来执行过滤器当中放行后的这一部分逻辑的逻辑。执行完毕之后，最终给浏览器响应数据。 接下来我们就来演示下过滤器和拦截器同时存在的执行流程：\n开启LoginCheckInterceptor拦截器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Component public class LoginCheckInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\u0026#34;preHandle .... \u0026#34;); return true; //true表示放行 } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\u0026#34;postHandle ... \u0026#34;); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\u0026#34;afterCompletion .... \u0026#34;); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Configuration public class WebConfig implements WebMvcConfigurer { //拦截器对象 @Autowired private LoginCheckInterceptor loginCheckInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { //注册自定义拦截器对象 registry.addInterceptor(loginCheckInterceptor) .addPathPatterns(\u0026#34;/**\u0026#34;)//拦截所有请求 .excludePathPatterns(\u0026#34;/login\u0026#34;);//不拦截登录请求 } } 开启DemoFilter过滤器 1 2 3 4 5 6 7 8 9 10 11 12 @WebFilter(urlPatterns = \u0026#34;/*\u0026#34;) public class DemoFilter implements Filter { @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { System.out.println(\u0026#34;DemoFilter 放行前逻辑.....\u0026#34;); //放行请求 filterChain.doFilter(servletRequest,servletResponse); System.out.println(\u0026#34;DemoFilter 放行后逻辑.....\u0026#34;); } } 重启SpringBoot服务后，清空日志，打开Postman，测试查询部门：\n以上就是拦截器的执行流程。通过执行流程分析，大家应该已经清楚了过滤器和拦截器之间的区别，其实它们之间的区别主要是两点：\n接口规范不同：过滤器需要实现Filter接口，而拦截器需要实现HandlerInterceptor接口。 拦截范围不同：过滤器Filter会拦截所有的资源，而Interceptor只会拦截Spring环境中的资源。 登录校验-Interceptor-登录校验拦截器 讲解完了拦截器的基本操作之后，接下来我们需要完成最后一步操作：通过拦截器来完成案例当中的登录校验功能。\n登录校验的业务逻辑以及操作步骤我们前面已经分析过了，和登录校验Filter过滤器当中的逻辑是完全一致的。现在我们只需要把这个技术方案由原来的过滤器换成拦截器interceptor就可以了。\n登录校验拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 //自定义拦截器 @Component //当前拦截器对象由Spring创建和管理 @Slf4j public class LoginCheckInterceptor implements HandlerInterceptor { //前置方式 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\u0026#34;preHandle .... \u0026#34;); //1.获取请求url //2.判断请求url中是否包含login，如果包含，说明是登录操作，放行 //3.获取请求头中的令牌（token） String token = request.getHeader(\u0026#34;token\u0026#34;); log.info(\u0026#34;从请求头中获取的令牌：{}\u0026#34;,token); //4.判断令牌是否存在，如果不存在，返回错误结果（未登录） if(!StringUtils.hasLength(token)){ log.info(\u0026#34;Token不存在\u0026#34;); //创建响应结果对象 Result responseResult = Result.error(\u0026#34;NOT_LOGIN\u0026#34;); //把Result对象转换为JSON格式字符串 (fastjson是阿里巴巴提供的用于实现对象和json的转换工具类) String json = JSONObject.toJSONString(responseResult); //设置响应头（告知浏览器：响应的数据类型为json、响应的数据编码表为utf-8） response.setContentType(\u0026#34;application/json;charset=utf-8\u0026#34;); //响应 response.getWriter().write(json); return false;//不放行 } //5.解析token，如果解析失败，返回错误结果（未登录） try { JwtUtils.parseJWT(token); }catch (Exception e){ log.info(\u0026#34;令牌解析失败!\u0026#34;); //创建响应结果对象 Result responseResult = Result.error(\u0026#34;NOT_LOGIN\u0026#34;); //把Result对象转换为JSON格式字符串 (fastjson是阿里巴巴提供的用于实现对象和json的转换工具类) String json = JSONObject.toJSONString(responseResult); //设置响应头 response.setContentType(\u0026#34;application/json;charset=utf-8\u0026#34;); //响应 response.getWriter().write(json); return false; } //6.放行 return true; } 注册配置拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Configuration public class WebConfig implements WebMvcConfigurer { //拦截器对象 @Autowired private LoginCheckInterceptor loginCheckInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { //注册自定义拦截器对象 registry.addInterceptor(loginCheckInterceptor) .addPathPatterns(\u0026#34;/**\u0026#34;) .excludePathPatterns(\u0026#34;/login\u0026#34;); } } 登录校验的拦截器编写完成后，接下来我们就可以重新启动服务来做一个测试： （关闭登录校验Filter过滤器）\n测试1：未登录是否可以访问部门管理页面\n首先关闭浏览器，重新打开浏览器，在地址栏中输入：http://localhost:9528/#/system/dept\n由于用户没有登录，校验机制返回错误信息，前端页面根据返回的错误信息结果，自动跳转到登录页面了\n测试2：先进行登录操作，再访问部门管理页面 登录校验成功之后，可以正常访问相关业务操作页面\n到此我们也就验证了所开发的登录校验的拦截器也是没问题的。登录校验的过滤器和拦截器，我们只需要使用其中的一种就可以了。\n异常处理 当前问题 登录功能和登录校验功能我们都实现了，下面我们学习下今天最后一块技术点：异常处理。首先我们先来看一下系统出现异常之后会发生什么现象，再来介绍异常处理的方案。\n我们打开浏览器，访问系统中的新增部门操作，系统中已经有了 \u0026ldquo;就业部\u0026rdquo; 这个部门，我们再来增加一个就业部，看看会发生什么现象。\n点击确定之后，窗口关闭了，页面没有任何反应，就业部也没有添加上。 而此时，大家会发现，网络请求报错了。\n状态码为500，表示服务器端异常，我们打开idea，来看一下，服务器端出了什么问题。\n上述错误信息的含义是，dept部门表的name字段的值 就业部 重复了，因为在数据库表dept中已经有了就业部，我们之前设计这张表时，为name字段建议了唯一约束，所以该字段的值是不能重复的。\n而当我们再添加就业部，这个部门时，就违反了唯一约束，此时就会报错。\n我们来看一下出现异常之后，最终服务端给前端响应回来的数据长什么样。\n响应回来的数据是一个JSON格式的数据。但这种JSON格式的数据还是我们开发规范当中所提到的统一响应结果Result吗？显然并不是。由于返回的数据不符合开发规范，所以前端并不能解析出响应的JSON数据。\n接下来我们需要思考的是出现异常之后，当前案例项目的异常是怎么处理的？\n答案：没有做任何的异常处理 当我们没有做任何的异常处理时，我们三层架构处理异常的方案：\nMapper接口在操作数据库的时候出错了，此时异常会往上抛(谁调用Mapper就抛给谁)，会抛给service。 service 中也存在异常了，会抛给controller。 而在controller当中，我们也没有做任何的异常处理，所以最终异常会再往上抛。最终抛给框架之后，框架就会返回一个JSON格式的数据，里面封装的就是错误的信息，但是框架返回的JSON格式的数据并不符合我们的开发规范。 16.2 解决方案 那么在三层构架项目中，出现了异常，该如何处理?\n方案一：在所有Controller的所有方法中进行try…catch处理 缺点：代码臃肿（不推荐） 方案二：全局异常处理器 好处：简单、优雅（推荐） 全局异常处理器 我们该怎么样定义全局异常处理器？\n定义全局异常处理器非常简单，就是定义一个类，在类上加上一个注解@RestControllerAdvice，加上这个注解就代表我们定义了一个全局异常处理器。 在全局异常处理器当中，需要定义一个方法来捕获异常，在这个方法上需要加上注解@ExceptionHandler。通过@ExceptionHandler注解当中的value属性来指定我们要捕获的是哪一类型的异常。 1 2 3 4 5 6 7 8 9 10 11 12 @RestControllerAdvice public class GlobalExceptionHandler { //处理异常 @ExceptionHandler(Exception.class) //指定能够处理的异常类型 public Result ex(Exception e){ e.printStackTrace();//打印堆栈中的异常信息 //捕获到异常之后，响应一个标准的Result return Result.error(\u0026#34;对不起,操作失败,请联系管理员\u0026#34;); } } @RestControllerAdvice = @ControllerAdvice + @ResponseBody\n处理异常的方法返回值会转换为json后再响应给前端\n重新启动SpringBoot服务，打开浏览器，再来测试一下添加部门这个操作，我们依然添加已存在的 \u0026ldquo;就业部\u0026rdquo; 这个部门：\n此时，我们可以看到，出现异常之后，异常已经被全局异常处理器捕获了。然后返回的错误信息，被前端程序正常解析，然后提示出了对应的错误提示信息。\n以上就是全局异常处理器的使用，主要涉及到两个注解：\n@RestControllerAdvice //表示当前类为全局异常处理器 @ExceptionHandler //指定可以捕获哪种类型的异常进行处理 ","date":"2024-04-13T16:01:23+08:00","image":"https://nova-bryan.github.io/p/%E7%99%BB%E5%BD%95%E5%8A%9F%E8%83%BD/image_hu17089168107649188491.png","permalink":"https://nova-bryan.github.io/p/%E7%99%BB%E5%BD%95%E5%8A%9F%E8%83%BD/","title":"登录功能"}]